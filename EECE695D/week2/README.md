1. 딥러닝 분산처리 기술동향 - 안신영(에트리) : training vs inference = https://ettrends.etri.re.kr/ettrends/159/0905002137/31-3_131-141.pdf
2. training vs inference = https://manchann.tistory.com/16
3. Dual Number and Automatic Differentiation： https://jryoungwmath.notion.site/Dual-Number-and-Automatic-Differentiation-1aedf496350340eca2f1ffd7e81d1566
－ Forward(Memory, requirements) = Constant 이해.
4. 고성능 코딩 In-place Operation : https://blog.naver.com/wideeyed/221374272094
5. 바닐라모델 : https://lv99.tistory.com/30
6. DeepLearning CNN BottleNeck 원리(Pytorch 구현) : https://coding-yoon.tistory.com/116
7. 순전파, 역전파의 메모리 : https://ko.d2l.ai/chapter_deep-learning-basics/backprop.html
8. 두 모델 중, FLOPs가 상대적으로 낮은 모델의 Inference time이 더 빠른가? : https://leechanhyuk.github.io/discussion/FLOPs%EA%B0%80-%EB%82%AE%EC%9C%BC%EB%A9%B4-%EB%8D%94-%EB%B9%A0%EB%A5%B8%EA%B0%80/
9. overhead : https://donggu1105.tistory.com/175
10. wall clock time
- https://2fered.tistory.com/614
- https://www.techtarget.com/whatis/definition/wall-time-real-world-time-or-wall-clock-time
11. FLOPs 계산
12. - https://math.stackexchange.com/questions/2427094/computing-flops-for-matrix-multiplication
13. - https://www.stat.cmu.edu/~ryantibs/convexopt-F18/scribes/Lecture_19.pdf
