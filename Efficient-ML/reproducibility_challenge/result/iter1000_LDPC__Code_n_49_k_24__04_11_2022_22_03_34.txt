Path to model/logs: Results_ECCT\LDPC__Code_n_49_k_24__04_11_2022_22_03_34
Namespace(epochs=1000, workers=0, lr=0.0001, gpus='0', batch_size=128, test_batch_size=2048, seed=42, code_type='LDPC', code_k=24, code_n=49, standardize=False, N_dec=6, d_model=32, h=8, code=<__main__.Code object at 0x00000248297F2470>, path='Results_ECCT\\LDPC__Code_n_49_k_24__04_11_2022_22_03_34')
Self-Attention Sparsity Ratio=72.26%, Self-Attention Complexity Ratio=13.87%
Mask:
 tensor([[[[False,  True,  True,  ...,  True,  True,  True],
          [ True, False,  True,  ...,  True,  True,  True],
          [ True,  True, False,  ...,  True,  True,  True],
          ...,
          [ True,  True,  True,  ..., False,  True,  True],
          [ True,  True,  True,  ...,  True, False,  True],
          [ True,  True,  True,  ...,  True,  True, False]]]])
ECC_Transformer(
  (decoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (oned_final_embed): Sequential(
    (0): Linear(in_features=32, out_features=1, bias=True)
  )
  (out_fc): Linear(in_features=77, out_features=49, bias=True)
)
# of Parameters: 82671
Training epoch 1, Batch 500/1000: LR=1.00e-04, Loss=2.50e-01 BER=8.23e-02 FER=8.53e-01
Training epoch 1, Batch 1000/1000: LR=1.00e-04, Loss=2.19e-01 BER=6.81e-02 FER=8.41e-01
Epoch 1 Train Time 41.05219554901123s


Test Loss 4: 1.95e-01 5: 1.36e-01 6: 8.49e-02
Test FER 4: 9.48e-01 5: 8.61e-01 6: 6.99e-01
Test BER 4: 5.84e-02 5: 3.95e-02 6: 2.42e-02
Test -ln(BER) 4: 2.84e+00 5: 3.23e+00 6: 3.72e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 56.758323192596436 s

Training epoch 2, Batch 500/1000: LR=1.00e-04, Loss=1.72e-01 BER=5.33e-02 FER=8.15e-01
Training epoch 2, Batch 1000/1000: LR=1.00e-04, Loss=1.64e-01 BER=5.22e-02 FER=7.74e-01
Epoch 2 Train Time 39.22764325141907s

Training epoch 3, Batch 500/1000: LR=1.00e-04, Loss=1.45e-01 BER=4.81e-02 FER=6.36e-01
Training epoch 3, Batch 1000/1000: LR=1.00e-04, Loss=1.40e-01 BER=4.68e-02 FER=6.09e-01
Epoch 3 Train Time 39.233930587768555s

Training epoch 4, Batch 500/1000: LR=1.00e-04, Loss=1.29e-01 BER=4.40e-02 FER=5.50e-01
Training epoch 4, Batch 1000/1000: LR=1.00e-04, Loss=1.26e-01 BER=4.32e-02 FER=5.37e-01
Epoch 4 Train Time 39.21053957939148s

Training epoch 5, Batch 500/1000: LR=1.00e-04, Loss=1.19e-01 BER=4.12e-02 FER=5.07e-01
Training epoch 5, Batch 1000/1000: LR=1.00e-04, Loss=1.17e-01 BER=4.07e-02 FER=4.99e-01
Epoch 5 Train Time 39.20812773704529s

Training epoch 6, Batch 500/1000: LR=1.00e-04, Loss=1.11e-01 BER=3.92e-02 FER=4.80e-01
Training epoch 6, Batch 1000/1000: LR=1.00e-04, Loss=1.09e-01 BER=3.88e-02 FER=4.77e-01
Epoch 6 Train Time 39.472633600234985s

Training epoch 7, Batch 500/1000: LR=1.00e-04, Loss=1.04e-01 BER=3.75e-02 FER=4.63e-01
Training epoch 7, Batch 1000/1000: LR=1.00e-04, Loss=1.02e-01 BER=3.70e-02 FER=4.60e-01
Epoch 7 Train Time 39.22774338722229s

Training epoch 8, Batch 500/1000: LR=1.00e-04, Loss=9.68e-02 BER=3.56e-02 FER=4.46e-01
Training epoch 8, Batch 1000/1000: LR=1.00e-04, Loss=9.49e-02 BER=3.51e-02 FER=4.41e-01
Epoch 8 Train Time 38.855074644088745s

Training epoch 9, Batch 500/1000: LR=1.00e-04, Loss=8.97e-02 BER=3.38e-02 FER=4.24e-01
Training epoch 9, Batch 1000/1000: LR=1.00e-04, Loss=8.79e-02 BER=3.31e-02 FER=4.17e-01
Epoch 9 Train Time 38.905460596084595s

Training epoch 10, Batch 500/1000: LR=1.00e-04, Loss=8.35e-02 BER=3.16e-02 FER=4.00e-01
Training epoch 10, Batch 1000/1000: LR=1.00e-04, Loss=8.25e-02 BER=3.12e-02 FER=3.94e-01
Epoch 10 Train Time 39.00076723098755s

Training epoch 11, Batch 500/1000: LR=1.00e-04, Loss=7.86e-02 BER=2.99e-02 FER=3.76e-01
Training epoch 11, Batch 1000/1000: LR=1.00e-04, Loss=7.74e-02 BER=2.94e-02 FER=3.70e-01
Epoch 11 Train Time 38.911983489990234s

Training epoch 12, Batch 500/1000: LR=1.00e-04, Loss=7.38e-02 BER=2.81e-02 FER=3.52e-01
Training epoch 12, Batch 1000/1000: LR=1.00e-04, Loss=7.30e-02 BER=2.78e-02 FER=3.48e-01
Epoch 12 Train Time 38.92033386230469s

Training epoch 13, Batch 500/1000: LR=1.00e-04, Loss=7.04e-02 BER=2.67e-02 FER=3.34e-01
Training epoch 13, Batch 1000/1000: LR=1.00e-04, Loss=6.94e-02 BER=2.64e-02 FER=3.29e-01
Epoch 13 Train Time 38.87580728530884s

Training epoch 14, Batch 500/1000: LR=1.00e-04, Loss=6.68e-02 BER=2.53e-02 FER=3.13e-01
Training epoch 14, Batch 1000/1000: LR=1.00e-04, Loss=6.58e-02 BER=2.50e-02 FER=3.08e-01
Epoch 14 Train Time 38.981542348861694s

Training epoch 15, Batch 500/1000: LR=1.00e-04, Loss=6.36e-02 BER=2.41e-02 FER=2.96e-01
Training epoch 15, Batch 1000/1000: LR=1.00e-04, Loss=6.24e-02 BER=2.37e-02 FER=2.90e-01
Epoch 15 Train Time 38.98714733123779s

Training epoch 16, Batch 500/1000: LR=9.99e-05, Loss=5.96e-02 BER=2.26e-02 FER=2.76e-01
Training epoch 16, Batch 1000/1000: LR=9.99e-05, Loss=5.91e-02 BER=2.23e-02 FER=2.72e-01
Epoch 16 Train Time 38.814799308776855s

Training epoch 17, Batch 500/1000: LR=9.99e-05, Loss=5.74e-02 BER=2.17e-02 FER=2.64e-01
Training epoch 17, Batch 1000/1000: LR=9.99e-05, Loss=5.67e-02 BER=2.14e-02 FER=2.59e-01
Epoch 17 Train Time 38.83260893821716s

Training epoch 18, Batch 500/1000: LR=9.99e-05, Loss=5.50e-02 BER=2.08e-02 FER=2.49e-01
Training epoch 18, Batch 1000/1000: LR=9.99e-05, Loss=5.41e-02 BER=2.05e-02 FER=2.43e-01
Epoch 18 Train Time 38.84550094604492s

Training epoch 19, Batch 500/1000: LR=9.99e-05, Loss=5.21e-02 BER=1.96e-02 FER=2.29e-01
Training epoch 19, Batch 1000/1000: LR=9.99e-05, Loss=5.16e-02 BER=1.95e-02 FER=2.25e-01
Epoch 19 Train Time 38.80939793586731s

Training epoch 20, Batch 500/1000: LR=9.99e-05, Loss=4.90e-02 BER=1.84e-02 FER=2.10e-01
Training epoch 20, Batch 1000/1000: LR=9.99e-05, Loss=4.88e-02 BER=1.84e-02 FER=2.09e-01
Epoch 20 Train Time 38.79447817802429s

Training epoch 21, Batch 500/1000: LR=9.99e-05, Loss=4.69e-02 BER=1.77e-02 FER=1.98e-01
Training epoch 21, Batch 1000/1000: LR=9.99e-05, Loss=4.65e-02 BER=1.76e-02 FER=1.96e-01
Epoch 21 Train Time 38.849525928497314s

Training epoch 22, Batch 500/1000: LR=9.99e-05, Loss=4.64e-02 BER=1.76e-02 FER=1.94e-01
Training epoch 22, Batch 1000/1000: LR=9.99e-05, Loss=4.58e-02 BER=1.74e-02 FER=1.91e-01
Epoch 22 Train Time 38.831392765045166s

Training epoch 23, Batch 500/1000: LR=9.99e-05, Loss=4.43e-02 BER=1.68e-02 FER=1.84e-01
Training epoch 23, Batch 1000/1000: LR=9.99e-05, Loss=4.42e-02 BER=1.68e-02 FER=1.84e-01
Epoch 23 Train Time 38.861701250076294s

Training epoch 24, Batch 500/1000: LR=9.99e-05, Loss=4.37e-02 BER=1.66e-02 FER=1.78e-01
Training epoch 24, Batch 1000/1000: LR=9.99e-05, Loss=4.39e-02 BER=1.68e-02 FER=1.79e-01
Epoch 24 Train Time 38.91135764122009s

Training epoch 25, Batch 500/1000: LR=9.99e-05, Loss=4.33e-02 BER=1.65e-02 FER=1.75e-01
Training epoch 25, Batch 1000/1000: LR=9.99e-05, Loss=4.27e-02 BER=1.63e-02 FER=1.73e-01
Epoch 25 Train Time 38.819788455963135s

Training epoch 26, Batch 500/1000: LR=9.98e-05, Loss=4.12e-02 BER=1.56e-02 FER=1.66e-01
Training epoch 26, Batch 1000/1000: LR=9.98e-05, Loss=4.15e-02 BER=1.58e-02 FER=1.68e-01
Epoch 26 Train Time 39.00793385505676s

Training epoch 27, Batch 500/1000: LR=9.98e-05, Loss=4.09e-02 BER=1.57e-02 FER=1.64e-01
Training epoch 27, Batch 1000/1000: LR=9.98e-05, Loss=4.14e-02 BER=1.58e-02 FER=1.65e-01
Epoch 27 Train Time 38.80843234062195s

Training epoch 28, Batch 500/1000: LR=9.98e-05, Loss=4.14e-02 BER=1.60e-02 FER=1.67e-01
Training epoch 28, Batch 1000/1000: LR=9.98e-05, Loss=4.11e-02 BER=1.58e-02 FER=1.65e-01
Epoch 28 Train Time 38.82035827636719s

Training epoch 29, Batch 500/1000: LR=9.98e-05, Loss=4.02e-02 BER=1.54e-02 FER=1.59e-01
Training epoch 29, Batch 1000/1000: LR=9.98e-05, Loss=4.03e-02 BER=1.55e-02 FER=1.60e-01
Epoch 29 Train Time 38.7980260848999s

Training epoch 30, Batch 500/1000: LR=9.98e-05, Loss=4.08e-02 BER=1.58e-02 FER=1.60e-01
Training epoch 30, Batch 1000/1000: LR=9.98e-05, Loss=4.04e-02 BER=1.56e-02 FER=1.59e-01
Epoch 30 Train Time 38.836326122283936s

Training epoch 31, Batch 500/1000: LR=9.98e-05, Loss=3.92e-02 BER=1.50e-02 FER=1.56e-01
Training epoch 31, Batch 1000/1000: LR=9.98e-05, Loss=3.96e-02 BER=1.53e-02 FER=1.57e-01
Epoch 31 Train Time 38.80801796913147s

Training epoch 32, Batch 500/1000: LR=9.98e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Training epoch 32, Batch 1000/1000: LR=9.98e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Epoch 32 Train Time 38.86104941368103s

Training epoch 33, Batch 500/1000: LR=9.98e-05, Loss=3.92e-02 BER=1.51e-02 FER=1.54e-01
Training epoch 33, Batch 1000/1000: LR=9.98e-05, Loss=3.89e-02 BER=1.51e-02 FER=1.53e-01
Epoch 33 Train Time 38.791754961013794s

Training epoch 34, Batch 500/1000: LR=9.97e-05, Loss=3.86e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 34, Batch 1000/1000: LR=9.97e-05, Loss=3.87e-02 BER=1.50e-02 FER=1.51e-01
Epoch 34 Train Time 38.81608271598816s

Training epoch 35, Batch 500/1000: LR=9.97e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 35, Batch 1000/1000: LR=9.97e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Epoch 35 Train Time 38.9932074546814s

Training epoch 36, Batch 500/1000: LR=9.97e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Training epoch 36, Batch 1000/1000: LR=9.97e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Epoch 36 Train Time 39.57495665550232s

Training epoch 37, Batch 500/1000: LR=9.97e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.50e-01
Training epoch 37, Batch 1000/1000: LR=9.97e-05, Loss=3.82e-02 BER=1.49e-02 FER=1.49e-01
Epoch 37 Train Time 38.77139973640442s

Training epoch 38, Batch 500/1000: LR=9.97e-05, Loss=3.78e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 38, Batch 1000/1000: LR=9.97e-05, Loss=3.78e-02 BER=1.47e-02 FER=1.47e-01
Epoch 38 Train Time 38.961445569992065s

Training epoch 39, Batch 500/1000: LR=9.96e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.49e-01
Training epoch 39, Batch 1000/1000: LR=9.96e-05, Loss=3.81e-02 BER=1.49e-02 FER=1.48e-01
Epoch 39 Train Time 38.81941509246826s

Training epoch 40, Batch 500/1000: LR=9.96e-05, Loss=3.76e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 40, Batch 1000/1000: LR=9.96e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.46e-01
Epoch 40 Train Time 38.81033754348755s

Training epoch 41, Batch 500/1000: LR=9.96e-05, Loss=3.78e-02 BER=1.48e-02 FER=1.47e-01
Training epoch 41, Batch 1000/1000: LR=9.96e-05, Loss=3.77e-02 BER=1.48e-02 FER=1.46e-01
Epoch 41 Train Time 38.86417770385742s

Training epoch 42, Batch 500/1000: LR=9.96e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 42, Batch 1000/1000: LR=9.96e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.43e-01
Epoch 42 Train Time 38.793354511260986s

Training epoch 43, Batch 500/1000: LR=9.96e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 43, Batch 1000/1000: LR=9.96e-05, Loss=3.70e-02 BER=1.45e-02 FER=1.44e-01
Epoch 43 Train Time 38.82466411590576s

Training epoch 44, Batch 500/1000: LR=9.95e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 44, Batch 1000/1000: LR=9.95e-05, Loss=3.76e-02 BER=1.48e-02 FER=1.46e-01
Epoch 44 Train Time 38.81491541862488s

Training epoch 45, Batch 500/1000: LR=9.95e-05, Loss=3.66e-02 BER=1.44e-02 FER=1.41e-01
Training epoch 45, Batch 1000/1000: LR=9.95e-05, Loss=3.65e-02 BER=1.44e-02 FER=1.42e-01
Epoch 45 Train Time 38.79359245300293s

Training epoch 46, Batch 500/1000: LR=9.95e-05, Loss=3.63e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 46, Batch 1000/1000: LR=9.95e-05, Loss=3.60e-02 BER=1.41e-02 FER=1.41e-01
Epoch 46 Train Time 65.42178678512573s

Training epoch 47, Batch 500/1000: LR=9.95e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.44e-01
Training epoch 47, Batch 1000/1000: LR=9.95e-05, Loss=3.67e-02 BER=1.44e-02 FER=1.42e-01
Epoch 47 Train Time 39.348411321640015s

Training epoch 48, Batch 500/1000: LR=9.95e-05, Loss=3.55e-02 BER=1.40e-02 FER=1.38e-01
Training epoch 48, Batch 1000/1000: LR=9.95e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.39e-01
Epoch 48 Train Time 38.96104979515076s

Training epoch 49, Batch 500/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 49, Batch 1000/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Epoch 49 Train Time 38.929667949676514s

Training epoch 50, Batch 500/1000: LR=9.94e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 50, Batch 1000/1000: LR=9.94e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Epoch 50 Train Time 38.93093824386597s

Training epoch 51, Batch 500/1000: LR=9.94e-05, Loss=3.62e-02 BER=1.44e-02 FER=1.41e-01
Training epoch 51, Batch 1000/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.43e-02 FER=1.40e-01
Epoch 51 Train Time 38.95204162597656s

Training epoch 52, Batch 500/1000: LR=9.94e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 52, Batch 1000/1000: LR=9.94e-05, Loss=3.56e-02 BER=1.41e-02 FER=1.38e-01
Epoch 52 Train Time 38.89628291130066s

Training epoch 53, Batch 500/1000: LR=9.93e-05, Loss=3.61e-02 BER=1.43e-02 FER=1.40e-01
Training epoch 53, Batch 1000/1000: LR=9.93e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.38e-01
Epoch 53 Train Time 38.96631360054016s

Training epoch 54, Batch 500/1000: LR=9.93e-05, Loss=3.53e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 54, Batch 1000/1000: LR=9.93e-05, Loss=3.52e-02 BER=1.39e-02 FER=1.36e-01
Epoch 54 Train Time 39.32654356956482s

Training epoch 55, Batch 500/1000: LR=9.93e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 55, Batch 1000/1000: LR=9.93e-05, Loss=3.53e-02 BER=1.40e-02 FER=1.37e-01
Epoch 55 Train Time 39.1203088760376s

Training epoch 56, Batch 500/1000: LR=9.93e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.36e-01
Training epoch 56, Batch 1000/1000: LR=9.93e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.35e-01
Epoch 56 Train Time 39.035260915756226s

Training epoch 57, Batch 500/1000: LR=9.92e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 57, Batch 1000/1000: LR=9.92e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.38e-01
Epoch 57 Train Time 38.55743169784546s

Training epoch 58, Batch 500/1000: LR=9.92e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.35e-01
Training epoch 58, Batch 1000/1000: LR=9.92e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 58 Train Time 38.522767782211304s

Training epoch 59, Batch 500/1000: LR=9.92e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 59, Batch 1000/1000: LR=9.92e-05, Loss=3.50e-02 BER=1.39e-02 FER=1.36e-01
Epoch 59 Train Time 38.55083656311035s

Training epoch 60, Batch 500/1000: LR=9.92e-05, Loss=3.56e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 60, Batch 1000/1000: LR=9.92e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Epoch 60 Train Time 38.52092146873474s

Training epoch 61, Batch 500/1000: LR=9.91e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 61, Batch 1000/1000: LR=9.91e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 61 Train Time 38.530730962753296s

Training epoch 62, Batch 500/1000: LR=9.91e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.36e-01
Training epoch 62, Batch 1000/1000: LR=9.91e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.36e-01
Epoch 62 Train Time 38.571999073028564s

Training epoch 63, Batch 500/1000: LR=9.91e-05, Loss=3.46e-02 BER=1.39e-02 FER=1.33e-01
Training epoch 63, Batch 1000/1000: LR=9.91e-05, Loss=3.48e-02 BER=1.39e-02 FER=1.35e-01
Epoch 63 Train Time 38.56329798698425s

Training epoch 64, Batch 500/1000: LR=9.90e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.33e-01
Training epoch 64, Batch 1000/1000: LR=9.90e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.34e-01
Epoch 64 Train Time 38.68087601661682s

Training epoch 65, Batch 500/1000: LR=9.90e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 65, Batch 1000/1000: LR=9.90e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.36e-01
Epoch 65 Train Time 38.537912368774414s

Training epoch 66, Batch 500/1000: LR=9.90e-05, Loss=3.37e-02 BER=1.34e-02 FER=1.32e-01
Training epoch 66, Batch 1000/1000: LR=9.90e-05, Loss=3.43e-02 BER=1.37e-02 FER=1.33e-01
Epoch 66 Train Time 38.5198028087616s

Training epoch 67, Batch 500/1000: LR=9.89e-05, Loss=3.42e-02 BER=1.36e-02 FER=1.32e-01
Training epoch 67, Batch 1000/1000: LR=9.89e-05, Loss=3.46e-02 BER=1.37e-02 FER=1.34e-01
Epoch 67 Train Time 38.51498627662659s

Training epoch 68, Batch 500/1000: LR=9.89e-05, Loss=3.47e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 68, Batch 1000/1000: LR=9.89e-05, Loss=3.45e-02 BER=1.38e-02 FER=1.34e-01
Epoch 68 Train Time 38.524285554885864s

Training epoch 69, Batch 500/1000: LR=9.89e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.33e-01
Training epoch 69, Batch 1000/1000: LR=9.89e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 69 Train Time 38.5116240978241s

Training epoch 70, Batch 500/1000: LR=9.88e-05, Loss=3.44e-02 BER=1.38e-02 FER=1.34e-01
Training epoch 70, Batch 1000/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.36e-02 FER=1.33e-01
Epoch 70 Train Time 38.539753913879395s

Training epoch 71, Batch 500/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 71, Batch 1000/1000: LR=9.88e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 71 Train Time 38.53736329078674s

Training epoch 72, Batch 500/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 72, Batch 1000/1000: LR=9.88e-05, Loss=3.40e-02 BER=1.35e-02 FER=1.32e-01
Epoch 72 Train Time 38.61905026435852s

Training epoch 73, Batch 500/1000: LR=9.87e-05, Loss=3.43e-02 BER=1.38e-02 FER=1.33e-01
Training epoch 73, Batch 1000/1000: LR=9.87e-05, Loss=3.39e-02 BER=1.36e-02 FER=1.32e-01
Epoch 73 Train Time 38.653565645217896s

Training epoch 74, Batch 500/1000: LR=9.87e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 74, Batch 1000/1000: LR=9.87e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 74 Train Time 38.59780025482178s

Training epoch 75, Batch 500/1000: LR=9.87e-05, Loss=3.35e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 75, Batch 1000/1000: LR=9.87e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 75 Train Time 38.544252157211304s

Training epoch 76, Batch 500/1000: LR=9.86e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 76, Batch 1000/1000: LR=9.86e-05, Loss=3.37e-02 BER=1.34e-02 FER=1.31e-01
Epoch 76 Train Time 38.57830238342285s

Training epoch 77, Batch 500/1000: LR=9.86e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 77, Batch 1000/1000: LR=9.86e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 77 Train Time 38.574660539627075s

Training epoch 78, Batch 500/1000: LR=9.86e-05, Loss=3.42e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 78, Batch 1000/1000: LR=9.86e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.32e-01
Epoch 78 Train Time 38.52133750915527s

Training epoch 79, Batch 500/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 79, Batch 1000/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.31e-01
Epoch 79 Train Time 38.50130033493042s

Training epoch 80, Batch 500/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 80, Batch 1000/1000: LR=9.85e-05, Loss=3.43e-02 BER=1.38e-02 FER=1.32e-01
Epoch 80 Train Time 38.50727391242981s

Training epoch 81, Batch 500/1000: LR=9.84e-05, Loss=3.38e-02 BER=1.34e-02 FER=1.30e-01
Training epoch 81, Batch 1000/1000: LR=9.84e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.31e-01
Epoch 81 Train Time 38.55281686782837s

Training epoch 82, Batch 500/1000: LR=9.84e-05, Loss=3.38e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 82, Batch 1000/1000: LR=9.84e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 82 Train Time 38.6388840675354s

Training epoch 83, Batch 500/1000: LR=9.84e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.30e-01
Training epoch 83, Batch 1000/1000: LR=9.84e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 83 Train Time 38.51431727409363s

Training epoch 84, Batch 500/1000: LR=9.83e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.30e-01
Training epoch 84, Batch 1000/1000: LR=9.83e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.30e-01
Epoch 84 Train Time 38.53512477874756s

Training epoch 85, Batch 500/1000: LR=9.83e-05, Loss=3.33e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 85, Batch 1000/1000: LR=9.83e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 85 Train Time 38.518723011016846s

Training epoch 86, Batch 500/1000: LR=9.82e-05, Loss=3.38e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 86, Batch 1000/1000: LR=9.82e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.30e-01
Epoch 86 Train Time 38.561712980270386s

Training epoch 87, Batch 500/1000: LR=9.82e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.31e-01
Training epoch 87, Batch 1000/1000: LR=9.82e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 87 Train Time 38.51438593864441s

Training epoch 88, Batch 500/1000: LR=9.82e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 88, Batch 1000/1000: LR=9.82e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 88 Train Time 38.588220834732056s

Training epoch 89, Batch 500/1000: LR=9.81e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 89, Batch 1000/1000: LR=9.81e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.30e-01
Epoch 89 Train Time 38.54647469520569s

Training epoch 90, Batch 500/1000: LR=9.81e-05, Loss=3.31e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 90, Batch 1000/1000: LR=9.81e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 90 Train Time 38.54132056236267s

Training epoch 91, Batch 500/1000: LR=9.80e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.28e-01
Training epoch 91, Batch 1000/1000: LR=9.80e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 91 Train Time 38.568161725997925s

Training epoch 92, Batch 500/1000: LR=9.80e-05, Loss=3.34e-02 BER=1.35e-02 FER=1.29e-01
Training epoch 92, Batch 1000/1000: LR=9.80e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.29e-01
Epoch 92 Train Time 38.661986351013184s

Training epoch 93, Batch 500/1000: LR=9.79e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.27e-01
Training epoch 93, Batch 1000/1000: LR=9.79e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 93 Train Time 201.1942162513733s

Training epoch 94, Batch 500/1000: LR=9.79e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 94, Batch 1000/1000: LR=9.79e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 94 Train Time 39.21542453765869s

Training epoch 95, Batch 500/1000: LR=9.79e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Training epoch 95, Batch 1000/1000: LR=9.79e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Epoch 95 Train Time 39.691967725753784s

Training epoch 96, Batch 500/1000: LR=9.78e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 96, Batch 1000/1000: LR=9.78e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 96 Train Time 39.351988554000854s

Training epoch 97, Batch 500/1000: LR=9.78e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 97, Batch 1000/1000: LR=9.78e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.28e-01
Epoch 97 Train Time 39.30508351325989s

Training epoch 98, Batch 500/1000: LR=9.77e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 98, Batch 1000/1000: LR=9.77e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.27e-01
Epoch 98 Train Time 39.31436777114868s

Training epoch 99, Batch 500/1000: LR=9.77e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 99, Batch 1000/1000: LR=9.77e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 99 Train Time 39.401973485946655s

Training epoch 100, Batch 500/1000: LR=9.76e-05, Loss=3.23e-02 BER=1.28e-02 FER=1.25e-01
Training epoch 100, Batch 1000/1000: LR=9.76e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 100 Train Time 39.24130821228027s

Training epoch 101, Batch 500/1000: LR=9.76e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 101, Batch 1000/1000: LR=9.76e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.28e-01
Epoch 101 Train Time 39.671005964279175s

Training epoch 102, Batch 500/1000: LR=9.75e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 102, Batch 1000/1000: LR=9.75e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 102 Train Time 39.36911654472351s

Training epoch 103, Batch 500/1000: LR=9.75e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 103, Batch 1000/1000: LR=9.75e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 103 Train Time 39.030439376831055s

Training epoch 104, Batch 500/1000: LR=9.74e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 104, Batch 1000/1000: LR=9.74e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 104 Train Time 39.04061555862427s

Training epoch 105, Batch 500/1000: LR=9.74e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 105, Batch 1000/1000: LR=9.74e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.27e-01
Epoch 105 Train Time 39.06710171699524s

Training epoch 106, Batch 500/1000: LR=9.73e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 106, Batch 1000/1000: LR=9.73e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 106 Train Time 38.96051859855652s

Training epoch 107, Batch 500/1000: LR=9.73e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.27e-01
Training epoch 107, Batch 1000/1000: LR=9.73e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.27e-01
Epoch 107 Train Time 38.611565828323364s

Training epoch 108, Batch 500/1000: LR=9.72e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 108, Batch 1000/1000: LR=9.72e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.26e-01
Epoch 108 Train Time 38.589770555496216s

Training epoch 109, Batch 500/1000: LR=9.72e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 109, Batch 1000/1000: LR=9.72e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 109 Train Time 38.58258414268494s

Training epoch 110, Batch 500/1000: LR=9.71e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 110, Batch 1000/1000: LR=9.71e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Epoch 110 Train Time 38.61723303794861s

Training epoch 111, Batch 500/1000: LR=9.71e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 111, Batch 1000/1000: LR=9.71e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 111 Train Time 38.60924935340881s

Training epoch 112, Batch 500/1000: LR=9.70e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 112, Batch 1000/1000: LR=9.70e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 112 Train Time 38.602118730545044s

Training epoch 113, Batch 500/1000: LR=9.70e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.27e-01
Training epoch 113, Batch 1000/1000: LR=9.70e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Epoch 113 Train Time 38.618083000183105s

Training epoch 114, Batch 500/1000: LR=9.69e-05, Loss=3.26e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 114, Batch 1000/1000: LR=9.69e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 114 Train Time 38.54842019081116s

Training epoch 115, Batch 500/1000: LR=9.69e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 115, Batch 1000/1000: LR=9.69e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 115 Train Time 38.7374472618103s

Training epoch 116, Batch 500/1000: LR=9.68e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 116, Batch 1000/1000: LR=9.68e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 116 Train Time 38.568562746047974s

Training epoch 117, Batch 500/1000: LR=9.67e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.25e-01
Training epoch 117, Batch 1000/1000: LR=9.67e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 117 Train Time 38.555556774139404s

Training epoch 118, Batch 500/1000: LR=9.67e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 118, Batch 1000/1000: LR=9.67e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 118 Train Time 38.60173773765564s

Training epoch 119, Batch 500/1000: LR=9.66e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 119, Batch 1000/1000: LR=9.66e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 119 Train Time 38.569918632507324s

Training epoch 120, Batch 500/1000: LR=9.66e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 120, Batch 1000/1000: LR=9.66e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 120 Train Time 38.535165548324585s

Training epoch 121, Batch 500/1000: LR=9.65e-05, Loss=3.31e-02 BER=1.34e-02 FER=1.28e-01
Training epoch 121, Batch 1000/1000: LR=9.65e-05, Loss=3.27e-02 BER=1.32e-02 FER=1.26e-01
Epoch 121 Train Time 38.5667998790741s

Training epoch 122, Batch 500/1000: LR=9.65e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 122, Batch 1000/1000: LR=9.65e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Epoch 122 Train Time 38.593931674957275s

Training epoch 123, Batch 500/1000: LR=9.64e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 123, Batch 1000/1000: LR=9.64e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 123 Train Time 38.57087182998657s

Training epoch 124, Batch 500/1000: LR=9.64e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 124, Batch 1000/1000: LR=9.64e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 124 Train Time 38.61858558654785s

Training epoch 125, Batch 500/1000: LR=9.63e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 125, Batch 1000/1000: LR=9.63e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 125 Train Time 38.599716901779175s

Training epoch 126, Batch 500/1000: LR=9.62e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 126, Batch 1000/1000: LR=9.62e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Epoch 126 Train Time 38.56518006324768s

Training epoch 127, Batch 500/1000: LR=9.62e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 127, Batch 1000/1000: LR=9.62e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 127 Train Time 38.58199882507324s

Training epoch 128, Batch 500/1000: LR=9.61e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 128, Batch 1000/1000: LR=9.61e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Epoch 128 Train Time 38.54033136367798s

Training epoch 129, Batch 500/1000: LR=9.61e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 129, Batch 1000/1000: LR=9.61e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 129 Train Time 38.55683875083923s

Training epoch 130, Batch 500/1000: LR=9.60e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 130, Batch 1000/1000: LR=9.60e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 130 Train Time 38.59931254386902s

Training epoch 131, Batch 500/1000: LR=9.59e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 131, Batch 1000/1000: LR=9.59e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 131 Train Time 38.54686760902405s

Training epoch 132, Batch 500/1000: LR=9.59e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 132, Batch 1000/1000: LR=9.59e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 132 Train Time 38.53987169265747s

Training epoch 133, Batch 500/1000: LR=9.58e-05, Loss=3.22e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 133, Batch 1000/1000: LR=9.58e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.23e-01
Epoch 133 Train Time 38.58954048156738s

Training epoch 134, Batch 500/1000: LR=9.57e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 134, Batch 1000/1000: LR=9.57e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 134 Train Time 38.637173652648926s

Training epoch 135, Batch 500/1000: LR=9.57e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 135, Batch 1000/1000: LR=9.57e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Epoch 135 Train Time 38.55606961250305s

Training epoch 136, Batch 500/1000: LR=9.56e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Training epoch 136, Batch 1000/1000: LR=9.56e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 136 Train Time 38.558719873428345s

Training epoch 137, Batch 500/1000: LR=9.56e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 137, Batch 1000/1000: LR=9.56e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 137 Train Time 38.594616651535034s

Training epoch 138, Batch 500/1000: LR=9.55e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 138, Batch 1000/1000: LR=9.55e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Epoch 138 Train Time 38.55905866622925s

Training epoch 139, Batch 500/1000: LR=9.54e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 139, Batch 1000/1000: LR=9.54e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.23e-01
Epoch 139 Train Time 38.549710750579834s

Training epoch 140, Batch 500/1000: LR=9.54e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 140, Batch 1000/1000: LR=9.54e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 140 Train Time 38.55428457260132s

Training epoch 141, Batch 500/1000: LR=9.53e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 141, Batch 1000/1000: LR=9.53e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 141 Train Time 38.579853534698486s

Training epoch 142, Batch 500/1000: LR=9.52e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 142, Batch 1000/1000: LR=9.52e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 142 Train Time 38.57184100151062s

Training epoch 143, Batch 500/1000: LR=9.52e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 143, Batch 1000/1000: LR=9.52e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 143 Train Time 38.6405086517334s

Training epoch 144, Batch 500/1000: LR=9.51e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 144, Batch 1000/1000: LR=9.51e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Epoch 144 Train Time 69.49013638496399s

Training epoch 145, Batch 500/1000: LR=9.50e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Training epoch 145, Batch 1000/1000: LR=9.50e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Epoch 145 Train Time 39.292651891708374s

Training epoch 146, Batch 500/1000: LR=9.50e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 146, Batch 1000/1000: LR=9.50e-05, Loss=3.23e-02 BER=1.31e-02 FER=1.24e-01
Epoch 146 Train Time 38.94445276260376s

Training epoch 147, Batch 500/1000: LR=9.49e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.25e-01
Training epoch 147, Batch 1000/1000: LR=9.49e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.24e-01
Epoch 147 Train Time 38.92415809631348s

Training epoch 148, Batch 500/1000: LR=9.48e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 148, Batch 1000/1000: LR=9.48e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 148 Train Time 38.93322229385376s

Training epoch 149, Batch 500/1000: LR=9.47e-05, Loss=3.23e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 149, Batch 1000/1000: LR=9.47e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.22e-01
Epoch 149 Train Time 38.8945746421814s

Training epoch 150, Batch 500/1000: LR=9.47e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 150, Batch 1000/1000: LR=9.47e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 150 Train Time 38.938368797302246s

Training epoch 151, Batch 500/1000: LR=9.46e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 151, Batch 1000/1000: LR=9.46e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Epoch 151 Train Time 38.91772532463074s

Training epoch 152, Batch 500/1000: LR=9.45e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 152, Batch 1000/1000: LR=9.45e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Epoch 152 Train Time 38.90985059738159s

Training epoch 153, Batch 500/1000: LR=9.45e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 153, Batch 1000/1000: LR=9.45e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 153 Train Time 38.59302473068237s

Training epoch 154, Batch 500/1000: LR=9.44e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 154, Batch 1000/1000: LR=9.44e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Epoch 154 Train Time 38.661747455596924s

Training epoch 155, Batch 500/1000: LR=9.43e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 155, Batch 1000/1000: LR=9.43e-05, Loss=3.21e-02 BER=1.30e-02 FER=1.23e-01
Epoch 155 Train Time 38.517234802246094s

Training epoch 156, Batch 500/1000: LR=9.42e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 156, Batch 1000/1000: LR=9.42e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 156 Train Time 38.513367652893066s

Training epoch 157, Batch 500/1000: LR=9.42e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 157, Batch 1000/1000: LR=9.42e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.23e-01
Epoch 157 Train Time 38.58556246757507s

Training epoch 158, Batch 500/1000: LR=9.41e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 158, Batch 1000/1000: LR=9.41e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 158 Train Time 38.52150559425354s

Training epoch 159, Batch 500/1000: LR=9.40e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 159, Batch 1000/1000: LR=9.40e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Epoch 159 Train Time 38.54610562324524s

Training epoch 160, Batch 500/1000: LR=9.40e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 160, Batch 1000/1000: LR=9.40e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 160 Train Time 38.57619786262512s

Training epoch 161, Batch 500/1000: LR=9.39e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 161, Batch 1000/1000: LR=9.39e-05, Loss=3.18e-02 BER=1.27e-02 FER=1.21e-01
Epoch 161 Train Time 38.57573938369751s

Training epoch 162, Batch 500/1000: LR=9.38e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 162, Batch 1000/1000: LR=9.38e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Epoch 162 Train Time 38.562519788742065s

Training epoch 163, Batch 500/1000: LR=9.37e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 163, Batch 1000/1000: LR=9.37e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 163 Train Time 38.691654682159424s

Training epoch 164, Batch 500/1000: LR=9.37e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 164, Batch 1000/1000: LR=9.37e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 164 Train Time 38.55048227310181s

Training epoch 165, Batch 500/1000: LR=9.36e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 165, Batch 1000/1000: LR=9.36e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 165 Train Time 38.531442403793335s

Training epoch 166, Batch 500/1000: LR=9.35e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 166, Batch 1000/1000: LR=9.35e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 166 Train Time 38.537774324417114s

Training epoch 167, Batch 500/1000: LR=9.34e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 167, Batch 1000/1000: LR=9.34e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Epoch 167 Train Time 38.554213762283325s

Training epoch 168, Batch 500/1000: LR=9.33e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 168, Batch 1000/1000: LR=9.33e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 168 Train Time 38.53861975669861s

Training epoch 169, Batch 500/1000: LR=9.33e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 169, Batch 1000/1000: LR=9.33e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 169 Train Time 38.54196071624756s

Training epoch 170, Batch 500/1000: LR=9.32e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 170, Batch 1000/1000: LR=9.32e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 170 Train Time 38.5444278717041s

Training epoch 171, Batch 500/1000: LR=9.31e-05, Loss=3.16e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 171, Batch 1000/1000: LR=9.31e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Epoch 171 Train Time 38.58015966415405s

Training epoch 172, Batch 500/1000: LR=9.30e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 172, Batch 1000/1000: LR=9.30e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 172 Train Time 38.63936519622803s

Training epoch 173, Batch 500/1000: LR=9.29e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 173, Batch 1000/1000: LR=9.29e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 173 Train Time 38.54862070083618s

Training epoch 174, Batch 500/1000: LR=9.29e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 174, Batch 1000/1000: LR=9.29e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 174 Train Time 38.54344844818115s

Training epoch 175, Batch 500/1000: LR=9.28e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 175, Batch 1000/1000: LR=9.28e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 175 Train Time 38.52671194076538s

Training epoch 176, Batch 500/1000: LR=9.27e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 176, Batch 1000/1000: LR=9.27e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 176 Train Time 38.51047706604004s

Training epoch 177, Batch 500/1000: LR=9.26e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 177, Batch 1000/1000: LR=9.26e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 177 Train Time 38.62960910797119s

Training epoch 178, Batch 500/1000: LR=9.25e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 178, Batch 1000/1000: LR=9.25e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 178 Train Time 38.54420447349548s

Training epoch 179, Batch 500/1000: LR=9.25e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 179, Batch 1000/1000: LR=9.25e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 179 Train Time 38.542314529418945s

Training epoch 180, Batch 500/1000: LR=9.24e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.21e-01
Training epoch 180, Batch 1000/1000: LR=9.24e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Epoch 180 Train Time 38.55438184738159s

Training epoch 181, Batch 500/1000: LR=9.23e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 181, Batch 1000/1000: LR=9.23e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 181 Train Time 38.66880989074707s

Training epoch 182, Batch 500/1000: LR=9.22e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 182, Batch 1000/1000: LR=9.22e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.19e-01
Epoch 182 Train Time 38.5540554523468s

Training epoch 183, Batch 500/1000: LR=9.21e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 183, Batch 1000/1000: LR=9.21e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 183 Train Time 38.54337668418884s

Training epoch 184, Batch 500/1000: LR=9.20e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 184, Batch 1000/1000: LR=9.20e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Epoch 184 Train Time 38.50043320655823s

Training epoch 185, Batch 500/1000: LR=9.20e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 185, Batch 1000/1000: LR=9.20e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 185 Train Time 38.55067992210388s

Training epoch 186, Batch 500/1000: LR=9.19e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 186, Batch 1000/1000: LR=9.19e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 186 Train Time 38.536558628082275s

Training epoch 187, Batch 500/1000: LR=9.18e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 187, Batch 1000/1000: LR=9.18e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.19e-01
Epoch 187 Train Time 38.514615535736084s

Training epoch 188, Batch 500/1000: LR=9.17e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 188, Batch 1000/1000: LR=9.17e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.18e-01
Epoch 188 Train Time 38.552032470703125s

Training epoch 189, Batch 500/1000: LR=9.16e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 189, Batch 1000/1000: LR=9.16e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 189 Train Time 38.52217721939087s

Training epoch 190, Batch 500/1000: LR=9.15e-05, Loss=3.14e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 190, Batch 1000/1000: LR=9.15e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 190 Train Time 38.668720722198486s

Training epoch 191, Batch 500/1000: LR=9.14e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 191, Batch 1000/1000: LR=9.14e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 191 Train Time 86.75950503349304s

Training epoch 192, Batch 500/1000: LR=9.14e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.21e-01
Training epoch 192, Batch 1000/1000: LR=9.14e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 192 Train Time 39.281001806259155s

Training epoch 193, Batch 500/1000: LR=9.13e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 193, Batch 1000/1000: LR=9.13e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 193 Train Time 38.95317625999451s

Training epoch 194, Batch 500/1000: LR=9.12e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 194, Batch 1000/1000: LR=9.12e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 194 Train Time 38.91783094406128s

Training epoch 195, Batch 500/1000: LR=9.11e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 195, Batch 1000/1000: LR=9.11e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 195 Train Time 38.90103316307068s

Training epoch 196, Batch 500/1000: LR=9.10e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 196, Batch 1000/1000: LR=9.10e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 196 Train Time 38.911237716674805s

Training epoch 197, Batch 500/1000: LR=9.09e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 197, Batch 1000/1000: LR=9.09e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.20e-01
Epoch 197 Train Time 38.95053577423096s

Training epoch 198, Batch 500/1000: LR=9.08e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 198, Batch 1000/1000: LR=9.08e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 198 Train Time 38.97420954704285s

Training epoch 199, Batch 500/1000: LR=9.07e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 199, Batch 1000/1000: LR=9.07e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 199 Train Time 38.8971164226532s

Training epoch 200, Batch 500/1000: LR=9.06e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 200, Batch 1000/1000: LR=9.06e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 200 Train Time 38.673457860946655s

Training epoch 201, Batch 500/1000: LR=9.05e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 201, Batch 1000/1000: LR=9.05e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 201 Train Time 38.96579647064209s

Training epoch 202, Batch 500/1000: LR=9.05e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 202, Batch 1000/1000: LR=9.05e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 202 Train Time 38.58430528640747s

Training epoch 203, Batch 500/1000: LR=9.04e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 203, Batch 1000/1000: LR=9.04e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 203 Train Time 38.54607152938843s

Training epoch 204, Batch 500/1000: LR=9.03e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 204, Batch 1000/1000: LR=9.03e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 204 Train Time 38.51103138923645s

Training epoch 205, Batch 500/1000: LR=9.02e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 205, Batch 1000/1000: LR=9.02e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 205 Train Time 38.53703689575195s

Training epoch 206, Batch 500/1000: LR=9.01e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 206, Batch 1000/1000: LR=9.01e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 206 Train Time 38.51669454574585s

Training epoch 207, Batch 500/1000: LR=9.00e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 207, Batch 1000/1000: LR=9.00e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 207 Train Time 38.72076988220215s

Training epoch 208, Batch 500/1000: LR=8.99e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 208, Batch 1000/1000: LR=8.99e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 208 Train Time 38.573182582855225s

Training epoch 209, Batch 500/1000: LR=8.98e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 209, Batch 1000/1000: LR=8.98e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.19e-01
Epoch 209 Train Time 38.47661566734314s

Training epoch 210, Batch 500/1000: LR=8.97e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 210, Batch 1000/1000: LR=8.97e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 210 Train Time 38.511927127838135s

Training epoch 211, Batch 500/1000: LR=8.96e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.18e-01
Training epoch 211, Batch 1000/1000: LR=8.96e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 211 Train Time 38.50685262680054s

Training epoch 212, Batch 500/1000: LR=8.95e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 212, Batch 1000/1000: LR=8.95e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Epoch 212 Train Time 38.51201272010803s

Training epoch 213, Batch 500/1000: LR=8.94e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 213, Batch 1000/1000: LR=8.94e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 213 Train Time 38.942566871643066s

Training epoch 214, Batch 500/1000: LR=8.93e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 214, Batch 1000/1000: LR=8.93e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 214 Train Time 38.68445634841919s

Training epoch 215, Batch 500/1000: LR=8.92e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 215, Batch 1000/1000: LR=8.92e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 215 Train Time 38.89531230926514s

Training epoch 216, Batch 500/1000: LR=8.91e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 216, Batch 1000/1000: LR=8.91e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 216 Train Time 38.68088984489441s

Training epoch 217, Batch 500/1000: LR=8.90e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 217, Batch 1000/1000: LR=8.90e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.18e-01
Epoch 217 Train Time 38.5189483165741s

Training epoch 218, Batch 500/1000: LR=8.89e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 218, Batch 1000/1000: LR=8.89e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 218 Train Time 38.50953674316406s

Training epoch 219, Batch 500/1000: LR=8.88e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 219, Batch 1000/1000: LR=8.88e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 219 Train Time 38.499138593673706s

Training epoch 220, Batch 500/1000: LR=8.87e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 220, Batch 1000/1000: LR=8.87e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 220 Train Time 38.52210998535156s

Training epoch 221, Batch 500/1000: LR=8.86e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 221, Batch 1000/1000: LR=8.86e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 221 Train Time 38.52732062339783s

Training epoch 222, Batch 500/1000: LR=8.85e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 222, Batch 1000/1000: LR=8.85e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 222 Train Time 38.51829934120178s

Training epoch 223, Batch 500/1000: LR=8.84e-05, Loss=3.15e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 223, Batch 1000/1000: LR=8.84e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.19e-01
Epoch 223 Train Time 38.584105014801025s

Training epoch 224, Batch 500/1000: LR=8.83e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 224, Batch 1000/1000: LR=8.83e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 224 Train Time 38.54484009742737s

Training epoch 225, Batch 500/1000: LR=8.82e-05, Loss=3.03e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 225, Batch 1000/1000: LR=8.82e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 225 Train Time 38.62286710739136s

Training epoch 226, Batch 500/1000: LR=8.81e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 226, Batch 1000/1000: LR=8.81e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 226 Train Time 38.51243448257446s

Training epoch 227, Batch 500/1000: LR=8.80e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 227, Batch 1000/1000: LR=8.80e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 227 Train Time 38.51911377906799s

Training epoch 228, Batch 500/1000: LR=8.79e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 228, Batch 1000/1000: LR=8.79e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 228 Train Time 38.520195960998535s

Training epoch 229, Batch 500/1000: LR=8.78e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 229, Batch 1000/1000: LR=8.78e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 229 Train Time 38.532681703567505s

Training epoch 230, Batch 500/1000: LR=8.77e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 230, Batch 1000/1000: LR=8.77e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 230 Train Time 38.50515842437744s

Training epoch 231, Batch 500/1000: LR=8.76e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.19e-01
Training epoch 231, Batch 1000/1000: LR=8.76e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.19e-01
Epoch 231 Train Time 38.48594880104065s

Training epoch 232, Batch 500/1000: LR=8.75e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 232, Batch 1000/1000: LR=8.75e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 232 Train Time 38.530797243118286s

Training epoch 233, Batch 500/1000: LR=8.74e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 233, Batch 1000/1000: LR=8.74e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 233 Train Time 38.5079607963562s

Training epoch 234, Batch 500/1000: LR=8.73e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 234, Batch 1000/1000: LR=8.73e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Epoch 234 Train Time 38.61652207374573s

Training epoch 235, Batch 500/1000: LR=8.72e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 235, Batch 1000/1000: LR=8.72e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 235 Train Time 38.52952265739441s

Training epoch 236, Batch 500/1000: LR=8.71e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 236, Batch 1000/1000: LR=8.71e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 236 Train Time 38.478920698165894s

Training epoch 237, Batch 500/1000: LR=8.70e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 237, Batch 1000/1000: LR=8.70e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 237 Train Time 38.50829339027405s

Training epoch 238, Batch 500/1000: LR=8.69e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 238, Batch 1000/1000: LR=8.69e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 238 Train Time 57.415143728256226s

Training epoch 239, Batch 500/1000: LR=8.68e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 239, Batch 1000/1000: LR=8.68e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 239 Train Time 39.44597411155701s

Training epoch 240, Batch 500/1000: LR=8.67e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 240, Batch 1000/1000: LR=8.67e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 240 Train Time 39.05519962310791s

Training epoch 241, Batch 500/1000: LR=8.66e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 241, Batch 1000/1000: LR=8.66e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 241 Train Time 38.941261768341064s

Training epoch 242, Batch 500/1000: LR=8.65e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 242, Batch 1000/1000: LR=8.65e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 242 Train Time 38.975314140319824s

Training epoch 243, Batch 500/1000: LR=8.64e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 243, Batch 1000/1000: LR=8.64e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 243 Train Time 39.06580710411072s

Training epoch 244, Batch 500/1000: LR=8.63e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 244, Batch 1000/1000: LR=8.63e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 244 Train Time 38.940572023391724s

Training epoch 245, Batch 500/1000: LR=8.62e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 245, Batch 1000/1000: LR=8.62e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 245 Train Time 38.92280316352844s

Training epoch 246, Batch 500/1000: LR=8.60e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 246, Batch 1000/1000: LR=8.60e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Epoch 246 Train Time 38.78412961959839s

Training epoch 247, Batch 500/1000: LR=8.59e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 247, Batch 1000/1000: LR=8.59e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 247 Train Time 38.55296730995178s

Training epoch 248, Batch 500/1000: LR=8.58e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 248, Batch 1000/1000: LR=8.58e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Epoch 248 Train Time 38.53488206863403s

Training epoch 249, Batch 500/1000: LR=8.57e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 249, Batch 1000/1000: LR=8.57e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 249 Train Time 38.510632276535034s

Training epoch 250, Batch 500/1000: LR=8.56e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 250, Batch 1000/1000: LR=8.56e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 250 Train Time 38.54795503616333s

Training epoch 251, Batch 500/1000: LR=8.55e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 251, Batch 1000/1000: LR=8.55e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 251 Train Time 38.5495069026947s

Training epoch 252, Batch 500/1000: LR=8.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 252, Batch 1000/1000: LR=8.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 252 Train Time 38.52134466171265s

Training epoch 253, Batch 500/1000: LR=8.53e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 253, Batch 1000/1000: LR=8.53e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 253 Train Time 38.59025025367737s

Training epoch 254, Batch 500/1000: LR=8.52e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 254, Batch 1000/1000: LR=8.52e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 254 Train Time 38.653112173080444s

Training epoch 255, Batch 500/1000: LR=8.51e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 255, Batch 1000/1000: LR=8.51e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 255 Train Time 38.7567412853241s

Training epoch 256, Batch 500/1000: LR=8.49e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 256, Batch 1000/1000: LR=8.49e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 256 Train Time 38.57289457321167s

Training epoch 257, Batch 500/1000: LR=8.48e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 257, Batch 1000/1000: LR=8.48e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 257 Train Time 38.58271145820618s

Training epoch 258, Batch 500/1000: LR=8.47e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 258, Batch 1000/1000: LR=8.47e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 258 Train Time 38.52780508995056s

Training epoch 259, Batch 500/1000: LR=8.46e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 259, Batch 1000/1000: LR=8.46e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 259 Train Time 38.522313594818115s

Training epoch 260, Batch 500/1000: LR=8.45e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 260, Batch 1000/1000: LR=8.45e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 260 Train Time 38.552188873291016s

Training epoch 261, Batch 500/1000: LR=8.44e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 261, Batch 1000/1000: LR=8.44e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Epoch 261 Train Time 38.55356025695801s

Training epoch 262, Batch 500/1000: LR=8.43e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 262, Batch 1000/1000: LR=8.43e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 262 Train Time 38.58068776130676s

Training epoch 263, Batch 500/1000: LR=8.42e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 263, Batch 1000/1000: LR=8.42e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 263 Train Time 38.57422399520874s

Training epoch 264, Batch 500/1000: LR=8.40e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 264, Batch 1000/1000: LR=8.40e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 264 Train Time 38.55219507217407s

Training epoch 265, Batch 500/1000: LR=8.39e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 265, Batch 1000/1000: LR=8.39e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 265 Train Time 38.672155141830444s

Training epoch 266, Batch 500/1000: LR=8.38e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 266, Batch 1000/1000: LR=8.38e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 266 Train Time 38.54516649246216s

Training epoch 267, Batch 500/1000: LR=8.37e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 267, Batch 1000/1000: LR=8.37e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 267 Train Time 38.578266620635986s

Training epoch 268, Batch 500/1000: LR=8.36e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 268, Batch 1000/1000: LR=8.36e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 268 Train Time 38.536097288131714s

Training epoch 269, Batch 500/1000: LR=8.35e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 269, Batch 1000/1000: LR=8.35e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 269 Train Time 38.56578040122986s

Training epoch 270, Batch 500/1000: LR=8.34e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 270, Batch 1000/1000: LR=8.34e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Epoch 270 Train Time 38.61142897605896s

Training epoch 271, Batch 500/1000: LR=8.32e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 271, Batch 1000/1000: LR=8.32e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 271 Train Time 38.562517404556274s

Training epoch 272, Batch 500/1000: LR=8.31e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 272, Batch 1000/1000: LR=8.31e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 272 Train Time 38.551936864852905s

Training epoch 273, Batch 500/1000: LR=8.30e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 273, Batch 1000/1000: LR=8.30e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 273 Train Time 38.516870975494385s

Training epoch 274, Batch 500/1000: LR=8.29e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 274, Batch 1000/1000: LR=8.29e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 274 Train Time 38.58033466339111s

Training epoch 275, Batch 500/1000: LR=8.28e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 275, Batch 1000/1000: LR=8.28e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 275 Train Time 38.509255170822144s

Training epoch 276, Batch 500/1000: LR=8.26e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 276, Batch 1000/1000: LR=8.26e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Epoch 276 Train Time 38.537049293518066s

Training epoch 277, Batch 500/1000: LR=8.25e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 277, Batch 1000/1000: LR=8.25e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 277 Train Time 38.552239418029785s

Training epoch 278, Batch 500/1000: LR=8.24e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 278, Batch 1000/1000: LR=8.24e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.17e-01
Epoch 278 Train Time 38.53853392601013s

Training epoch 279, Batch 500/1000: LR=8.23e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 279, Batch 1000/1000: LR=8.23e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 279 Train Time 38.53353548049927s

Training epoch 280, Batch 500/1000: LR=8.22e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 280, Batch 1000/1000: LR=8.22e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 280 Train Time 38.520052433013916s

Training epoch 281, Batch 500/1000: LR=8.21e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 281, Batch 1000/1000: LR=8.21e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 281 Train Time 38.53655695915222s

Training epoch 282, Batch 500/1000: LR=8.19e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 282, Batch 1000/1000: LR=8.19e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 282 Train Time 39.50584292411804s

Training epoch 283, Batch 500/1000: LR=8.18e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 283, Batch 1000/1000: LR=8.18e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 283 Train Time 38.97317123413086s

Training epoch 284, Batch 500/1000: LR=8.17e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 284, Batch 1000/1000: LR=8.17e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.16e-01
Epoch 284 Train Time 38.840312004089355s

Training epoch 285, Batch 500/1000: LR=8.16e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 285, Batch 1000/1000: LR=8.16e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 285 Train Time 38.82278919219971s

Training epoch 286, Batch 500/1000: LR=8.14e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 286, Batch 1000/1000: LR=8.14e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Epoch 286 Train Time 38.91810369491577s

Training epoch 287, Batch 500/1000: LR=8.13e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 287, Batch 1000/1000: LR=8.13e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 287 Train Time 38.78465747833252s

Training epoch 288, Batch 500/1000: LR=8.12e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 288, Batch 1000/1000: LR=8.12e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 288 Train Time 38.86341953277588s

Training epoch 289, Batch 500/1000: LR=8.11e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 289, Batch 1000/1000: LR=8.11e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 289 Train Time 38.814443588256836s

Training epoch 290, Batch 500/1000: LR=8.10e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 290, Batch 1000/1000: LR=8.10e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 290 Train Time 38.83090877532959s

Training epoch 291, Batch 500/1000: LR=8.08e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 291, Batch 1000/1000: LR=8.08e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 291 Train Time 38.81984782218933s

Training epoch 292, Batch 500/1000: LR=8.07e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 292, Batch 1000/1000: LR=8.07e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 292 Train Time 38.95716047286987s

Training epoch 293, Batch 500/1000: LR=8.06e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 293, Batch 1000/1000: LR=8.06e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 293 Train Time 38.95759439468384s

Training epoch 294, Batch 500/1000: LR=8.05e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 294, Batch 1000/1000: LR=8.05e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 294 Train Time 38.85444712638855s

Training epoch 295, Batch 500/1000: LR=8.03e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 295, Batch 1000/1000: LR=8.03e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 295 Train Time 38.880738496780396s

Training epoch 296, Batch 500/1000: LR=8.02e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 296, Batch 1000/1000: LR=8.02e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 296 Train Time 38.60705351829529s

Training epoch 297, Batch 500/1000: LR=8.01e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 297, Batch 1000/1000: LR=8.01e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 297 Train Time 38.608195543289185s

Training epoch 298, Batch 500/1000: LR=8.00e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.17e-01
Training epoch 298, Batch 1000/1000: LR=8.00e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 298 Train Time 38.61237859725952s

Training epoch 299, Batch 500/1000: LR=7.98e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 299, Batch 1000/1000: LR=7.98e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 299 Train Time 38.6775586605072s

Training epoch 300, Batch 500/1000: LR=7.97e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 300, Batch 1000/1000: LR=7.97e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Epoch 300 Train Time 38.58775448799133s


Test Loss 4: 9.58e-03 5: 1.07e-03 6: 4.84e-05
Test FER 4: 4.31e-02 5: 4.83e-03 6: 2.35e-04
Test BER 4: 3.46e-03 5: 3.37e-04 6: 1.14e-05
Test -ln(BER) 4: 5.67e+00 5: 8.00e+00 6: 1.14e+01
# of testing samples: [100352.0, 100352.0, 430080.0]
 Test Time 116.6386513710022 s

Training epoch 301, Batch 500/1000: LR=7.96e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 301, Batch 1000/1000: LR=7.96e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.17e-01
Epoch 301 Train Time 38.57581686973572s

Training epoch 302, Batch 500/1000: LR=7.95e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 302, Batch 1000/1000: LR=7.95e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 302 Train Time 38.634472608566284s

Training epoch 303, Batch 500/1000: LR=7.93e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 303, Batch 1000/1000: LR=7.93e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 303 Train Time 38.59475588798523s

Training epoch 304, Batch 500/1000: LR=7.92e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 304, Batch 1000/1000: LR=7.92e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 304 Train Time 38.695180892944336s

Training epoch 305, Batch 500/1000: LR=7.91e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 305, Batch 1000/1000: LR=7.91e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 305 Train Time 40.36839270591736s

Training epoch 306, Batch 500/1000: LR=7.90e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 306, Batch 1000/1000: LR=7.90e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 306 Train Time 38.559245347976685s

Training epoch 307, Batch 500/1000: LR=7.88e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 307, Batch 1000/1000: LR=7.88e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 307 Train Time 38.590709924697876s

Training epoch 308, Batch 500/1000: LR=7.87e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 308, Batch 1000/1000: LR=7.87e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 308 Train Time 38.65807843208313s

Training epoch 309, Batch 500/1000: LR=7.86e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 309, Batch 1000/1000: LR=7.86e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 309 Train Time 38.57089614868164s

Training epoch 310, Batch 500/1000: LR=7.85e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 310, Batch 1000/1000: LR=7.85e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.16e-01
Epoch 310 Train Time 38.5649950504303s

Training epoch 311, Batch 500/1000: LR=7.83e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 311, Batch 1000/1000: LR=7.83e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 311 Train Time 38.54430818557739s

Training epoch 312, Batch 500/1000: LR=7.82e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.17e-01
Training epoch 312, Batch 1000/1000: LR=7.82e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Epoch 312 Train Time 38.55821657180786s

Training epoch 313, Batch 500/1000: LR=7.81e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 313, Batch 1000/1000: LR=7.81e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 313 Train Time 38.576557874679565s

Training epoch 314, Batch 500/1000: LR=7.79e-05, Loss=3.04e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 314, Batch 1000/1000: LR=7.79e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 314 Train Time 38.61573553085327s

Training epoch 315, Batch 500/1000: LR=7.78e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 315, Batch 1000/1000: LR=7.78e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 315 Train Time 38.5757577419281s

Training epoch 316, Batch 500/1000: LR=7.77e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 316, Batch 1000/1000: LR=7.77e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 316 Train Time 38.58978605270386s

Training epoch 317, Batch 500/1000: LR=7.75e-05, Loss=3.12e-02 BER=1.27e-02 FER=1.18e-01
Training epoch 317, Batch 1000/1000: LR=7.75e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 317 Train Time 38.695178508758545s

Training epoch 318, Batch 500/1000: LR=7.74e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 318, Batch 1000/1000: LR=7.74e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 318 Train Time 38.564226388931274s

Training epoch 319, Batch 500/1000: LR=7.73e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 319, Batch 1000/1000: LR=7.73e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 319 Train Time 38.563847064971924s

Training epoch 320, Batch 500/1000: LR=7.72e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 320, Batch 1000/1000: LR=7.72e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 320 Train Time 38.57571458816528s

Training epoch 321, Batch 500/1000: LR=7.70e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 321, Batch 1000/1000: LR=7.70e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 321 Train Time 38.56437826156616s

Training epoch 322, Batch 500/1000: LR=7.69e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 322, Batch 1000/1000: LR=7.69e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 322 Train Time 38.553237199783325s

Training epoch 323, Batch 500/1000: LR=7.68e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 323, Batch 1000/1000: LR=7.68e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 323 Train Time 38.578856468200684s

Training epoch 324, Batch 500/1000: LR=7.66e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 324, Batch 1000/1000: LR=7.66e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 324 Train Time 38.54261255264282s

Training epoch 325, Batch 500/1000: LR=7.65e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 325, Batch 1000/1000: LR=7.65e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.14e-01
Epoch 325 Train Time 38.567184925079346s

Training epoch 326, Batch 500/1000: LR=7.64e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 326, Batch 1000/1000: LR=7.64e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 326 Train Time 38.57335877418518s

Training epoch 327, Batch 500/1000: LR=7.62e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 327, Batch 1000/1000: LR=7.62e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.16e-01
Epoch 327 Train Time 38.65307331085205s

Training epoch 328, Batch 500/1000: LR=7.61e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 328, Batch 1000/1000: LR=7.61e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 328 Train Time 38.56914663314819s

Training epoch 329, Batch 500/1000: LR=7.60e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 329, Batch 1000/1000: LR=7.60e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 329 Train Time 38.62864303588867s

Training epoch 330, Batch 500/1000: LR=7.58e-05, Loss=3.04e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 330, Batch 1000/1000: LR=7.58e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Epoch 330 Train Time 38.59148073196411s

Training epoch 331, Batch 500/1000: LR=7.57e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 331, Batch 1000/1000: LR=7.57e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 331 Train Time 38.57529830932617s

Training epoch 332, Batch 500/1000: LR=7.56e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 332, Batch 1000/1000: LR=7.56e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 332 Train Time 38.561169147491455s

Training epoch 333, Batch 500/1000: LR=7.54e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 333, Batch 1000/1000: LR=7.54e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 333 Train Time 38.55945801734924s

Training epoch 334, Batch 500/1000: LR=7.53e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.15e-01
Training epoch 334, Batch 1000/1000: LR=7.53e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 334 Train Time 38.53672409057617s

Training epoch 335, Batch 500/1000: LR=7.52e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 335, Batch 1000/1000: LR=7.52e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 335 Train Time 38.58895468711853s

Training epoch 336, Batch 500/1000: LR=7.50e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 336, Batch 1000/1000: LR=7.50e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 336 Train Time 38.65505909919739s

Training epoch 337, Batch 500/1000: LR=7.49e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 337, Batch 1000/1000: LR=7.49e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 337 Train Time 70.63024258613586s

Training epoch 338, Batch 500/1000: LR=7.48e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 338, Batch 1000/1000: LR=7.48e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 338 Train Time 39.111467123031616s

Training epoch 339, Batch 500/1000: LR=7.46e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 339, Batch 1000/1000: LR=7.46e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 339 Train Time 38.748146533966064s

Training epoch 340, Batch 500/1000: LR=7.45e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 340, Batch 1000/1000: LR=7.45e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 340 Train Time 38.54732346534729s

Training epoch 341, Batch 500/1000: LR=7.43e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 341, Batch 1000/1000: LR=7.43e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 341 Train Time 38.54253149032593s

Training epoch 342, Batch 500/1000: LR=7.42e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 342, Batch 1000/1000: LR=7.42e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 342 Train Time 38.55086016654968s

Training epoch 343, Batch 500/1000: LR=7.41e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 343, Batch 1000/1000: LR=7.41e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 343 Train Time 38.557663679122925s

Training epoch 344, Batch 500/1000: LR=7.39e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 344, Batch 1000/1000: LR=7.39e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 344 Train Time 38.715370655059814s

Training epoch 345, Batch 500/1000: LR=7.38e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 345, Batch 1000/1000: LR=7.38e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 345 Train Time 38.60841131210327s

Training epoch 346, Batch 500/1000: LR=7.37e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 346, Batch 1000/1000: LR=7.37e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 346 Train Time 38.5430006980896s

Training epoch 347, Batch 500/1000: LR=7.35e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 347, Batch 1000/1000: LR=7.35e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 347 Train Time 38.511826515197754s

Training epoch 348, Batch 500/1000: LR=7.34e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 348, Batch 1000/1000: LR=7.34e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 348 Train Time 38.55584454536438s

Training epoch 349, Batch 500/1000: LR=7.32e-05, Loss=3.04e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 349, Batch 1000/1000: LR=7.32e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 349 Train Time 38.54141688346863s

Training epoch 350, Batch 500/1000: LR=7.31e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 350, Batch 1000/1000: LR=7.31e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 350 Train Time 38.53033113479614s

Training epoch 351, Batch 500/1000: LR=7.30e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 351, Batch 1000/1000: LR=7.30e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 351 Train Time 38.543384075164795s

Training epoch 352, Batch 500/1000: LR=7.28e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 352, Batch 1000/1000: LR=7.28e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 352 Train Time 38.564810037612915s

Training epoch 353, Batch 500/1000: LR=7.27e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 353, Batch 1000/1000: LR=7.27e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 353 Train Time 38.61465001106262s

Training epoch 354, Batch 500/1000: LR=7.26e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 354, Batch 1000/1000: LR=7.26e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 354 Train Time 38.59302759170532s

Training epoch 355, Batch 500/1000: LR=7.24e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 355, Batch 1000/1000: LR=7.24e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 355 Train Time 38.54171824455261s

Training epoch 356, Batch 500/1000: LR=7.23e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 356, Batch 1000/1000: LR=7.23e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 356 Train Time 38.57977271080017s

Training epoch 357, Batch 500/1000: LR=7.21e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 357, Batch 1000/1000: LR=7.21e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 357 Train Time 38.68095588684082s

Training epoch 358, Batch 500/1000: LR=7.20e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 358, Batch 1000/1000: LR=7.20e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 358 Train Time 38.53682613372803s

Training epoch 359, Batch 500/1000: LR=7.19e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 359, Batch 1000/1000: LR=7.19e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 359 Train Time 38.534998655319214s

Training epoch 360, Batch 500/1000: LR=7.17e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 360, Batch 1000/1000: LR=7.17e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 360 Train Time 38.60399651527405s

Training epoch 361, Batch 500/1000: LR=7.16e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 361, Batch 1000/1000: LR=7.16e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 361 Train Time 38.51949095726013s

Training epoch 362, Batch 500/1000: LR=7.14e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.15e-01
Training epoch 362, Batch 1000/1000: LR=7.14e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 362 Train Time 38.554290533065796s

Training epoch 363, Batch 500/1000: LR=7.13e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 363, Batch 1000/1000: LR=7.13e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 363 Train Time 38.548004388809204s

Training epoch 364, Batch 500/1000: LR=7.12e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 364, Batch 1000/1000: LR=7.12e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 364 Train Time 38.54447865486145s

Training epoch 365, Batch 500/1000: LR=7.10e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 365, Batch 1000/1000: LR=7.10e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 365 Train Time 38.55991816520691s

Training epoch 366, Batch 500/1000: LR=7.09e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 366, Batch 1000/1000: LR=7.09e-05, Loss=2.98e-02 BER=1.19e-02 FER=1.12e-01
Epoch 366 Train Time 38.67707133293152s

Training epoch 367, Batch 500/1000: LR=7.07e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 367, Batch 1000/1000: LR=7.07e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 367 Train Time 38.57392144203186s

Training epoch 368, Batch 500/1000: LR=7.06e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 368, Batch 1000/1000: LR=7.06e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 368 Train Time 38.562091588974s

Training epoch 369, Batch 500/1000: LR=7.04e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 369, Batch 1000/1000: LR=7.04e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Epoch 369 Train Time 38.52669167518616s

Training epoch 370, Batch 500/1000: LR=7.03e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 370, Batch 1000/1000: LR=7.03e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 370 Train Time 38.52668356895447s

Training epoch 371, Batch 500/1000: LR=7.02e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 371, Batch 1000/1000: LR=7.02e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 371 Train Time 38.53216075897217s

Training epoch 372, Batch 500/1000: LR=7.00e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 372, Batch 1000/1000: LR=7.00e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 372 Train Time 38.52844953536987s

Training epoch 373, Batch 500/1000: LR=6.99e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 373, Batch 1000/1000: LR=6.99e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 373 Train Time 38.54996347427368s

Training epoch 374, Batch 500/1000: LR=6.97e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 374, Batch 1000/1000: LR=6.97e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 374 Train Time 38.5418598651886s

Training epoch 375, Batch 500/1000: LR=6.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 375, Batch 1000/1000: LR=6.96e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 375 Train Time 38.68876671791077s

Training epoch 376, Batch 500/1000: LR=6.94e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 376, Batch 1000/1000: LR=6.94e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 376 Train Time 38.630356550216675s

Training epoch 377, Batch 500/1000: LR=6.93e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 377, Batch 1000/1000: LR=6.93e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Epoch 377 Train Time 38.51031303405762s

Training epoch 378, Batch 500/1000: LR=6.92e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 378, Batch 1000/1000: LR=6.92e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 378 Train Time 38.52709627151489s

Training epoch 379, Batch 500/1000: LR=6.90e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 379, Batch 1000/1000: LR=6.90e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 379 Train Time 38.54942560195923s

Training epoch 380, Batch 500/1000: LR=6.89e-05, Loss=3.06e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 380, Batch 1000/1000: LR=6.89e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.16e-01
Epoch 380 Train Time 38.54628324508667s

Training epoch 381, Batch 500/1000: LR=6.87e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 381, Batch 1000/1000: LR=6.87e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 381 Train Time 38.53932332992554s

Training epoch 382, Batch 500/1000: LR=6.86e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 382, Batch 1000/1000: LR=6.86e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 382 Train Time 38.55805015563965s

Training epoch 383, Batch 500/1000: LR=6.84e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 383, Batch 1000/1000: LR=6.84e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 383 Train Time 38.54632234573364s

Training epoch 384, Batch 500/1000: LR=6.83e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 384, Batch 1000/1000: LR=6.83e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.13e-01
Epoch 384 Train Time 56.029953718185425s

Training epoch 385, Batch 500/1000: LR=6.81e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 385, Batch 1000/1000: LR=6.81e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 385 Train Time 39.24487066268921s

Training epoch 386, Batch 500/1000: LR=6.80e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 386, Batch 1000/1000: LR=6.80e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Epoch 386 Train Time 38.94659209251404s

Training epoch 387, Batch 500/1000: LR=6.79e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 387, Batch 1000/1000: LR=6.79e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 387 Train Time 38.92152237892151s

Training epoch 388, Batch 500/1000: LR=6.77e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 388, Batch 1000/1000: LR=6.77e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 388 Train Time 38.91307592391968s

Training epoch 389, Batch 500/1000: LR=6.76e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 389, Batch 1000/1000: LR=6.76e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 389 Train Time 38.918007612228394s

Training epoch 390, Batch 500/1000: LR=6.74e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 390, Batch 1000/1000: LR=6.74e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 390 Train Time 38.89659667015076s

Training epoch 391, Batch 500/1000: LR=6.73e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 391, Batch 1000/1000: LR=6.73e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 391 Train Time 38.96853756904602s

Training epoch 392, Batch 500/1000: LR=6.71e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 392, Batch 1000/1000: LR=6.71e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 392 Train Time 38.90633201599121s

Training epoch 393, Batch 500/1000: LR=6.70e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 393, Batch 1000/1000: LR=6.70e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Epoch 393 Train Time 39.037843465805054s

Training epoch 394, Batch 500/1000: LR=6.68e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.15e-01
Training epoch 394, Batch 1000/1000: LR=6.68e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 394 Train Time 38.92760372161865s

Training epoch 395, Batch 500/1000: LR=6.67e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 395, Batch 1000/1000: LR=6.67e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 395 Train Time 38.90470623970032s

Training epoch 396, Batch 500/1000: LR=6.65e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 396, Batch 1000/1000: LR=6.65e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 396 Train Time 38.9070041179657s

Training epoch 397, Batch 500/1000: LR=6.64e-05, Loss=3.04e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 397, Batch 1000/1000: LR=6.64e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 397 Train Time 38.93043112754822s

Training epoch 398, Batch 500/1000: LR=6.62e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 398, Batch 1000/1000: LR=6.62e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 398 Train Time 38.895524978637695s

Training epoch 399, Batch 500/1000: LR=6.61e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 399, Batch 1000/1000: LR=6.61e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 399 Train Time 38.904824018478394s

Training epoch 400, Batch 500/1000: LR=6.59e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 400, Batch 1000/1000: LR=6.59e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 400 Train Time 38.94191265106201s

Training epoch 401, Batch 500/1000: LR=6.58e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 401, Batch 1000/1000: LR=6.58e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 401 Train Time 38.8861563205719s

Training epoch 402, Batch 500/1000: LR=6.56e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 402, Batch 1000/1000: LR=6.56e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 402 Train Time 38.99163007736206s

Training epoch 403, Batch 500/1000: LR=6.55e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 403, Batch 1000/1000: LR=6.55e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 403 Train Time 38.98930764198303s

Training epoch 404, Batch 500/1000: LR=6.54e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 404, Batch 1000/1000: LR=6.54e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 404 Train Time 38.885621786117554s

Training epoch 405, Batch 500/1000: LR=6.52e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 405, Batch 1000/1000: LR=6.52e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Epoch 405 Train Time 38.89807367324829s

Training epoch 406, Batch 500/1000: LR=6.51e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 406, Batch 1000/1000: LR=6.51e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 406 Train Time 38.88197898864746s

Training epoch 407, Batch 500/1000: LR=6.49e-05, Loss=3.01e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 407, Batch 1000/1000: LR=6.49e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 407 Train Time 38.98660397529602s

Training epoch 408, Batch 500/1000: LR=6.48e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 408, Batch 1000/1000: LR=6.48e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Epoch 408 Train Time 38.91452622413635s

Training epoch 409, Batch 500/1000: LR=6.46e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 409, Batch 1000/1000: LR=6.46e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.14e-01
Epoch 409 Train Time 38.93579053878784s

Training epoch 410, Batch 500/1000: LR=6.45e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 410, Batch 1000/1000: LR=6.45e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 410 Train Time 38.92091989517212s

Training epoch 411, Batch 500/1000: LR=6.43e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 411, Batch 1000/1000: LR=6.43e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 411 Train Time 38.91375970840454s

Training epoch 412, Batch 500/1000: LR=6.42e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 412, Batch 1000/1000: LR=6.42e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 412 Train Time 39.056331396102905s

Training epoch 413, Batch 500/1000: LR=6.40e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 413, Batch 1000/1000: LR=6.40e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 413 Train Time 38.89284920692444s

Training epoch 414, Batch 500/1000: LR=6.39e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 414, Batch 1000/1000: LR=6.39e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 414 Train Time 38.90944004058838s

Training epoch 415, Batch 500/1000: LR=6.37e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 415, Batch 1000/1000: LR=6.37e-05, Loss=3.01e-02 BER=1.23e-02 FER=1.14e-01
Epoch 415 Train Time 38.927693367004395s

Training epoch 416, Batch 500/1000: LR=6.36e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 416, Batch 1000/1000: LR=6.36e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 416 Train Time 38.898881912231445s

Training epoch 417, Batch 500/1000: LR=6.34e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 417, Batch 1000/1000: LR=6.34e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 417 Train Time 38.90100717544556s

Training epoch 418, Batch 500/1000: LR=6.33e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 418, Batch 1000/1000: LR=6.33e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 418 Train Time 38.881162881851196s

Training epoch 419, Batch 500/1000: LR=6.31e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 419, Batch 1000/1000: LR=6.31e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 419 Train Time 38.90136241912842s

Training epoch 420, Batch 500/1000: LR=6.30e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 420, Batch 1000/1000: LR=6.30e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 420 Train Time 38.93013334274292s

Training epoch 421, Batch 500/1000: LR=6.28e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 421, Batch 1000/1000: LR=6.28e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 421 Train Time 39.03449821472168s

Training epoch 422, Batch 500/1000: LR=6.27e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 422, Batch 1000/1000: LR=6.27e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 422 Train Time 38.95690059661865s

Training epoch 423, Batch 500/1000: LR=6.25e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 423, Batch 1000/1000: LR=6.25e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 423 Train Time 38.96016812324524s

Training epoch 424, Batch 500/1000: LR=6.24e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 424, Batch 1000/1000: LR=6.24e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 424 Train Time 38.939032554626465s

Training epoch 425, Batch 500/1000: LR=6.22e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 425, Batch 1000/1000: LR=6.22e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 425 Train Time 38.90653038024902s

Training epoch 426, Batch 500/1000: LR=6.21e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 426, Batch 1000/1000: LR=6.21e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 426 Train Time 38.64560508728027s

Training epoch 427, Batch 500/1000: LR=6.19e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 427, Batch 1000/1000: LR=6.19e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Epoch 427 Train Time 38.52125287055969s

Training epoch 428, Batch 500/1000: LR=6.18e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 428, Batch 1000/1000: LR=6.18e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 428 Train Time 38.50740122795105s

Training epoch 429, Batch 500/1000: LR=6.16e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 429, Batch 1000/1000: LR=6.16e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 429 Train Time 38.58620238304138s

Training epoch 430, Batch 500/1000: LR=6.14e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 430, Batch 1000/1000: LR=6.14e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Epoch 430 Train Time 38.63869857788086s

Training epoch 431, Batch 500/1000: LR=6.13e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 431, Batch 1000/1000: LR=6.13e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 431 Train Time 65.92810988426208s

Training epoch 432, Batch 500/1000: LR=6.11e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 432, Batch 1000/1000: LR=6.11e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 432 Train Time 39.167622566223145s

Training epoch 433, Batch 500/1000: LR=6.10e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 433, Batch 1000/1000: LR=6.10e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Epoch 433 Train Time 38.956117391586304s

Training epoch 434, Batch 500/1000: LR=6.08e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 434, Batch 1000/1000: LR=6.08e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 434 Train Time 38.99745535850525s

Training epoch 435, Batch 500/1000: LR=6.07e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 435, Batch 1000/1000: LR=6.07e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 435 Train Time 39.4934458732605s

Training epoch 436, Batch 500/1000: LR=6.05e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 436, Batch 1000/1000: LR=6.05e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 436 Train Time 38.950026988983154s

Training epoch 437, Batch 500/1000: LR=6.04e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 437, Batch 1000/1000: LR=6.04e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 437 Train Time 38.9585235118866s

Training epoch 438, Batch 500/1000: LR=6.02e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 438, Batch 1000/1000: LR=6.02e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 438 Train Time 38.96243500709534s

Training epoch 439, Batch 500/1000: LR=6.01e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 439, Batch 1000/1000: LR=6.01e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 439 Train Time 38.93751883506775s

Training epoch 440, Batch 500/1000: LR=5.99e-05, Loss=2.90e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 440, Batch 1000/1000: LR=5.99e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 440 Train Time 38.9418306350708s

Training epoch 441, Batch 500/1000: LR=5.98e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 441, Batch 1000/1000: LR=5.98e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 441 Train Time 38.89727759361267s

Training epoch 442, Batch 500/1000: LR=5.96e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 442, Batch 1000/1000: LR=5.96e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 442 Train Time 38.920167446136475s

Training epoch 443, Batch 500/1000: LR=5.95e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 443, Batch 1000/1000: LR=5.95e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 443 Train Time 39.0680615901947s

Training epoch 444, Batch 500/1000: LR=5.93e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 444, Batch 1000/1000: LR=5.93e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 444 Train Time 38.926846742630005s

Training epoch 445, Batch 500/1000: LR=5.92e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 445, Batch 1000/1000: LR=5.92e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 445 Train Time 38.924275636672974s

Training epoch 446, Batch 500/1000: LR=5.90e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 446, Batch 1000/1000: LR=5.90e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 446 Train Time 38.92913794517517s

Training epoch 447, Batch 500/1000: LR=5.89e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 447, Batch 1000/1000: LR=5.89e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 447 Train Time 38.99205803871155s

Training epoch 448, Batch 500/1000: LR=5.87e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 448, Batch 1000/1000: LR=5.87e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 448 Train Time 38.91665244102478s

Training epoch 449, Batch 500/1000: LR=5.86e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 449, Batch 1000/1000: LR=5.86e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 449 Train Time 38.93721389770508s

Training epoch 450, Batch 500/1000: LR=5.84e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 450, Batch 1000/1000: LR=5.84e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 450 Train Time 38.93062686920166s

Training epoch 451, Batch 500/1000: LR=5.82e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 451, Batch 1000/1000: LR=5.82e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 451 Train Time 38.90977644920349s

Training epoch 452, Batch 500/1000: LR=5.81e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 452, Batch 1000/1000: LR=5.81e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 452 Train Time 39.00348401069641s

Training epoch 453, Batch 500/1000: LR=5.79e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 453, Batch 1000/1000: LR=5.79e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Epoch 453 Train Time 39.05342936515808s

Training epoch 454, Batch 500/1000: LR=5.78e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 454, Batch 1000/1000: LR=5.78e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 454 Train Time 38.92357850074768s

Training epoch 455, Batch 500/1000: LR=5.76e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 455, Batch 1000/1000: LR=5.76e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 455 Train Time 38.95329022407532s

Training epoch 456, Batch 500/1000: LR=5.75e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 456, Batch 1000/1000: LR=5.75e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Epoch 456 Train Time 38.95588731765747s

Training epoch 457, Batch 500/1000: LR=5.73e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 457, Batch 1000/1000: LR=5.73e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 457 Train Time 38.93302297592163s

Training epoch 458, Batch 500/1000: LR=5.72e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 458, Batch 1000/1000: LR=5.72e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 458 Train Time 38.922709703445435s

Training epoch 459, Batch 500/1000: LR=5.70e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.12e-01
Training epoch 459, Batch 1000/1000: LR=5.70e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 459 Train Time 38.90970993041992s

Training epoch 460, Batch 500/1000: LR=5.69e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 460, Batch 1000/1000: LR=5.69e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 460 Train Time 38.913538217544556s

Training epoch 461, Batch 500/1000: LR=5.67e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 461, Batch 1000/1000: LR=5.67e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 461 Train Time 38.913328886032104s

Training epoch 462, Batch 500/1000: LR=5.65e-05, Loss=2.90e-02 BER=1.16e-02 FER=1.10e-01
Training epoch 462, Batch 1000/1000: LR=5.65e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 462 Train Time 39.056044816970825s

Training epoch 463, Batch 500/1000: LR=5.64e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 463, Batch 1000/1000: LR=5.64e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 463 Train Time 38.90699338912964s

Training epoch 464, Batch 500/1000: LR=5.62e-05, Loss=2.98e-02 BER=1.19e-02 FER=1.13e-01
Training epoch 464, Batch 1000/1000: LR=5.62e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 464 Train Time 38.91834354400635s

Training epoch 465, Batch 500/1000: LR=5.61e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 465, Batch 1000/1000: LR=5.61e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 465 Train Time 38.921560287475586s

Training epoch 466, Batch 500/1000: LR=5.59e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 466, Batch 1000/1000: LR=5.59e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 466 Train Time 38.963029861450195s

Training epoch 467, Batch 500/1000: LR=5.58e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 467, Batch 1000/1000: LR=5.58e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 467 Train Time 38.88930654525757s

Training epoch 468, Batch 500/1000: LR=5.56e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 468, Batch 1000/1000: LR=5.56e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 468 Train Time 38.976261377334595s

Training epoch 469, Batch 500/1000: LR=5.55e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 469, Batch 1000/1000: LR=5.55e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 469 Train Time 38.99918842315674s

Training epoch 470, Batch 500/1000: LR=5.53e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 470, Batch 1000/1000: LR=5.53e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 470 Train Time 38.94029426574707s

Training epoch 471, Batch 500/1000: LR=5.52e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 471, Batch 1000/1000: LR=5.52e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 471 Train Time 39.00347542762756s

Training epoch 472, Batch 500/1000: LR=5.50e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 472, Batch 1000/1000: LR=5.50e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 472 Train Time 38.932055950164795s

Training epoch 473, Batch 500/1000: LR=5.48e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 473, Batch 1000/1000: LR=5.48e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 473 Train Time 39.29840850830078s

Training epoch 474, Batch 500/1000: LR=5.47e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 474, Batch 1000/1000: LR=5.47e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 474 Train Time 39.10611820220947s

Training epoch 475, Batch 500/1000: LR=5.45e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 475, Batch 1000/1000: LR=5.45e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 475 Train Time 38.89976143836975s

Training epoch 476, Batch 500/1000: LR=5.44e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 476, Batch 1000/1000: LR=5.44e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 476 Train Time 38.559221506118774s

Training epoch 477, Batch 500/1000: LR=5.42e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 477, Batch 1000/1000: LR=5.42e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Epoch 477 Train Time 38.56910729408264s

Training epoch 478, Batch 500/1000: LR=5.41e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 478, Batch 1000/1000: LR=5.41e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 478 Train Time 96.92157936096191s

Training epoch 479, Batch 500/1000: LR=5.39e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 479, Batch 1000/1000: LR=5.39e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 479 Train Time 38.715872049331665s

Training epoch 480, Batch 500/1000: LR=5.38e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 480, Batch 1000/1000: LR=5.38e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 480 Train Time 38.55153274536133s

Training epoch 481, Batch 500/1000: LR=5.36e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 481, Batch 1000/1000: LR=5.36e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 481 Train Time 38.8474600315094s

Training epoch 482, Batch 500/1000: LR=5.35e-05, Loss=2.95e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 482, Batch 1000/1000: LR=5.35e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Epoch 482 Train Time 38.71178483963013s

Training epoch 483, Batch 500/1000: LR=5.33e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 483, Batch 1000/1000: LR=5.33e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 483 Train Time 38.64312720298767s

Training epoch 484, Batch 500/1000: LR=5.31e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 484, Batch 1000/1000: LR=5.31e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 484 Train Time 38.53117895126343s

Training epoch 485, Batch 500/1000: LR=5.30e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 485, Batch 1000/1000: LR=5.30e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 485 Train Time 38.53999161720276s

Training epoch 486, Batch 500/1000: LR=5.28e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 486, Batch 1000/1000: LR=5.28e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 486 Train Time 38.935277700424194s

Training epoch 487, Batch 500/1000: LR=5.27e-05, Loss=3.05e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 487, Batch 1000/1000: LR=5.27e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 487 Train Time 38.6635959148407s

Training epoch 488, Batch 500/1000: LR=5.25e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 488, Batch 1000/1000: LR=5.25e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 488 Train Time 38.556944847106934s

Training epoch 489, Batch 500/1000: LR=5.24e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 489, Batch 1000/1000: LR=5.24e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Epoch 489 Train Time 38.57566452026367s

Training epoch 490, Batch 500/1000: LR=5.22e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 490, Batch 1000/1000: LR=5.22e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 490 Train Time 38.532164573669434s

Training epoch 491, Batch 500/1000: LR=5.21e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 491, Batch 1000/1000: LR=5.21e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 491 Train Time 38.675987243652344s

Training epoch 492, Batch 500/1000: LR=5.19e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 492, Batch 1000/1000: LR=5.19e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 492 Train Time 38.54218316078186s

Training epoch 493, Batch 500/1000: LR=5.17e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 493, Batch 1000/1000: LR=5.17e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 493 Train Time 38.5223605632782s

Training epoch 494, Batch 500/1000: LR=5.16e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 494, Batch 1000/1000: LR=5.16e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 494 Train Time 38.5643253326416s

Training epoch 495, Batch 500/1000: LR=5.14e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 495, Batch 1000/1000: LR=5.14e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 495 Train Time 39.609034061431885s

Training epoch 496, Batch 500/1000: LR=5.13e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 496, Batch 1000/1000: LR=5.13e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 496 Train Time 38.563515424728394s

Training epoch 497, Batch 500/1000: LR=5.11e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 497, Batch 1000/1000: LR=5.11e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 497 Train Time 38.5211660861969s

Training epoch 498, Batch 500/1000: LR=5.10e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 498, Batch 1000/1000: LR=5.10e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 498 Train Time 38.53006982803345s

Training epoch 499, Batch 500/1000: LR=5.08e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 499, Batch 1000/1000: LR=5.08e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 499 Train Time 38.5971462726593s

Training epoch 500, Batch 500/1000: LR=5.07e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 500, Batch 1000/1000: LR=5.07e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 500 Train Time 38.56456971168518s

Training epoch 501, Batch 500/1000: LR=5.05e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 501, Batch 1000/1000: LR=5.05e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 501 Train Time 38.61267018318176s

Training epoch 502, Batch 500/1000: LR=5.03e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 502, Batch 1000/1000: LR=5.03e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 502 Train Time 38.62077593803406s

Training epoch 503, Batch 500/1000: LR=5.02e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 503, Batch 1000/1000: LR=5.02e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.12e-01
Epoch 503 Train Time 38.52166962623596s

Training epoch 504, Batch 500/1000: LR=5.00e-05, Loss=3.00e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 504, Batch 1000/1000: LR=5.00e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 504 Train Time 38.50755286216736s

Training epoch 505, Batch 500/1000: LR=4.99e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 505, Batch 1000/1000: LR=4.99e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 505 Train Time 38.49093794822693s

Training epoch 506, Batch 500/1000: LR=4.97e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.11e-01
Training epoch 506, Batch 1000/1000: LR=4.97e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 506 Train Time 38.51684784889221s

Training epoch 507, Batch 500/1000: LR=4.96e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 507, Batch 1000/1000: LR=4.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 507 Train Time 38.54270887374878s

Training epoch 508, Batch 500/1000: LR=4.94e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 508, Batch 1000/1000: LR=4.94e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 508 Train Time 38.51909875869751s

Training epoch 509, Batch 500/1000: LR=4.93e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 509, Batch 1000/1000: LR=4.93e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 509 Train Time 38.560113191604614s

Training epoch 510, Batch 500/1000: LR=4.91e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 510, Batch 1000/1000: LR=4.91e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 510 Train Time 38.554837226867676s

Training epoch 511, Batch 500/1000: LR=4.89e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 511, Batch 1000/1000: LR=4.89e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 511 Train Time 38.59373950958252s

Training epoch 512, Batch 500/1000: LR=4.88e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 512, Batch 1000/1000: LR=4.88e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 512 Train Time 38.49513268470764s

Training epoch 513, Batch 500/1000: LR=4.86e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 513, Batch 1000/1000: LR=4.86e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 513 Train Time 38.53819942474365s

Training epoch 514, Batch 500/1000: LR=4.85e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 514, Batch 1000/1000: LR=4.85e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 514 Train Time 38.58833193778992s

Training epoch 515, Batch 500/1000: LR=4.83e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 515, Batch 1000/1000: LR=4.83e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 515 Train Time 38.51696801185608s

Training epoch 516, Batch 500/1000: LR=4.82e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 516, Batch 1000/1000: LR=4.82e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 516 Train Time 38.54051971435547s

Training epoch 517, Batch 500/1000: LR=4.80e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 517, Batch 1000/1000: LR=4.80e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 517 Train Time 38.48883557319641s

Training epoch 518, Batch 500/1000: LR=4.79e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 518, Batch 1000/1000: LR=4.79e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 518 Train Time 38.54061031341553s

Training epoch 519, Batch 500/1000: LR=4.77e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 519, Batch 1000/1000: LR=4.77e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 519 Train Time 38.56667923927307s

Training epoch 520, Batch 500/1000: LR=4.75e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 520, Batch 1000/1000: LR=4.75e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 520 Train Time 38.611432790756226s

Training epoch 521, Batch 500/1000: LR=4.74e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 521, Batch 1000/1000: LR=4.74e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 521 Train Time 38.537272691726685s

Training epoch 522, Batch 500/1000: LR=4.72e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 522, Batch 1000/1000: LR=4.72e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 522 Train Time 38.545072078704834s

Training epoch 523, Batch 500/1000: LR=4.71e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 523, Batch 1000/1000: LR=4.71e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 523 Train Time 38.50853490829468s

Training epoch 524, Batch 500/1000: LR=4.69e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 524, Batch 1000/1000: LR=4.69e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 524 Train Time 38.49528217315674s

Training epoch 525, Batch 500/1000: LR=4.68e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 525, Batch 1000/1000: LR=4.68e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 525 Train Time 55.68260622024536s

Training epoch 526, Batch 500/1000: LR=4.66e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 526, Batch 1000/1000: LR=4.66e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Epoch 526 Train Time 39.1185884475708s

Training epoch 527, Batch 500/1000: LR=4.65e-05, Loss=3.04e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 527, Batch 1000/1000: LR=4.65e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 527 Train Time 38.594907999038696s

Training epoch 528, Batch 500/1000: LR=4.63e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 528, Batch 1000/1000: LR=4.63e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 528 Train Time 38.610676288604736s

Training epoch 529, Batch 500/1000: LR=4.62e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 529, Batch 1000/1000: LR=4.62e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 529 Train Time 38.676061153411865s

Training epoch 530, Batch 500/1000: LR=4.60e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.15e-01
Training epoch 530, Batch 1000/1000: LR=4.60e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 530 Train Time 38.63769316673279s

Training epoch 531, Batch 500/1000: LR=4.58e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 531, Batch 1000/1000: LR=4.58e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 531 Train Time 38.564414978027344s

Training epoch 532, Batch 500/1000: LR=4.57e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 532, Batch 1000/1000: LR=4.57e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 532 Train Time 38.5367636680603s

Training epoch 533, Batch 500/1000: LR=4.55e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 533, Batch 1000/1000: LR=4.55e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 533 Train Time 38.55508613586426s

Training epoch 534, Batch 500/1000: LR=4.54e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 534, Batch 1000/1000: LR=4.54e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 534 Train Time 38.586127042770386s

Training epoch 535, Batch 500/1000: LR=4.52e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 535, Batch 1000/1000: LR=4.52e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Epoch 535 Train Time 38.57017683982849s

Training epoch 536, Batch 500/1000: LR=4.51e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 536, Batch 1000/1000: LR=4.51e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 536 Train Time 38.59627723693848s

Training epoch 537, Batch 500/1000: LR=4.49e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 537, Batch 1000/1000: LR=4.49e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 537 Train Time 38.68318033218384s

Training epoch 538, Batch 500/1000: LR=4.48e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 538, Batch 1000/1000: LR=4.48e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 538 Train Time 38.55345845222473s

Training epoch 539, Batch 500/1000: LR=4.46e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 539, Batch 1000/1000: LR=4.46e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 539 Train Time 38.688021659851074s

Training epoch 540, Batch 500/1000: LR=4.45e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 540, Batch 1000/1000: LR=4.45e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 540 Train Time 39.02124500274658s

Training epoch 541, Batch 500/1000: LR=4.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 541, Batch 1000/1000: LR=4.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 541 Train Time 38.60107207298279s

Training epoch 542, Batch 500/1000: LR=4.41e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 542, Batch 1000/1000: LR=4.41e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 542 Train Time 38.59375476837158s

Training epoch 543, Batch 500/1000: LR=4.40e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 543, Batch 1000/1000: LR=4.40e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 543 Train Time 38.556605100631714s

Training epoch 544, Batch 500/1000: LR=4.38e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 544, Batch 1000/1000: LR=4.38e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 544 Train Time 38.5906195640564s

Training epoch 545, Batch 500/1000: LR=4.37e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 545, Batch 1000/1000: LR=4.37e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 545 Train Time 38.65931820869446s

Training epoch 546, Batch 500/1000: LR=4.35e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 546, Batch 1000/1000: LR=4.35e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 546 Train Time 38.60366439819336s

Training epoch 547, Batch 500/1000: LR=4.34e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 547, Batch 1000/1000: LR=4.34e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 547 Train Time 38.5768768787384s

Training epoch 548, Batch 500/1000: LR=4.32e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 548, Batch 1000/1000: LR=4.32e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.12e-01
Epoch 548 Train Time 38.55442762374878s

Training epoch 549, Batch 500/1000: LR=4.31e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 549, Batch 1000/1000: LR=4.31e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 549 Train Time 38.58181405067444s

Training epoch 550, Batch 500/1000: LR=4.29e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 550, Batch 1000/1000: LR=4.29e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 550 Train Time 38.58411240577698s

Training epoch 551, Batch 500/1000: LR=4.28e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 551, Batch 1000/1000: LR=4.28e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 551 Train Time 38.64489030838013s

Training epoch 552, Batch 500/1000: LR=4.26e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 552, Batch 1000/1000: LR=4.26e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 552 Train Time 38.57574796676636s

Training epoch 553, Batch 500/1000: LR=4.24e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 553, Batch 1000/1000: LR=4.24e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 553 Train Time 38.555213928222656s

Training epoch 554, Batch 500/1000: LR=4.23e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 554, Batch 1000/1000: LR=4.23e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 554 Train Time 38.563252687454224s

Training epoch 555, Batch 500/1000: LR=4.21e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 555, Batch 1000/1000: LR=4.21e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 555 Train Time 38.53926968574524s

Training epoch 556, Batch 500/1000: LR=4.20e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 556, Batch 1000/1000: LR=4.20e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 556 Train Time 38.5546498298645s

Training epoch 557, Batch 500/1000: LR=4.18e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 557, Batch 1000/1000: LR=4.18e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 557 Train Time 38.56606316566467s

Training epoch 558, Batch 500/1000: LR=4.17e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 558, Batch 1000/1000: LR=4.17e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 558 Train Time 38.54798626899719s

Training epoch 559, Batch 500/1000: LR=4.15e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 559, Batch 1000/1000: LR=4.15e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 559 Train Time 38.55547833442688s

Training epoch 560, Batch 500/1000: LR=4.14e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 560, Batch 1000/1000: LR=4.14e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 560 Train Time 38.65717554092407s

Training epoch 561, Batch 500/1000: LR=4.12e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 561, Batch 1000/1000: LR=4.12e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 561 Train Time 38.76396703720093s

Training epoch 562, Batch 500/1000: LR=4.11e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 562, Batch 1000/1000: LR=4.11e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 562 Train Time 38.579203605651855s

Training epoch 563, Batch 500/1000: LR=4.09e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 563, Batch 1000/1000: LR=4.09e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 563 Train Time 38.572699785232544s

Training epoch 564, Batch 500/1000: LR=4.08e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 564, Batch 1000/1000: LR=4.08e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 564 Train Time 38.52252221107483s

Training epoch 565, Batch 500/1000: LR=4.06e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 565, Batch 1000/1000: LR=4.06e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 565 Train Time 38.57696342468262s

Training epoch 566, Batch 500/1000: LR=4.05e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 566, Batch 1000/1000: LR=4.05e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Epoch 566 Train Time 38.547462940216064s

Training epoch 567, Batch 500/1000: LR=4.03e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 567, Batch 1000/1000: LR=4.03e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 567 Train Time 38.554261207580566s

Training epoch 568, Batch 500/1000: LR=4.02e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 568, Batch 1000/1000: LR=4.02e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 568 Train Time 38.57429051399231s

Training epoch 569, Batch 500/1000: LR=4.00e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 569, Batch 1000/1000: LR=4.00e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Epoch 569 Train Time 38.70340895652771s

Training epoch 570, Batch 500/1000: LR=3.99e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 570, Batch 1000/1000: LR=3.99e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 570 Train Time 38.524924993515015s

Training epoch 571, Batch 500/1000: LR=3.97e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 571, Batch 1000/1000: LR=3.97e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 571 Train Time 38.563156843185425s

Training epoch 572, Batch 500/1000: LR=3.96e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 572, Batch 1000/1000: LR=3.96e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 572 Train Time 58.27859807014465s

Training epoch 573, Batch 500/1000: LR=3.94e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 573, Batch 1000/1000: LR=3.94e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 573 Train Time 39.206868410110474s

Training epoch 574, Batch 500/1000: LR=3.92e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 574, Batch 1000/1000: LR=3.92e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 574 Train Time 38.70393419265747s

Training epoch 575, Batch 500/1000: LR=3.91e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 575, Batch 1000/1000: LR=3.91e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 575 Train Time 38.557026863098145s

Training epoch 576, Batch 500/1000: LR=3.89e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 576, Batch 1000/1000: LR=3.89e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 576 Train Time 38.6190128326416s

Training epoch 577, Batch 500/1000: LR=3.88e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 577, Batch 1000/1000: LR=3.88e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 577 Train Time 39.051037311553955s

Training epoch 578, Batch 500/1000: LR=3.86e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 578, Batch 1000/1000: LR=3.86e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 578 Train Time 38.97600507736206s

Training epoch 579, Batch 500/1000: LR=3.85e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 579, Batch 1000/1000: LR=3.85e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 579 Train Time 38.538658618927s

Training epoch 580, Batch 500/1000: LR=3.83e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 580, Batch 1000/1000: LR=3.83e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 580 Train Time 38.539387941360474s

Training epoch 581, Batch 500/1000: LR=3.82e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 581, Batch 1000/1000: LR=3.82e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Epoch 581 Train Time 38.5680615901947s

Training epoch 582, Batch 500/1000: LR=3.80e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 582, Batch 1000/1000: LR=3.80e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 582 Train Time 38.56320667266846s

Training epoch 583, Batch 500/1000: LR=3.79e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 583, Batch 1000/1000: LR=3.79e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 583 Train Time 38.570979833602905s

Training epoch 584, Batch 500/1000: LR=3.77e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 584, Batch 1000/1000: LR=3.77e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 584 Train Time 38.56014919281006s

Training epoch 585, Batch 500/1000: LR=3.76e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 585, Batch 1000/1000: LR=3.76e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 585 Train Time 38.56720018386841s

Training epoch 586, Batch 500/1000: LR=3.74e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 586, Batch 1000/1000: LR=3.74e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 586 Train Time 38.57082533836365s

Training epoch 587, Batch 500/1000: LR=3.73e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 587, Batch 1000/1000: LR=3.73e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 587 Train Time 38.699862241744995s

Training epoch 588, Batch 500/1000: LR=3.71e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 588, Batch 1000/1000: LR=3.71e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 588 Train Time 38.60798192024231s

Training epoch 589, Batch 500/1000: LR=3.70e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 589, Batch 1000/1000: LR=3.70e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 589 Train Time 39.18893647193909s

Training epoch 590, Batch 500/1000: LR=3.68e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 590, Batch 1000/1000: LR=3.68e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 590 Train Time 38.574167251586914s

Training epoch 591, Batch 500/1000: LR=3.67e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 591, Batch 1000/1000: LR=3.67e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Epoch 591 Train Time 38.580681800842285s

Training epoch 592, Batch 500/1000: LR=3.65e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 592, Batch 1000/1000: LR=3.65e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 592 Train Time 38.69008946418762s

Training epoch 593, Batch 500/1000: LR=3.64e-05, Loss=2.95e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 593, Batch 1000/1000: LR=3.64e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 593 Train Time 38.563966035842896s

Training epoch 594, Batch 500/1000: LR=3.62e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 594, Batch 1000/1000: LR=3.62e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 594 Train Time 38.56850266456604s

Training epoch 595, Batch 500/1000: LR=3.61e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 595, Batch 1000/1000: LR=3.61e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 595 Train Time 38.5514235496521s

Training epoch 596, Batch 500/1000: LR=3.59e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 596, Batch 1000/1000: LR=3.59e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 596 Train Time 38.684775829315186s

Training epoch 597, Batch 500/1000: LR=3.58e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 597, Batch 1000/1000: LR=3.58e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 597 Train Time 38.56907820701599s

Training epoch 598, Batch 500/1000: LR=3.56e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 598, Batch 1000/1000: LR=3.56e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 598 Train Time 38.54203939437866s

Training epoch 599, Batch 500/1000: LR=3.55e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 599, Batch 1000/1000: LR=3.55e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 599 Train Time 38.55151605606079s

Training epoch 600, Batch 500/1000: LR=3.54e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 600, Batch 1000/1000: LR=3.54e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 600 Train Time 38.543073415756226s


Test Loss 4: 8.90e-03 5: 9.46e-04 6: 4.60e-05
Test FER 4: 3.95e-02 5: 4.33e-03 6: 2.19e-04
Test BER 4: 3.25e-03 5: 2.98e-04 6: 1.16e-05
Test -ln(BER) 4: 5.73e+00 5: 8.12e+00 6: 1.14e+01
# of testing samples: [100352.0, 100352.0, 460800.0]
 Test Time 122.35298657417297 s

Training epoch 601, Batch 500/1000: LR=3.52e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 601, Batch 1000/1000: LR=3.52e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 601 Train Time 38.57170343399048s

Training epoch 602, Batch 500/1000: LR=3.51e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 602, Batch 1000/1000: LR=3.51e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 602 Train Time 38.62850332260132s

Training epoch 603, Batch 500/1000: LR=3.49e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 603, Batch 1000/1000: LR=3.49e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 603 Train Time 38.55719971656799s

Training epoch 604, Batch 500/1000: LR=3.48e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 604, Batch 1000/1000: LR=3.48e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 604 Train Time 38.540064334869385s

Training epoch 605, Batch 500/1000: LR=3.46e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 605, Batch 1000/1000: LR=3.46e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 605 Train Time 38.636293172836304s

Training epoch 606, Batch 500/1000: LR=3.45e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 606, Batch 1000/1000: LR=3.45e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 606 Train Time 38.56471061706543s

Training epoch 607, Batch 500/1000: LR=3.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 607, Batch 1000/1000: LR=3.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 607 Train Time 38.53229856491089s

Training epoch 608, Batch 500/1000: LR=3.42e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 608, Batch 1000/1000: LR=3.42e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 608 Train Time 38.52929711341858s

Training epoch 609, Batch 500/1000: LR=3.40e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 609, Batch 1000/1000: LR=3.40e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.13e-01
Epoch 609 Train Time 38.546008586883545s

Training epoch 610, Batch 500/1000: LR=3.39e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 610, Batch 1000/1000: LR=3.39e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 610 Train Time 38.62928748130798s

Training epoch 611, Batch 500/1000: LR=3.37e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 611, Batch 1000/1000: LR=3.37e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 611 Train Time 38.644017934799194s

Training epoch 612, Batch 500/1000: LR=3.36e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 612, Batch 1000/1000: LR=3.36e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 612 Train Time 38.70372152328491s

Training epoch 613, Batch 500/1000: LR=3.34e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 613, Batch 1000/1000: LR=3.34e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 613 Train Time 38.543540954589844s

Training epoch 614, Batch 500/1000: LR=3.33e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 614, Batch 1000/1000: LR=3.33e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 614 Train Time 38.53851509094238s

Training epoch 615, Batch 500/1000: LR=3.31e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 615, Batch 1000/1000: LR=3.31e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 615 Train Time 38.569143772125244s

Training epoch 616, Batch 500/1000: LR=3.30e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 616, Batch 1000/1000: LR=3.30e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 616 Train Time 55.85489296913147s

Training epoch 617, Batch 500/1000: LR=3.29e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 617, Batch 1000/1000: LR=3.29e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 617 Train Time 39.76709747314453s

Training epoch 618, Batch 500/1000: LR=3.27e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 618, Batch 1000/1000: LR=3.27e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 618 Train Time 39.38660550117493s

Training epoch 619, Batch 500/1000: LR=3.26e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 619, Batch 1000/1000: LR=3.26e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 619 Train Time 39.049365758895874s

Training epoch 620, Batch 500/1000: LR=3.24e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 620, Batch 1000/1000: LR=3.24e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 620 Train Time 38.66604399681091s

Training epoch 621, Batch 500/1000: LR=3.23e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 621, Batch 1000/1000: LR=3.23e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 621 Train Time 39.00845909118652s

Training epoch 622, Batch 500/1000: LR=3.21e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 622, Batch 1000/1000: LR=3.21e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 622 Train Time 40.52947425842285s

Training epoch 623, Batch 500/1000: LR=3.20e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 623, Batch 1000/1000: LR=3.20e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 623 Train Time 40.058507442474365s

Training epoch 624, Batch 500/1000: LR=3.18e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 624, Batch 1000/1000: LR=3.18e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 624 Train Time 39.34584355354309s

Training epoch 625, Batch 500/1000: LR=3.17e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 625, Batch 1000/1000: LR=3.17e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 625 Train Time 39.17329668998718s

Training epoch 626, Batch 500/1000: LR=3.16e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 626, Batch 1000/1000: LR=3.16e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 626 Train Time 40.50229001045227s

Training epoch 627, Batch 500/1000: LR=3.14e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 627, Batch 1000/1000: LR=3.14e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 627 Train Time 39.75405406951904s

Training epoch 628, Batch 500/1000: LR=3.13e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 628, Batch 1000/1000: LR=3.13e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 628 Train Time 39.214555978775024s

Training epoch 629, Batch 500/1000: LR=3.11e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 629, Batch 1000/1000: LR=3.11e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 629 Train Time 38.6556339263916s

Training epoch 630, Batch 500/1000: LR=3.10e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.12e-01
Training epoch 630, Batch 1000/1000: LR=3.10e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Epoch 630 Train Time 38.56940054893494s

Training epoch 631, Batch 500/1000: LR=3.08e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 631, Batch 1000/1000: LR=3.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 631 Train Time 38.55872917175293s

Training epoch 632, Batch 500/1000: LR=3.07e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 632, Batch 1000/1000: LR=3.07e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 632 Train Time 38.610027551651s

Training epoch 633, Batch 500/1000: LR=3.06e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 633, Batch 1000/1000: LR=3.06e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 633 Train Time 38.541260719299316s

Training epoch 634, Batch 500/1000: LR=3.04e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 634, Batch 1000/1000: LR=3.04e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 634 Train Time 38.57928490638733s

Training epoch 635, Batch 500/1000: LR=3.03e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 635, Batch 1000/1000: LR=3.03e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 635 Train Time 38.58882761001587s

Training epoch 636, Batch 500/1000: LR=3.01e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 636, Batch 1000/1000: LR=3.01e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 636 Train Time 38.61343955993652s

Training epoch 637, Batch 500/1000: LR=3.00e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 637, Batch 1000/1000: LR=3.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 637 Train Time 38.563257455825806s

Training epoch 638, Batch 500/1000: LR=2.98e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 638, Batch 1000/1000: LR=2.98e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 638 Train Time 38.57901954650879s

Training epoch 639, Batch 500/1000: LR=2.97e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 639, Batch 1000/1000: LR=2.97e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 639 Train Time 38.539129972457886s

Training epoch 640, Batch 500/1000: LR=2.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 640, Batch 1000/1000: LR=2.96e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 640 Train Time 38.57619833946228s

Training epoch 641, Batch 500/1000: LR=2.94e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 641, Batch 1000/1000: LR=2.94e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Epoch 641 Train Time 38.5626323223114s

Training epoch 642, Batch 500/1000: LR=2.93e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 642, Batch 1000/1000: LR=2.93e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 642 Train Time 38.70760202407837s

Training epoch 643, Batch 500/1000: LR=2.91e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 643, Batch 1000/1000: LR=2.91e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 643 Train Time 38.54168128967285s

Training epoch 644, Batch 500/1000: LR=2.90e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 644, Batch 1000/1000: LR=2.90e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 644 Train Time 39.311299085617065s

Training epoch 645, Batch 500/1000: LR=2.89e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 645, Batch 1000/1000: LR=2.89e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 645 Train Time 38.54422926902771s

Training epoch 646, Batch 500/1000: LR=2.87e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 646, Batch 1000/1000: LR=2.87e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 646 Train Time 38.54925799369812s

Training epoch 647, Batch 500/1000: LR=2.86e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 647, Batch 1000/1000: LR=2.86e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 647 Train Time 38.541221618652344s

Training epoch 648, Batch 500/1000: LR=2.84e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 648, Batch 1000/1000: LR=2.84e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 648 Train Time 38.53134512901306s

Training epoch 649, Batch 500/1000: LR=2.83e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 649, Batch 1000/1000: LR=2.83e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 649 Train Time 38.55343747138977s

Training epoch 650, Batch 500/1000: LR=2.82e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 650, Batch 1000/1000: LR=2.82e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 650 Train Time 38.629555463790894s

Training epoch 651, Batch 500/1000: LR=2.80e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 651, Batch 1000/1000: LR=2.80e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 651 Train Time 38.66218709945679s

Training epoch 652, Batch 500/1000: LR=2.79e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 652, Batch 1000/1000: LR=2.79e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 652 Train Time 38.525962352752686s

Training epoch 653, Batch 500/1000: LR=2.78e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 653, Batch 1000/1000: LR=2.78e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 653 Train Time 38.52912402153015s

Training epoch 654, Batch 500/1000: LR=2.76e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 654, Batch 1000/1000: LR=2.76e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 654 Train Time 38.55304265022278s

Training epoch 655, Batch 500/1000: LR=2.75e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 655, Batch 1000/1000: LR=2.75e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 655 Train Time 38.57006907463074s

Training epoch 656, Batch 500/1000: LR=2.73e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 656, Batch 1000/1000: LR=2.73e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 656 Train Time 38.53471612930298s

Training epoch 657, Batch 500/1000: LR=2.72e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 657, Batch 1000/1000: LR=2.72e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 657 Train Time 38.54652762413025s

Training epoch 658, Batch 500/1000: LR=2.71e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 658, Batch 1000/1000: LR=2.71e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 658 Train Time 38.53551959991455s

Training epoch 659, Batch 500/1000: LR=2.69e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 659, Batch 1000/1000: LR=2.69e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 659 Train Time 38.63840317726135s

Training epoch 660, Batch 500/1000: LR=2.68e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 660, Batch 1000/1000: LR=2.68e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 660 Train Time 38.524107456207275s

Training epoch 661, Batch 500/1000: LR=2.67e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 661, Batch 1000/1000: LR=2.67e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 661 Train Time 38.55707573890686s

Training epoch 662, Batch 500/1000: LR=2.65e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 662, Batch 1000/1000: LR=2.65e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Epoch 662 Train Time 38.528823375701904s

Training epoch 663, Batch 500/1000: LR=2.64e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 663, Batch 1000/1000: LR=2.64e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 663 Train Time 97.3936095237732s

Training epoch 664, Batch 500/1000: LR=2.62e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 664, Batch 1000/1000: LR=2.62e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 664 Train Time 40.35288977622986s

Training epoch 665, Batch 500/1000: LR=2.61e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 665, Batch 1000/1000: LR=2.61e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 665 Train Time 39.0884051322937s

Training epoch 666, Batch 500/1000: LR=2.60e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 666, Batch 1000/1000: LR=2.60e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 666 Train Time 38.57071375846863s

Training epoch 667, Batch 500/1000: LR=2.58e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 667, Batch 1000/1000: LR=2.58e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 667 Train Time 38.641539573669434s

Training epoch 668, Batch 500/1000: LR=2.57e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 668, Batch 1000/1000: LR=2.57e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 668 Train Time 38.54123902320862s

Training epoch 669, Batch 500/1000: LR=2.56e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 669, Batch 1000/1000: LR=2.56e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 669 Train Time 38.497336626052856s

Training epoch 670, Batch 500/1000: LR=2.54e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 670, Batch 1000/1000: LR=2.54e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 670 Train Time 38.55107140541077s

Training epoch 671, Batch 500/1000: LR=2.53e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 671, Batch 1000/1000: LR=2.53e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 671 Train Time 38.54012870788574s

Training epoch 672, Batch 500/1000: LR=2.52e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 672, Batch 1000/1000: LR=2.52e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 672 Train Time 38.561769247055054s

Training epoch 673, Batch 500/1000: LR=2.50e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 673, Batch 1000/1000: LR=2.50e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 673 Train Time 38.53681302070618s

Training epoch 674, Batch 500/1000: LR=2.49e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 674, Batch 1000/1000: LR=2.49e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 674 Train Time 38.52780842781067s

Training epoch 675, Batch 500/1000: LR=2.48e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 675, Batch 1000/1000: LR=2.48e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 675 Train Time 38.559730768203735s

Training epoch 676, Batch 500/1000: LR=2.46e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 676, Batch 1000/1000: LR=2.46e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 676 Train Time 38.62748312950134s

Training epoch 677, Batch 500/1000: LR=2.45e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 677, Batch 1000/1000: LR=2.45e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 677 Train Time 38.55142307281494s

Training epoch 678, Batch 500/1000: LR=2.44e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 678, Batch 1000/1000: LR=2.44e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 678 Train Time 38.54493689537048s

Training epoch 679, Batch 500/1000: LR=2.42e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 679, Batch 1000/1000: LR=2.42e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 679 Train Time 38.493109703063965s

Training epoch 680, Batch 500/1000: LR=2.41e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 680, Batch 1000/1000: LR=2.41e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 680 Train Time 38.57223606109619s

Training epoch 681, Batch 500/1000: LR=2.40e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 681, Batch 1000/1000: LR=2.40e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 681 Train Time 38.61850333213806s

Training epoch 682, Batch 500/1000: LR=2.38e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 682, Batch 1000/1000: LR=2.38e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 682 Train Time 38.509685039520264s

Training epoch 683, Batch 500/1000: LR=2.37e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 683, Batch 1000/1000: LR=2.37e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 683 Train Time 38.517343044281006s

Training epoch 684, Batch 500/1000: LR=2.36e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 684, Batch 1000/1000: LR=2.36e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Epoch 684 Train Time 38.547892808914185s

Training epoch 685, Batch 500/1000: LR=2.35e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 685, Batch 1000/1000: LR=2.35e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 685 Train Time 38.65428066253662s

Training epoch 686, Batch 500/1000: LR=2.33e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 686, Batch 1000/1000: LR=2.33e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 686 Train Time 38.50278615951538s

Training epoch 687, Batch 500/1000: LR=2.32e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 687, Batch 1000/1000: LR=2.32e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 687 Train Time 38.52117419242859s

Training epoch 688, Batch 500/1000: LR=2.31e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 688, Batch 1000/1000: LR=2.31e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 688 Train Time 38.51589894294739s

Training epoch 689, Batch 500/1000: LR=2.29e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 689, Batch 1000/1000: LR=2.29e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 689 Train Time 38.51832938194275s

Training epoch 690, Batch 500/1000: LR=2.28e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 690, Batch 1000/1000: LR=2.28e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 690 Train Time 38.53406524658203s

Training epoch 691, Batch 500/1000: LR=2.27e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 691, Batch 1000/1000: LR=2.27e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 691 Train Time 38.52043008804321s

Training epoch 692, Batch 500/1000: LR=2.25e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 692, Batch 1000/1000: LR=2.25e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 692 Train Time 38.545045614242554s

Training epoch 693, Batch 500/1000: LR=2.24e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 693, Batch 1000/1000: LR=2.24e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 693 Train Time 38.50476264953613s

Training epoch 694, Batch 500/1000: LR=2.23e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 694, Batch 1000/1000: LR=2.23e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 694 Train Time 38.51267671585083s

Training epoch 695, Batch 500/1000: LR=2.22e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 695, Batch 1000/1000: LR=2.22e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 695 Train Time 38.64285659790039s

Training epoch 696, Batch 500/1000: LR=2.20e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 696, Batch 1000/1000: LR=2.20e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 696 Train Time 38.494592905044556s

Training epoch 697, Batch 500/1000: LR=2.19e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 697, Batch 1000/1000: LR=2.19e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 697 Train Time 38.60019373893738s

Training epoch 698, Batch 500/1000: LR=2.18e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 698, Batch 1000/1000: LR=2.18e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 698 Train Time 38.48962903022766s

Training epoch 699, Batch 500/1000: LR=2.17e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 699, Batch 1000/1000: LR=2.17e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 699 Train Time 38.510353803634644s

Training epoch 700, Batch 500/1000: LR=2.15e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 700, Batch 1000/1000: LR=2.15e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 700 Train Time 38.48947286605835s

Training epoch 701, Batch 500/1000: LR=2.14e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 701, Batch 1000/1000: LR=2.14e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 701 Train Time 38.53931403160095s

Training epoch 702, Batch 500/1000: LR=2.13e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 702, Batch 1000/1000: LR=2.13e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 702 Train Time 38.52527046203613s

Training epoch 703, Batch 500/1000: LR=2.12e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 703, Batch 1000/1000: LR=2.12e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 703 Train Time 38.522197246551514s

Training epoch 704, Batch 500/1000: LR=2.10e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 704, Batch 1000/1000: LR=2.10e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 704 Train Time 38.63190698623657s

Training epoch 705, Batch 500/1000: LR=2.09e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 705, Batch 1000/1000: LR=2.09e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 705 Train Time 38.51349973678589s

Training epoch 706, Batch 500/1000: LR=2.08e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 706, Batch 1000/1000: LR=2.08e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 706 Train Time 38.54459524154663s

Training epoch 707, Batch 500/1000: LR=2.07e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 707, Batch 1000/1000: LR=2.07e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 707 Train Time 38.50983762741089s

Training epoch 708, Batch 500/1000: LR=2.05e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 708, Batch 1000/1000: LR=2.05e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 708 Train Time 38.52133250236511s

Training epoch 709, Batch 500/1000: LR=2.04e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 709, Batch 1000/1000: LR=2.04e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 709 Train Time 38.521984338760376s

Training epoch 710, Batch 500/1000: LR=2.03e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 710, Batch 1000/1000: LR=2.03e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 710 Train Time 38.50959825515747s

Training epoch 711, Batch 500/1000: LR=2.02e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 711, Batch 1000/1000: LR=2.02e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 711 Train Time 105.41638517379761s

Training epoch 712, Batch 500/1000: LR=2.00e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 712, Batch 1000/1000: LR=2.00e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 712 Train Time 39.20887804031372s

Training epoch 713, Batch 500/1000: LR=1.99e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 713, Batch 1000/1000: LR=1.99e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 713 Train Time 38.94280934333801s

Training epoch 714, Batch 500/1000: LR=1.98e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 714, Batch 1000/1000: LR=1.98e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 714 Train Time 38.94643783569336s

Training epoch 715, Batch 500/1000: LR=1.97e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 715, Batch 1000/1000: LR=1.97e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 715 Train Time 38.975446462631226s

Training epoch 716, Batch 500/1000: LR=1.96e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 716, Batch 1000/1000: LR=1.96e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 716 Train Time 38.94413495063782s

Training epoch 717, Batch 500/1000: LR=1.94e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 717, Batch 1000/1000: LR=1.94e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 717 Train Time 38.93386673927307s

Training epoch 718, Batch 500/1000: LR=1.93e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 718, Batch 1000/1000: LR=1.93e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 718 Train Time 38.93976879119873s

Training epoch 719, Batch 500/1000: LR=1.92e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 719, Batch 1000/1000: LR=1.92e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 719 Train Time 39.03705072402954s

Training epoch 720, Batch 500/1000: LR=1.91e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 720, Batch 1000/1000: LR=1.91e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 720 Train Time 38.97194790840149s

Training epoch 721, Batch 500/1000: LR=1.89e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 721, Batch 1000/1000: LR=1.89e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 721 Train Time 38.95211052894592s

Training epoch 722, Batch 500/1000: LR=1.88e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 722, Batch 1000/1000: LR=1.88e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 722 Train Time 38.98989653587341s

Training epoch 723, Batch 500/1000: LR=1.87e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 723, Batch 1000/1000: LR=1.87e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 723 Train Time 38.94938325881958s

Training epoch 724, Batch 500/1000: LR=1.86e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 724, Batch 1000/1000: LR=1.86e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 724 Train Time 38.937819719314575s

Training epoch 725, Batch 500/1000: LR=1.85e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 725, Batch 1000/1000: LR=1.85e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 725 Train Time 38.961029052734375s

Training epoch 726, Batch 500/1000: LR=1.84e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 726, Batch 1000/1000: LR=1.84e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 726 Train Time 38.96435332298279s

Training epoch 727, Batch 500/1000: LR=1.82e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 727, Batch 1000/1000: LR=1.82e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 727 Train Time 39.04904913902283s

Training epoch 728, Batch 500/1000: LR=1.81e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 728, Batch 1000/1000: LR=1.81e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 728 Train Time 39.088643312454224s

Training epoch 729, Batch 500/1000: LR=1.80e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 729, Batch 1000/1000: LR=1.80e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 729 Train Time 38.940062522888184s

Training epoch 730, Batch 500/1000: LR=1.79e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 730, Batch 1000/1000: LR=1.79e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 730 Train Time 38.93464231491089s

Training epoch 731, Batch 500/1000: LR=1.78e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 731, Batch 1000/1000: LR=1.78e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 731 Train Time 38.94683122634888s

Training epoch 732, Batch 500/1000: LR=1.76e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 732, Batch 1000/1000: LR=1.76e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 732 Train Time 38.931720495224s

Training epoch 733, Batch 500/1000: LR=1.75e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 733, Batch 1000/1000: LR=1.75e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 733 Train Time 38.93497014045715s

Training epoch 734, Batch 500/1000: LR=1.74e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 734, Batch 1000/1000: LR=1.74e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 734 Train Time 38.93872547149658s

Training epoch 735, Batch 500/1000: LR=1.73e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 735, Batch 1000/1000: LR=1.73e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 735 Train Time 38.96662402153015s

Training epoch 736, Batch 500/1000: LR=1.72e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 736, Batch 1000/1000: LR=1.72e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 736 Train Time 38.97944474220276s

Training epoch 737, Batch 500/1000: LR=1.71e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 737, Batch 1000/1000: LR=1.71e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 737 Train Time 39.067718744277954s

Training epoch 738, Batch 500/1000: LR=1.70e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 738, Batch 1000/1000: LR=1.70e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 738 Train Time 38.91583514213562s

Training epoch 739, Batch 500/1000: LR=1.68e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 739, Batch 1000/1000: LR=1.68e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 739 Train Time 38.92556929588318s

Training epoch 740, Batch 500/1000: LR=1.67e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 740, Batch 1000/1000: LR=1.67e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 740 Train Time 38.92594766616821s

Training epoch 741, Batch 500/1000: LR=1.66e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 741, Batch 1000/1000: LR=1.66e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 741 Train Time 38.93288803100586s

Training epoch 742, Batch 500/1000: LR=1.65e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 742, Batch 1000/1000: LR=1.65e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 742 Train Time 39.035834074020386s

Training epoch 743, Batch 500/1000: LR=1.64e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 743, Batch 1000/1000: LR=1.64e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 743 Train Time 38.96092939376831s

Training epoch 744, Batch 500/1000: LR=1.63e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 744, Batch 1000/1000: LR=1.63e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 744 Train Time 38.924293994903564s

Training epoch 745, Batch 500/1000: LR=1.62e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 745, Batch 1000/1000: LR=1.62e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 745 Train Time 38.90859508514404s

Training epoch 746, Batch 500/1000: LR=1.61e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 746, Batch 1000/1000: LR=1.61e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 746 Train Time 39.05046844482422s

Training epoch 747, Batch 500/1000: LR=1.59e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 747, Batch 1000/1000: LR=1.59e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 747 Train Time 38.90516710281372s

Training epoch 748, Batch 500/1000: LR=1.58e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 748, Batch 1000/1000: LR=1.58e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.08e-01
Epoch 748 Train Time 38.950981855392456s

Training epoch 749, Batch 500/1000: LR=1.57e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 749, Batch 1000/1000: LR=1.57e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 749 Train Time 38.897265672683716s

Training epoch 750, Batch 500/1000: LR=1.56e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 750, Batch 1000/1000: LR=1.56e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 750 Train Time 38.92702889442444s

Training epoch 751, Batch 500/1000: LR=1.55e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.09e-01
Training epoch 751, Batch 1000/1000: LR=1.55e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 751 Train Time 38.927714586257935s

Training epoch 752, Batch 500/1000: LR=1.54e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 752, Batch 1000/1000: LR=1.54e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Epoch 752 Train Time 38.59609389305115s

Training epoch 753, Batch 500/1000: LR=1.53e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 753, Batch 1000/1000: LR=1.53e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 753 Train Time 38.53810405731201s

Training epoch 754, Batch 500/1000: LR=1.52e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 754, Batch 1000/1000: LR=1.52e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 754 Train Time 38.57542943954468s

Training epoch 755, Batch 500/1000: LR=1.51e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 755, Batch 1000/1000: LR=1.51e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 755 Train Time 38.562849044799805s

Training epoch 756, Batch 500/1000: LR=1.50e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 756, Batch 1000/1000: LR=1.50e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 756 Train Time 38.670047998428345s

Training epoch 757, Batch 500/1000: LR=1.48e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 757, Batch 1000/1000: LR=1.48e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 757 Train Time 38.54476714134216s

Training epoch 758, Batch 500/1000: LR=1.47e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 758, Batch 1000/1000: LR=1.47e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 758 Train Time 64.63482856750488s

Training epoch 759, Batch 500/1000: LR=1.46e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 759, Batch 1000/1000: LR=1.46e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 759 Train Time 39.160524129867554s

Training epoch 760, Batch 500/1000: LR=1.45e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 760, Batch 1000/1000: LR=1.45e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 760 Train Time 38.59362864494324s

Training epoch 761, Batch 500/1000: LR=1.44e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 761, Batch 1000/1000: LR=1.44e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 761 Train Time 38.55598258972168s

Training epoch 762, Batch 500/1000: LR=1.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 762, Batch 1000/1000: LR=1.43e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 762 Train Time 38.55000686645508s

Training epoch 763, Batch 500/1000: LR=1.42e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 763, Batch 1000/1000: LR=1.42e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 763 Train Time 38.55604386329651s

Training epoch 764, Batch 500/1000: LR=1.41e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 764, Batch 1000/1000: LR=1.41e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 764 Train Time 38.521164417266846s

Training epoch 765, Batch 500/1000: LR=1.40e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 765, Batch 1000/1000: LR=1.40e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 765 Train Time 38.56611895561218s

Training epoch 766, Batch 500/1000: LR=1.39e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 766, Batch 1000/1000: LR=1.39e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 766 Train Time 38.56884837150574s

Training epoch 767, Batch 500/1000: LR=1.38e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 767, Batch 1000/1000: LR=1.38e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 767 Train Time 38.56002879142761s

Training epoch 768, Batch 500/1000: LR=1.37e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 768, Batch 1000/1000: LR=1.37e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 768 Train Time 38.65961718559265s

Training epoch 769, Batch 500/1000: LR=1.36e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 769, Batch 1000/1000: LR=1.36e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 769 Train Time 38.55473709106445s

Training epoch 770, Batch 500/1000: LR=1.35e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 770, Batch 1000/1000: LR=1.35e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 770 Train Time 38.534923791885376s

Training epoch 771, Batch 500/1000: LR=1.34e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 771, Batch 1000/1000: LR=1.34e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 771 Train Time 38.558334827423096s

Training epoch 772, Batch 500/1000: LR=1.33e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 772, Batch 1000/1000: LR=1.33e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 772 Train Time 38.55199313163757s

Training epoch 773, Batch 500/1000: LR=1.32e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 773, Batch 1000/1000: LR=1.32e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 773 Train Time 38.523263931274414s

Training epoch 774, Batch 500/1000: LR=1.31e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 774, Batch 1000/1000: LR=1.31e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 774 Train Time 38.59640145301819s

Training epoch 775, Batch 500/1000: LR=1.30e-05, Loss=2.90e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 775, Batch 1000/1000: LR=1.30e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 775 Train Time 38.56861996650696s

Training epoch 776, Batch 500/1000: LR=1.29e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 776, Batch 1000/1000: LR=1.29e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 776 Train Time 38.550163984298706s

Training epoch 777, Batch 500/1000: LR=1.28e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 777, Batch 1000/1000: LR=1.28e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 777 Train Time 38.680078983306885s

Training epoch 778, Batch 500/1000: LR=1.27e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 778, Batch 1000/1000: LR=1.27e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 778 Train Time 38.5408034324646s

Training epoch 779, Batch 500/1000: LR=1.26e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 779, Batch 1000/1000: LR=1.26e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 779 Train Time 38.54123115539551s

Training epoch 780, Batch 500/1000: LR=1.25e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 780, Batch 1000/1000: LR=1.25e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 780 Train Time 38.55719590187073s

Training epoch 781, Batch 500/1000: LR=1.24e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 781, Batch 1000/1000: LR=1.24e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 781 Train Time 38.55104923248291s

Training epoch 782, Batch 500/1000: LR=1.23e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 782, Batch 1000/1000: LR=1.23e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 782 Train Time 38.54893779754639s

Training epoch 783, Batch 500/1000: LR=1.22e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 783, Batch 1000/1000: LR=1.22e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 783 Train Time 38.55388402938843s

Training epoch 784, Batch 500/1000: LR=1.21e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 784, Batch 1000/1000: LR=1.21e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 784 Train Time 38.56316518783569s

Training epoch 785, Batch 500/1000: LR=1.20e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 785, Batch 1000/1000: LR=1.20e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 785 Train Time 38.59164547920227s

Training epoch 786, Batch 500/1000: LR=1.19e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 786, Batch 1000/1000: LR=1.19e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 786 Train Time 38.65495467185974s

Training epoch 787, Batch 500/1000: LR=1.18e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 787, Batch 1000/1000: LR=1.18e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 787 Train Time 38.55954551696777s

Training epoch 788, Batch 500/1000: LR=1.17e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 788, Batch 1000/1000: LR=1.17e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 788 Train Time 38.56629800796509s

Training epoch 789, Batch 500/1000: LR=1.16e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 789, Batch 1000/1000: LR=1.16e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 789 Train Time 38.53387761116028s

Training epoch 790, Batch 500/1000: LR=1.15e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 790, Batch 1000/1000: LR=1.15e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 790 Train Time 38.576728105545044s

Training epoch 791, Batch 500/1000: LR=1.14e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 791, Batch 1000/1000: LR=1.14e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 791 Train Time 38.54751443862915s

Training epoch 792, Batch 500/1000: LR=1.13e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 792, Batch 1000/1000: LR=1.13e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 792 Train Time 38.53589582443237s

Training epoch 793, Batch 500/1000: LR=1.12e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 793, Batch 1000/1000: LR=1.12e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 793 Train Time 38.53738617897034s

Training epoch 794, Batch 500/1000: LR=1.11e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 794, Batch 1000/1000: LR=1.11e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 794 Train Time 38.51415967941284s

Training epoch 795, Batch 500/1000: LR=1.10e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 795, Batch 1000/1000: LR=1.10e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 795 Train Time 38.61681342124939s

Training epoch 796, Batch 500/1000: LR=1.09e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 796, Batch 1000/1000: LR=1.09e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 796 Train Time 38.62058091163635s

Training epoch 797, Batch 500/1000: LR=1.08e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 797, Batch 1000/1000: LR=1.08e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 797 Train Time 38.519195556640625s

Training epoch 798, Batch 500/1000: LR=1.07e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 798, Batch 1000/1000: LR=1.07e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 798 Train Time 38.5414879322052s

Training epoch 799, Batch 500/1000: LR=1.06e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 799, Batch 1000/1000: LR=1.06e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 799 Train Time 38.53664803504944s

Training epoch 800, Batch 500/1000: LR=1.05e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 800, Batch 1000/1000: LR=1.05e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 800 Train Time 38.51823019981384s

Training epoch 801, Batch 500/1000: LR=1.05e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 801, Batch 1000/1000: LR=1.05e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 801 Train Time 38.54723811149597s

Training epoch 802, Batch 500/1000: LR=1.04e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 802, Batch 1000/1000: LR=1.04e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 802 Train Time 38.54105877876282s

Training epoch 803, Batch 500/1000: LR=1.03e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 803, Batch 1000/1000: LR=1.03e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 803 Train Time 38.561744689941406s

Training epoch 804, Batch 500/1000: LR=1.02e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 804, Batch 1000/1000: LR=1.02e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 804 Train Time 38.5540452003479s

Training epoch 805, Batch 500/1000: LR=1.01e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 805, Batch 1000/1000: LR=1.01e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 805 Train Time 38.73992896080017s

Training epoch 806, Batch 500/1000: LR=1.00e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 806, Batch 1000/1000: LR=1.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 806 Train Time 38.52356672286987s

Training epoch 807, Batch 500/1000: LR=9.91e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 807, Batch 1000/1000: LR=9.91e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 807 Train Time 38.55267024040222s

Training epoch 808, Batch 500/1000: LR=9.82e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 808, Batch 1000/1000: LR=9.82e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 808 Train Time 94.51123023033142s

Training epoch 809, Batch 500/1000: LR=9.74e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 809, Batch 1000/1000: LR=9.74e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 809 Train Time 39.422181367874146s

Training epoch 810, Batch 500/1000: LR=9.65e-06, Loss=2.92e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 810, Batch 1000/1000: LR=9.65e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 810 Train Time 39.05156970024109s

Training epoch 811, Batch 500/1000: LR=9.56e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 811, Batch 1000/1000: LR=9.56e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 811 Train Time 38.957863330841064s

Training epoch 812, Batch 500/1000: LR=9.47e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 812, Batch 1000/1000: LR=9.47e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 812 Train Time 38.94650363922119s

Training epoch 813, Batch 500/1000: LR=9.39e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 813, Batch 1000/1000: LR=9.39e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 813 Train Time 38.97011160850525s

Training epoch 814, Batch 500/1000: LR=9.30e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.09e-01
Training epoch 814, Batch 1000/1000: LR=9.30e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 814 Train Time 38.91608738899231s

Training epoch 815, Batch 500/1000: LR=9.21e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 815, Batch 1000/1000: LR=9.21e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 815 Train Time 39.48752307891846s

Training epoch 816, Batch 500/1000: LR=9.13e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 816, Batch 1000/1000: LR=9.13e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 816 Train Time 39.06817388534546s

Training epoch 817, Batch 500/1000: LR=9.04e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 817, Batch 1000/1000: LR=9.04e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 817 Train Time 38.96673583984375s

Training epoch 818, Batch 500/1000: LR=8.96e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 818, Batch 1000/1000: LR=8.96e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 818 Train Time 38.96023893356323s

Training epoch 819, Batch 500/1000: LR=8.87e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 819, Batch 1000/1000: LR=8.87e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 819 Train Time 39.48917579650879s

Training epoch 820, Batch 500/1000: LR=8.79e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 820, Batch 1000/1000: LR=8.79e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 820 Train Time 38.978448152542114s

Training epoch 821, Batch 500/1000: LR=8.71e-06, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 821, Batch 1000/1000: LR=8.71e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 821 Train Time 38.951101303100586s

Training epoch 822, Batch 500/1000: LR=8.62e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 822, Batch 1000/1000: LR=8.62e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Epoch 822 Train Time 38.95002508163452s

Training epoch 823, Batch 500/1000: LR=8.54e-06, Loss=2.92e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 823, Batch 1000/1000: LR=8.54e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 823 Train Time 38.940837144851685s

Training epoch 824, Batch 500/1000: LR=8.46e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 824, Batch 1000/1000: LR=8.46e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 824 Train Time 38.96649885177612s

Training epoch 825, Batch 500/1000: LR=8.38e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 825, Batch 1000/1000: LR=8.38e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 825 Train Time 38.94371438026428s

Training epoch 826, Batch 500/1000: LR=8.29e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 826, Batch 1000/1000: LR=8.29e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 826 Train Time 38.94312906265259s

Training epoch 827, Batch 500/1000: LR=8.21e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 827, Batch 1000/1000: LR=8.21e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 827 Train Time 39.045963764190674s

Training epoch 828, Batch 500/1000: LR=8.13e-06, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 828, Batch 1000/1000: LR=8.13e-06, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 828 Train Time 38.935760736465454s

Training epoch 829, Batch 500/1000: LR=8.05e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 829, Batch 1000/1000: LR=8.05e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 829 Train Time 38.94811487197876s

Training epoch 830, Batch 500/1000: LR=7.97e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 830, Batch 1000/1000: LR=7.97e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 830 Train Time 38.95072031021118s

Training epoch 831, Batch 500/1000: LR=7.89e-06, Loss=2.84e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 831, Batch 1000/1000: LR=7.89e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.10e-01
Epoch 831 Train Time 38.930864572525024s

Training epoch 832, Batch 500/1000: LR=7.81e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 832, Batch 1000/1000: LR=7.81e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 832 Train Time 38.938934564590454s

Training epoch 833, Batch 500/1000: LR=7.74e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 833, Batch 1000/1000: LR=7.74e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 833 Train Time 38.91396737098694s

Training epoch 834, Batch 500/1000: LR=7.66e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 834, Batch 1000/1000: LR=7.66e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 834 Train Time 38.96406555175781s

Training epoch 835, Batch 500/1000: LR=7.58e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 835, Batch 1000/1000: LR=7.58e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 835 Train Time 39.060770988464355s

Training epoch 836, Batch 500/1000: LR=7.50e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 836, Batch 1000/1000: LR=7.50e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 836 Train Time 38.92349910736084s

Training epoch 837, Batch 500/1000: LR=7.43e-06, Loss=2.87e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 837, Batch 1000/1000: LR=7.43e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Epoch 837 Train Time 38.945573806762695s

Training epoch 838, Batch 500/1000: LR=7.35e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 838, Batch 1000/1000: LR=7.35e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 838 Train Time 38.9362256526947s

Training epoch 839, Batch 500/1000: LR=7.27e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 839, Batch 1000/1000: LR=7.27e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 839 Train Time 38.95851016044617s

Training epoch 840, Batch 500/1000: LR=7.20e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 840, Batch 1000/1000: LR=7.20e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 840 Train Time 38.94776964187622s

Training epoch 841, Batch 500/1000: LR=7.12e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 841, Batch 1000/1000: LR=7.12e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 841 Train Time 38.96140241622925s

Training epoch 842, Batch 500/1000: LR=7.05e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 842, Batch 1000/1000: LR=7.05e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 842 Train Time 38.94190859794617s

Training epoch 843, Batch 500/1000: LR=6.97e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 843, Batch 1000/1000: LR=6.97e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 843 Train Time 38.92405891418457s

Training epoch 844, Batch 500/1000: LR=6.90e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 844, Batch 1000/1000: LR=6.90e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 844 Train Time 39.07091999053955s

Training epoch 845, Batch 500/1000: LR=6.83e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 845, Batch 1000/1000: LR=6.83e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 845 Train Time 38.922075271606445s

Training epoch 846, Batch 500/1000: LR=6.75e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 846, Batch 1000/1000: LR=6.75e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 846 Train Time 38.931458473205566s

Training epoch 847, Batch 500/1000: LR=6.68e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 847, Batch 1000/1000: LR=6.68e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 847 Train Time 38.94335436820984s

Training epoch 848, Batch 500/1000: LR=6.61e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 848, Batch 1000/1000: LR=6.61e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 848 Train Time 39.05310344696045s

Training epoch 849, Batch 500/1000: LR=6.54e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 849, Batch 1000/1000: LR=6.54e-06, Loss=2.90e-02 BER=1.16e-02 FER=1.09e-01
Epoch 849 Train Time 39.03985667228699s

Training epoch 850, Batch 500/1000: LR=6.47e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 850, Batch 1000/1000: LR=6.47e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 850 Train Time 38.9612398147583s

Training epoch 851, Batch 500/1000: LR=6.40e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 851, Batch 1000/1000: LR=6.40e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 851 Train Time 38.925299644470215s

Training epoch 852, Batch 500/1000: LR=6.32e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 852, Batch 1000/1000: LR=6.32e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 852 Train Time 38.8209068775177s

Training epoch 853, Batch 500/1000: LR=6.25e-06, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 853, Batch 1000/1000: LR=6.25e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 853 Train Time 38.56906700134277s

Training epoch 854, Batch 500/1000: LR=6.19e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.10e-01
Training epoch 854, Batch 1000/1000: LR=6.19e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 854 Train Time 38.65342330932617s

Training epoch 855, Batch 500/1000: LR=6.12e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 855, Batch 1000/1000: LR=6.12e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 855 Train Time 87.77493190765381s

Training epoch 856, Batch 500/1000: LR=6.05e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 856, Batch 1000/1000: LR=6.05e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 856 Train Time 39.08124589920044s

Training epoch 857, Batch 500/1000: LR=5.98e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 857, Batch 1000/1000: LR=5.98e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 857 Train Time 38.560601472854614s

Training epoch 858, Batch 500/1000: LR=5.91e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 858, Batch 1000/1000: LR=5.91e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 858 Train Time 38.550559997558594s

Training epoch 859, Batch 500/1000: LR=5.84e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 859, Batch 1000/1000: LR=5.84e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 859 Train Time 38.5483283996582s

Training epoch 860, Batch 500/1000: LR=5.78e-06, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 860, Batch 1000/1000: LR=5.78e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 860 Train Time 38.57205653190613s

Training epoch 861, Batch 500/1000: LR=5.71e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 861, Batch 1000/1000: LR=5.71e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 861 Train Time 38.55987238883972s

Training epoch 862, Batch 500/1000: LR=5.65e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 862, Batch 1000/1000: LR=5.65e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 862 Train Time 38.66006803512573s

Training epoch 863, Batch 500/1000: LR=5.58e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 863, Batch 1000/1000: LR=5.58e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 863 Train Time 38.5811710357666s

Training epoch 864, Batch 500/1000: LR=5.51e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 864, Batch 1000/1000: LR=5.51e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 864 Train Time 38.61545181274414s

Training epoch 865, Batch 500/1000: LR=5.45e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 865, Batch 1000/1000: LR=5.45e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 865 Train Time 38.582502365112305s

Training epoch 866, Batch 500/1000: LR=5.39e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 866, Batch 1000/1000: LR=5.39e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 866 Train Time 38.55813503265381s

Training epoch 867, Batch 500/1000: LR=5.32e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 867, Batch 1000/1000: LR=5.32e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 867 Train Time 38.53843832015991s

Training epoch 868, Batch 500/1000: LR=5.26e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 868, Batch 1000/1000: LR=5.26e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 868 Train Time 38.54151129722595s

Training epoch 869, Batch 500/1000: LR=5.20e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 869, Batch 1000/1000: LR=5.20e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 869 Train Time 38.980591773986816s

Training epoch 870, Batch 500/1000: LR=5.13e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 870, Batch 1000/1000: LR=5.13e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 870 Train Time 38.69677209854126s

Training epoch 871, Batch 500/1000: LR=5.07e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 871, Batch 1000/1000: LR=5.07e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 871 Train Time 38.602816104888916s

Training epoch 872, Batch 500/1000: LR=5.01e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 872, Batch 1000/1000: LR=5.01e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 872 Train Time 38.56109666824341s

Training epoch 873, Batch 500/1000: LR=4.95e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 873, Batch 1000/1000: LR=4.95e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 873 Train Time 38.54042077064514s

Training epoch 874, Batch 500/1000: LR=4.89e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 874, Batch 1000/1000: LR=4.89e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 874 Train Time 38.53399920463562s

Training epoch 875, Batch 500/1000: LR=4.83e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 875, Batch 1000/1000: LR=4.83e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 875 Train Time 38.53874707221985s

Training epoch 876, Batch 500/1000: LR=4.77e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 876, Batch 1000/1000: LR=4.77e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 876 Train Time 38.54791808128357s

Training epoch 877, Batch 500/1000: LR=4.71e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 877, Batch 1000/1000: LR=4.71e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 877 Train Time 38.53084373474121s

Training epoch 878, Batch 500/1000: LR=4.65e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 878, Batch 1000/1000: LR=4.65e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 878 Train Time 38.56906461715698s

Training epoch 879, Batch 500/1000: LR=4.59e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 879, Batch 1000/1000: LR=4.59e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 879 Train Time 38.64547371864319s

Training epoch 880, Batch 500/1000: LR=4.53e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 880, Batch 1000/1000: LR=4.53e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 880 Train Time 38.54680395126343s

Training epoch 881, Batch 500/1000: LR=4.48e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 881, Batch 1000/1000: LR=4.48e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 881 Train Time 38.55556678771973s

Training epoch 882, Batch 500/1000: LR=4.42e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 882, Batch 1000/1000: LR=4.42e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 882 Train Time 38.547558546066284s

Training epoch 883, Batch 500/1000: LR=4.36e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 883, Batch 1000/1000: LR=4.36e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 883 Train Time 38.515429735183716s

Training epoch 884, Batch 500/1000: LR=4.31e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 884, Batch 1000/1000: LR=4.31e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 884 Train Time 38.54594445228577s

Training epoch 885, Batch 500/1000: LR=4.25e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 885, Batch 1000/1000: LR=4.25e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 885 Train Time 38.537405490875244s

Training epoch 886, Batch 500/1000: LR=4.20e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 886, Batch 1000/1000: LR=4.20e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 886 Train Time 38.53442573547363s

Training epoch 887, Batch 500/1000: LR=4.14e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 887, Batch 1000/1000: LR=4.14e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 887 Train Time 38.5586793422699s

Training epoch 888, Batch 500/1000: LR=4.09e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 888, Batch 1000/1000: LR=4.09e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 888 Train Time 38.63490962982178s

Training epoch 889, Batch 500/1000: LR=4.03e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 889, Batch 1000/1000: LR=4.03e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 889 Train Time 38.52148938179016s

Training epoch 890, Batch 500/1000: LR=3.98e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 890, Batch 1000/1000: LR=3.98e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 890 Train Time 38.50371074676514s

Training epoch 891, Batch 500/1000: LR=3.93e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 891, Batch 1000/1000: LR=3.93e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 891 Train Time 38.537591218948364s

Training epoch 892, Batch 500/1000: LR=3.87e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 892, Batch 1000/1000: LR=3.87e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 892 Train Time 38.517722368240356s

Training epoch 893, Batch 500/1000: LR=3.82e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 893, Batch 1000/1000: LR=3.82e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 893 Train Time 38.540125608444214s

Training epoch 894, Batch 500/1000: LR=3.77e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 894, Batch 1000/1000: LR=3.77e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Epoch 894 Train Time 38.565284729003906s

Training epoch 895, Batch 500/1000: LR=3.72e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 895, Batch 1000/1000: LR=3.72e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 895 Train Time 38.54468870162964s

Training epoch 896, Batch 500/1000: LR=3.67e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 896, Batch 1000/1000: LR=3.67e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Epoch 896 Train Time 38.574628829956055s

Training epoch 897, Batch 500/1000: LR=3.62e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 897, Batch 1000/1000: LR=3.62e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 897 Train Time 38.603100061416626s

Training epoch 898, Batch 500/1000: LR=3.57e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 898, Batch 1000/1000: LR=3.57e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 898 Train Time 38.53944969177246s

Training epoch 899, Batch 500/1000: LR=3.52e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 899, Batch 1000/1000: LR=3.52e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 899 Train Time 38.507819175720215s

Training epoch 900, Batch 500/1000: LR=3.47e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 900, Batch 1000/1000: LR=3.47e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.09e-01
Epoch 900 Train Time 38.508228063583374s


Test Loss 4: 8.90e-03 5: 9.30e-04 6: 4.37e-05
Test FER 4: 3.97e-02 5: 4.36e-03 6: 2.16e-04
Test BER 4: 3.26e-03 5: 3.10e-04 6: 1.34e-05
Test -ln(BER) 4: 5.73e+00 5: 8.08e+00 6: 1.12e+01
# of testing samples: [100352.0, 100352.0, 466944.0]
 Test Time 173.87202382087708 s

Training epoch 901, Batch 500/1000: LR=3.42e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 901, Batch 1000/1000: LR=3.42e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 901 Train Time 38.62970995903015s

Training epoch 902, Batch 500/1000: LR=3.37e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 902, Batch 1000/1000: LR=3.37e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Epoch 902 Train Time 38.6570258140564s

Training epoch 903, Batch 500/1000: LR=3.33e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 903, Batch 1000/1000: LR=3.33e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Epoch 903 Train Time 38.521114110946655s

Training epoch 904, Batch 500/1000: LR=3.28e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 904, Batch 1000/1000: LR=3.28e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 904 Train Time 39.27532696723938s

Training epoch 905, Batch 500/1000: LR=3.23e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 905, Batch 1000/1000: LR=3.23e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 905 Train Time 39.2361364364624s

Training epoch 906, Batch 500/1000: LR=3.19e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 906, Batch 1000/1000: LR=3.19e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 906 Train Time 39.30594992637634s

Training epoch 907, Batch 500/1000: LR=3.14e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 907, Batch 1000/1000: LR=3.14e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 907 Train Time 40.66161108016968s

Training epoch 908, Batch 500/1000: LR=3.10e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 908, Batch 1000/1000: LR=3.10e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 908 Train Time 39.61595630645752s

Training epoch 909, Batch 500/1000: LR=3.05e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 909, Batch 1000/1000: LR=3.05e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 909 Train Time 38.73614573478699s

Training epoch 910, Batch 500/1000: LR=3.01e-06, Loss=2.90e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 910, Batch 1000/1000: LR=3.01e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 910 Train Time 38.53321671485901s

Training epoch 911, Batch 500/1000: LR=2.97e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 911, Batch 1000/1000: LR=2.97e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 911 Train Time 38.65049624443054s

Training epoch 912, Batch 500/1000: LR=2.92e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 912, Batch 1000/1000: LR=2.92e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 912 Train Time 38.51204466819763s

Training epoch 913, Batch 500/1000: LR=2.88e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 913, Batch 1000/1000: LR=2.88e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 913 Train Time 38.494104862213135s

Training epoch 914, Batch 500/1000: LR=2.84e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 914, Batch 1000/1000: LR=2.84e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 914 Train Time 38.48789048194885s

Training epoch 915, Batch 500/1000: LR=2.80e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 915, Batch 1000/1000: LR=2.80e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 915 Train Time 38.52373290061951s

Training epoch 916, Batch 500/1000: LR=2.75e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 916, Batch 1000/1000: LR=2.75e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 916 Train Time 38.539413928985596s

Training epoch 917, Batch 500/1000: LR=2.71e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 917, Batch 1000/1000: LR=2.71e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 917 Train Time 38.490941286087036s

Training epoch 918, Batch 500/1000: LR=2.67e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 918, Batch 1000/1000: LR=2.67e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 918 Train Time 38.500049114227295s

Training epoch 919, Batch 500/1000: LR=2.63e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 919, Batch 1000/1000: LR=2.63e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 919 Train Time 38.52220368385315s

Training epoch 920, Batch 500/1000: LR=2.59e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 920, Batch 1000/1000: LR=2.59e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 920 Train Time 38.47520470619202s

Training epoch 921, Batch 500/1000: LR=2.56e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 921, Batch 1000/1000: LR=2.56e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 921 Train Time 38.54225516319275s

Training epoch 922, Batch 500/1000: LR=2.52e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 922, Batch 1000/1000: LR=2.52e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 922 Train Time 38.5413715839386s

Training epoch 923, Batch 500/1000: LR=2.48e-06, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 923, Batch 1000/1000: LR=2.48e-06, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Epoch 923 Train Time 38.50937461853027s

Training epoch 924, Batch 500/1000: LR=2.44e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 924, Batch 1000/1000: LR=2.44e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 924 Train Time 38.99786615371704s

Training epoch 925, Batch 500/1000: LR=2.40e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 925, Batch 1000/1000: LR=2.40e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 925 Train Time 38.91972351074219s

Training epoch 926, Batch 500/1000: LR=2.37e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 926, Batch 1000/1000: LR=2.37e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 926 Train Time 38.493106842041016s

Training epoch 927, Batch 500/1000: LR=2.33e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 927, Batch 1000/1000: LR=2.33e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 927 Train Time 38.549965381622314s

Training epoch 928, Batch 500/1000: LR=2.30e-06, Loss=2.92e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 928, Batch 1000/1000: LR=2.30e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 928 Train Time 38.51080775260925s

Training epoch 929, Batch 500/1000: LR=2.26e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 929, Batch 1000/1000: LR=2.26e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 929 Train Time 38.49211573600769s

Training epoch 930, Batch 500/1000: LR=2.23e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 930, Batch 1000/1000: LR=2.23e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 930 Train Time 38.53249716758728s

Training epoch 931, Batch 500/1000: LR=2.19e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 931, Batch 1000/1000: LR=2.19e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 931 Train Time 38.52736186981201s

Training epoch 932, Batch 500/1000: LR=2.16e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 932, Batch 1000/1000: LR=2.16e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 932 Train Time 38.54363012313843s

Training epoch 933, Batch 500/1000: LR=2.13e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 933, Batch 1000/1000: LR=2.13e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 933 Train Time 38.52851724624634s

Training epoch 934, Batch 500/1000: LR=2.09e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 934, Batch 1000/1000: LR=2.09e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 934 Train Time 38.619436264038086s

Training epoch 935, Batch 500/1000: LR=2.06e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 935, Batch 1000/1000: LR=2.06e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 935 Train Time 38.5421884059906s

Training epoch 936, Batch 500/1000: LR=2.03e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 936, Batch 1000/1000: LR=2.03e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 936 Train Time 38.52414417266846s

Training epoch 937, Batch 500/1000: LR=2.00e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 937, Batch 1000/1000: LR=2.00e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 937 Train Time 38.51215171813965s

Training epoch 938, Batch 500/1000: LR=1.97e-06, Loss=2.87e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 938, Batch 1000/1000: LR=1.97e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 938 Train Time 38.51111102104187s

Training epoch 939, Batch 500/1000: LR=1.94e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 939, Batch 1000/1000: LR=1.94e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 939 Train Time 38.52461504936218s

Training epoch 940, Batch 500/1000: LR=1.91e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 940, Batch 1000/1000: LR=1.91e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 940 Train Time 38.50709915161133s

Training epoch 941, Batch 500/1000: LR=1.88e-06, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 941, Batch 1000/1000: LR=1.88e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 941 Train Time 38.51295804977417s

Training epoch 942, Batch 500/1000: LR=1.85e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 942, Batch 1000/1000: LR=1.85e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 942 Train Time 38.50894260406494s

Training epoch 943, Batch 500/1000: LR=1.82e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 943, Batch 1000/1000: LR=1.82e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 943 Train Time 38.66009521484375s

Training epoch 944, Batch 500/1000: LR=1.79e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 944, Batch 1000/1000: LR=1.79e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 944 Train Time 38.53262758255005s

Training epoch 945, Batch 500/1000: LR=1.76e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 945, Batch 1000/1000: LR=1.76e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 945 Train Time 38.49905014038086s

Training epoch 946, Batch 500/1000: LR=1.74e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 946, Batch 1000/1000: LR=1.74e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 946 Train Time 71.49440932273865s

Training epoch 947, Batch 500/1000: LR=1.71e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 947, Batch 1000/1000: LR=1.71e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 947 Train Time 39.449846029281616s

Training epoch 948, Batch 500/1000: LR=1.68e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 948, Batch 1000/1000: LR=1.68e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 948 Train Time 39.049360513687134s

Training epoch 949, Batch 500/1000: LR=1.66e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 949, Batch 1000/1000: LR=1.66e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 949 Train Time 38.92427086830139s

Training epoch 950, Batch 500/1000: LR=1.63e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 950, Batch 1000/1000: LR=1.63e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 950 Train Time 38.92416477203369s

Training epoch 951, Batch 500/1000: LR=1.61e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 951, Batch 1000/1000: LR=1.61e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 951 Train Time 38.89787268638611s

Training epoch 952, Batch 500/1000: LR=1.59e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 952, Batch 1000/1000: LR=1.59e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 952 Train Time 39.00756335258484s

Training epoch 953, Batch 500/1000: LR=1.56e-06, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 953, Batch 1000/1000: LR=1.56e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 953 Train Time 38.677090883255005s

Training epoch 954, Batch 500/1000: LR=1.54e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 954, Batch 1000/1000: LR=1.54e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 954 Train Time 38.520132303237915s

Training epoch 955, Batch 500/1000: LR=1.52e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 955, Batch 1000/1000: LR=1.52e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 955 Train Time 38.502344608306885s

Training epoch 956, Batch 500/1000: LR=1.49e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 956, Batch 1000/1000: LR=1.49e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 956 Train Time 38.51685118675232s

Training epoch 957, Batch 500/1000: LR=1.47e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 957, Batch 1000/1000: LR=1.47e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 957 Train Time 38.501490354537964s

Training epoch 958, Batch 500/1000: LR=1.45e-06, Loss=2.88e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 958, Batch 1000/1000: LR=1.45e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 958 Train Time 38.473790407180786s

Training epoch 959, Batch 500/1000: LR=1.43e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 959, Batch 1000/1000: LR=1.43e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 959 Train Time 38.48352932929993s

Training epoch 960, Batch 500/1000: LR=1.41e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 960, Batch 1000/1000: LR=1.41e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 960 Train Time 38.5092613697052s

Training epoch 961, Batch 500/1000: LR=1.39e-06, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 961, Batch 1000/1000: LR=1.39e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 961 Train Time 38.62593197822571s

Training epoch 962, Batch 500/1000: LR=1.37e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 962, Batch 1000/1000: LR=1.37e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 962 Train Time 38.54762148857117s

Training epoch 963, Batch 500/1000: LR=1.35e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 963, Batch 1000/1000: LR=1.35e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 963 Train Time 38.509602785110474s

Training epoch 964, Batch 500/1000: LR=1.33e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 964, Batch 1000/1000: LR=1.33e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 964 Train Time 38.503965854644775s

Training epoch 965, Batch 500/1000: LR=1.32e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 965, Batch 1000/1000: LR=1.32e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 965 Train Time 38.50084972381592s

Training epoch 966, Batch 500/1000: LR=1.30e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 966, Batch 1000/1000: LR=1.30e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 966 Train Time 39.010613441467285s

Training epoch 967, Batch 500/1000: LR=1.28e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 967, Batch 1000/1000: LR=1.28e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 967 Train Time 38.61887168884277s

Training epoch 968, Batch 500/1000: LR=1.27e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 968, Batch 1000/1000: LR=1.27e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 968 Train Time 38.55276417732239s

Training epoch 969, Batch 500/1000: LR=1.25e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 969, Batch 1000/1000: LR=1.25e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 969 Train Time 38.50499892234802s

Training epoch 970, Batch 500/1000: LR=1.23e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 970, Batch 1000/1000: LR=1.23e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 970 Train Time 38.59497046470642s

Training epoch 971, Batch 500/1000: LR=1.22e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 971, Batch 1000/1000: LR=1.22e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 971 Train Time 38.523616552352905s

Training epoch 972, Batch 500/1000: LR=1.21e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 972, Batch 1000/1000: LR=1.21e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 972 Train Time 38.490370750427246s

Training epoch 973, Batch 500/1000: LR=1.19e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 973, Batch 1000/1000: LR=1.19e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 973 Train Time 38.47893714904785s

Training epoch 974, Batch 500/1000: LR=1.18e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 974, Batch 1000/1000: LR=1.18e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 974 Train Time 38.519909381866455s

Training epoch 975, Batch 500/1000: LR=1.17e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 975, Batch 1000/1000: LR=1.17e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 975 Train Time 38.5795476436615s

Training epoch 976, Batch 500/1000: LR=1.15e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 976, Batch 1000/1000: LR=1.15e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 976 Train Time 38.506184101104736s

Training epoch 977, Batch 500/1000: LR=1.14e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 977, Batch 1000/1000: LR=1.14e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 977 Train Time 38.534228801727295s

Training epoch 978, Batch 500/1000: LR=1.13e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 978, Batch 1000/1000: LR=1.13e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 978 Train Time 38.506491899490356s

Training epoch 979, Batch 500/1000: LR=1.12e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 979, Batch 1000/1000: LR=1.12e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 979 Train Time 38.5061571598053s

Training epoch 980, Batch 500/1000: LR=1.11e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 980, Batch 1000/1000: LR=1.11e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 980 Train Time 38.541526556015015s

Training epoch 981, Batch 500/1000: LR=1.10e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 981, Batch 1000/1000: LR=1.10e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 981 Train Time 38.50065803527832s

Training epoch 982, Batch 500/1000: LR=1.09e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 982, Batch 1000/1000: LR=1.09e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 982 Train Time 38.50110650062561s

Training epoch 983, Batch 500/1000: LR=1.08e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 983, Batch 1000/1000: LR=1.08e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 983 Train Time 38.53149676322937s

Training epoch 984, Batch 500/1000: LR=1.07e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 984, Batch 1000/1000: LR=1.07e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 984 Train Time 38.54958772659302s

Training epoch 985, Batch 500/1000: LR=1.06e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 985, Batch 1000/1000: LR=1.06e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 985 Train Time 38.61308479309082s

Training epoch 986, Batch 500/1000: LR=1.05e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 986, Batch 1000/1000: LR=1.05e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Epoch 986 Train Time 38.491897106170654s

Training epoch 987, Batch 500/1000: LR=1.05e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 987, Batch 1000/1000: LR=1.05e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 987 Train Time 38.508652687072754s

Training epoch 988, Batch 500/1000: LR=1.04e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 988, Batch 1000/1000: LR=1.04e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 988 Train Time 38.49776816368103s

Training epoch 989, Batch 500/1000: LR=1.04e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.10e-01
Training epoch 989, Batch 1000/1000: LR=1.04e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 989 Train Time 38.53422927856445s

Training epoch 990, Batch 500/1000: LR=1.03e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 990, Batch 1000/1000: LR=1.03e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 990 Train Time 38.50208568572998s

Training epoch 991, Batch 500/1000: LR=1.02e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 991, Batch 1000/1000: LR=1.02e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 991 Train Time 38.48003911972046s

Training epoch 992, Batch 500/1000: LR=1.02e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 992, Batch 1000/1000: LR=1.02e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 992 Train Time 38.529040575027466s

Training epoch 993, Batch 500/1000: LR=1.02e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 993, Batch 1000/1000: LR=1.02e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 993 Train Time 38.55152893066406s

Training epoch 994, Batch 500/1000: LR=1.01e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 994, Batch 1000/1000: LR=1.01e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 994 Train Time 136.1103253364563s

Training epoch 995, Batch 500/1000: LR=1.01e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 995, Batch 1000/1000: LR=1.01e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 995 Train Time 39.038177251815796s

Training epoch 996, Batch 500/1000: LR=1.01e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 996, Batch 1000/1000: LR=1.01e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 996 Train Time 38.915050983428955s

Training epoch 997, Batch 500/1000: LR=1.00e-06, Loss=2.93e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 997, Batch 1000/1000: LR=1.00e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 997 Train Time 38.946733713150024s

Training epoch 998, Batch 500/1000: LR=1.00e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 998, Batch 1000/1000: LR=1.00e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 998 Train Time 38.91328954696655s

Training epoch 999, Batch 500/1000: LR=1.00e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 999, Batch 1000/1000: LR=1.00e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 999 Train Time 38.91455006599426s

Training epoch 1000, Batch 500/1000: LR=1.00e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1000, Batch 1000/1000: LR=1.00e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 1000 Train Time 38.56286406517029s


Test Loss 4: 8.73e-03 5: 9.42e-04 6: 4.38e-05
Test FER 4: 3.83e-02 5: 4.72e-03 6: 2.08e-04
Test BER 4: 3.21e-03 5: 3.18e-04 6: 1.10e-05
Test -ln(BER) 4: 5.74e+00 5: 8.05e+00 6: 1.14e+01
# of testing samples: [100352.0, 100352.0, 491520.0]
 Test Time 127.89319348335266 s

