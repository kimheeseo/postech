Path to model/logs: Results_ECCT\LDPC__Code_n_49_k_24__07_11_2022_23_58_07
Namespace(epochs=1000, workers=0, lr=0.0001, gpus='0', batch_size=128, test_batch_size=2048, seed=42, code_type='LDPC', code_k=24, code_n=49, standardize=False, N_dec=6, d_model=32, h=8, code=<__main__.Code object at 0x000001A920A52470>, path='Results_ECCT\\LDPC__Code_n_49_k_24__07_11_2022_23_58_07')
Self-Attention Sparsity Ratio=72.26%, Self-Attention Complexity Ratio=13.87%
Mask:
 tensor([[[[False,  True,  True,  ...,  True,  True,  True],
          [ True, False,  True,  ...,  True,  True,  True],
          [ True,  True, False,  ...,  True,  True,  True],
          ...,
          [ True,  True,  True,  ..., False,  True,  True],
          [ True,  True,  True,  ...,  True, False,  True],
          [ True,  True,  True,  ...,  True,  True, False]]]])
ECC_Transformer(
  (decoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (oned_final_embed): Sequential(
    (0): Linear(in_features=32, out_features=1, bias=True)
  )
  (out_fc): Linear(in_features=77, out_features=49, bias=True)
)
# of Parameters: 82671
Training epoch 1, Batch 500/1000: LR=1.00e-04, Loss=2.50e-01 BER=8.23e-02 FER=8.53e-01
Training epoch 1, Batch 1000/1000: LR=1.00e-04, Loss=2.19e-01 BER=6.81e-02 FER=8.41e-01
Epoch 1 Train Time 57.26993918418884s


Test Loss 1: 3.97e-01 2: 3.30e-01 3: 2.61e-01
Test FER 1: 9.99e-01 2: 9.96e-01 3: 9.84e-01
Test BER 1: 1.33e-01 2: 1.07e-01 3: 8.10e-02
Test -ln(BER) 1: 2.01e+00 2: 2.24e+00 3: 2.51e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 76.70100426673889 s

Training epoch 2, Batch 500/1000: LR=1.00e-04, Loss=1.72e-01 BER=5.33e-02 FER=8.15e-01
Training epoch 2, Batch 1000/1000: LR=1.00e-04, Loss=1.64e-01 BER=5.22e-02 FER=7.74e-01
Epoch 2 Train Time 751.7183957099915s

Training epoch 3, Batch 500/1000: LR=1.00e-04, Loss=1.45e-01 BER=4.81e-02 FER=6.36e-01
Training epoch 3, Batch 1000/1000: LR=1.00e-04, Loss=1.40e-01 BER=4.68e-02 FER=6.09e-01
Epoch 3 Train Time 55.20944619178772s

Training epoch 4, Batch 500/1000: LR=1.00e-04, Loss=1.29e-01 BER=4.40e-02 FER=5.50e-01
Training epoch 4, Batch 1000/1000: LR=1.00e-04, Loss=1.26e-01 BER=4.32e-02 FER=5.37e-01
Epoch 4 Train Time 54.98604083061218s

Training epoch 5, Batch 500/1000: LR=1.00e-04, Loss=1.19e-01 BER=4.12e-02 FER=5.07e-01
Training epoch 5, Batch 1000/1000: LR=1.00e-04, Loss=1.17e-01 BER=4.07e-02 FER=4.99e-01
Epoch 5 Train Time 54.82846474647522s

Training epoch 6, Batch 500/1000: LR=1.00e-04, Loss=1.11e-01 BER=3.92e-02 FER=4.80e-01
Training epoch 6, Batch 1000/1000: LR=1.00e-04, Loss=1.09e-01 BER=3.88e-02 FER=4.77e-01
Epoch 6 Train Time 55.223408222198486s

Training epoch 7, Batch 500/1000: LR=1.00e-04, Loss=1.04e-01 BER=3.75e-02 FER=4.63e-01
Training epoch 7, Batch 1000/1000: LR=1.00e-04, Loss=1.02e-01 BER=3.70e-02 FER=4.60e-01
Epoch 7 Train Time 55.17653441429138s

Training epoch 8, Batch 500/1000: LR=1.00e-04, Loss=9.68e-02 BER=3.56e-02 FER=4.46e-01
Training epoch 8, Batch 1000/1000: LR=1.00e-04, Loss=9.49e-02 BER=3.51e-02 FER=4.41e-01
Epoch 8 Train Time 55.13763785362244s

Training epoch 9, Batch 500/1000: LR=1.00e-04, Loss=8.97e-02 BER=3.38e-02 FER=4.24e-01
Training epoch 9, Batch 1000/1000: LR=1.00e-04, Loss=8.79e-02 BER=3.31e-02 FER=4.17e-01
Epoch 9 Train Time 55.539562940597534s

Training epoch 10, Batch 500/1000: LR=1.00e-04, Loss=8.35e-02 BER=3.16e-02 FER=4.00e-01
Training epoch 10, Batch 1000/1000: LR=1.00e-04, Loss=8.25e-02 BER=3.12e-02 FER=3.94e-01
Epoch 10 Train Time 55.5914261341095s

Training epoch 11, Batch 500/1000: LR=1.00e-04, Loss=7.86e-02 BER=2.99e-02 FER=3.76e-01
Training epoch 11, Batch 1000/1000: LR=1.00e-04, Loss=7.74e-02 BER=2.94e-02 FER=3.70e-01
Epoch 11 Train Time 55.34309124946594s

Training epoch 12, Batch 500/1000: LR=1.00e-04, Loss=7.38e-02 BER=2.81e-02 FER=3.52e-01
Training epoch 12, Batch 1000/1000: LR=1.00e-04, Loss=7.30e-02 BER=2.78e-02 FER=3.48e-01
Epoch 12 Train Time 55.502662897109985s

Training epoch 13, Batch 500/1000: LR=1.00e-04, Loss=7.04e-02 BER=2.67e-02 FER=3.34e-01
Training epoch 13, Batch 1000/1000: LR=1.00e-04, Loss=6.94e-02 BER=2.64e-02 FER=3.29e-01
Epoch 13 Train Time 55.623337745666504s

Training epoch 14, Batch 500/1000: LR=1.00e-04, Loss=6.68e-02 BER=2.53e-02 FER=3.13e-01
Training epoch 14, Batch 1000/1000: LR=1.00e-04, Loss=6.58e-02 BER=2.50e-02 FER=3.08e-01
Epoch 14 Train Time 55.36702489852905s

Training epoch 15, Batch 500/1000: LR=1.00e-04, Loss=6.36e-02 BER=2.41e-02 FER=2.96e-01
Training epoch 15, Batch 1000/1000: LR=1.00e-04, Loss=6.24e-02 BER=2.37e-02 FER=2.90e-01
Epoch 15 Train Time 55.48869967460632s

Training epoch 16, Batch 500/1000: LR=9.99e-05, Loss=5.96e-02 BER=2.26e-02 FER=2.76e-01
Training epoch 16, Batch 1000/1000: LR=9.99e-05, Loss=5.91e-02 BER=2.23e-02 FER=2.72e-01
Epoch 16 Train Time 55.59840655326843s

Training epoch 17, Batch 500/1000: LR=9.99e-05, Loss=5.74e-02 BER=2.17e-02 FER=2.64e-01
Training epoch 17, Batch 1000/1000: LR=9.99e-05, Loss=5.67e-02 BER=2.14e-02 FER=2.59e-01
Epoch 17 Train Time 55.463768005371094s

Training epoch 18, Batch 500/1000: LR=9.99e-05, Loss=5.50e-02 BER=2.08e-02 FER=2.49e-01
Training epoch 18, Batch 1000/1000: LR=9.99e-05, Loss=5.41e-02 BER=2.05e-02 FER=2.43e-01
Epoch 18 Train Time 54.697813510894775s

Training epoch 19, Batch 500/1000: LR=9.99e-05, Loss=5.21e-02 BER=1.96e-02 FER=2.29e-01
Training epoch 19, Batch 1000/1000: LR=9.99e-05, Loss=5.16e-02 BER=1.95e-02 FER=2.25e-01
Epoch 19 Train Time 54.10439920425415s

Training epoch 20, Batch 500/1000: LR=9.99e-05, Loss=4.90e-02 BER=1.84e-02 FER=2.10e-01
Training epoch 20, Batch 1000/1000: LR=9.99e-05, Loss=4.88e-02 BER=1.84e-02 FER=2.09e-01
Epoch 20 Train Time 54.280927419662476s

Training epoch 21, Batch 500/1000: LR=9.99e-05, Loss=4.69e-02 BER=1.77e-02 FER=1.98e-01
Training epoch 21, Batch 1000/1000: LR=9.99e-05, Loss=4.65e-02 BER=1.76e-02 FER=1.96e-01
Epoch 21 Train Time 54.45745658874512s

Training epoch 22, Batch 500/1000: LR=9.99e-05, Loss=4.64e-02 BER=1.76e-02 FER=1.94e-01
Training epoch 22, Batch 1000/1000: LR=9.99e-05, Loss=4.58e-02 BER=1.74e-02 FER=1.91e-01
Epoch 22 Train Time 54.82746934890747s

Training epoch 23, Batch 500/1000: LR=9.99e-05, Loss=4.43e-02 BER=1.68e-02 FER=1.84e-01
Training epoch 23, Batch 1000/1000: LR=9.99e-05, Loss=4.42e-02 BER=1.68e-02 FER=1.84e-01
Epoch 23 Train Time 54.089435338974s

Training epoch 24, Batch 500/1000: LR=9.99e-05, Loss=4.37e-02 BER=1.66e-02 FER=1.78e-01
Training epoch 24, Batch 1000/1000: LR=9.99e-05, Loss=4.39e-02 BER=1.68e-02 FER=1.79e-01
Epoch 24 Train Time 54.31384038925171s

Training epoch 25, Batch 500/1000: LR=9.99e-05, Loss=4.33e-02 BER=1.65e-02 FER=1.75e-01
Training epoch 25, Batch 1000/1000: LR=9.99e-05, Loss=4.27e-02 BER=1.63e-02 FER=1.73e-01
Epoch 25 Train Time 54.33678126335144s

Training epoch 26, Batch 500/1000: LR=9.98e-05, Loss=4.12e-02 BER=1.56e-02 FER=1.66e-01
Training epoch 26, Batch 1000/1000: LR=9.98e-05, Loss=4.15e-02 BER=1.58e-02 FER=1.68e-01
Epoch 26 Train Time 54.219094038009644s

Training epoch 27, Batch 500/1000: LR=9.98e-05, Loss=4.09e-02 BER=1.57e-02 FER=1.64e-01
Training epoch 27, Batch 1000/1000: LR=9.98e-05, Loss=4.14e-02 BER=1.58e-02 FER=1.65e-01
Epoch 27 Train Time 54.147284746170044s

Training epoch 28, Batch 500/1000: LR=9.98e-05, Loss=4.14e-02 BER=1.60e-02 FER=1.67e-01
Training epoch 28, Batch 1000/1000: LR=9.98e-05, Loss=4.11e-02 BER=1.58e-02 FER=1.65e-01
Epoch 28 Train Time 54.46842622756958s

Training epoch 29, Batch 500/1000: LR=9.98e-05, Loss=4.02e-02 BER=1.54e-02 FER=1.59e-01
Training epoch 29, Batch 1000/1000: LR=9.98e-05, Loss=4.03e-02 BER=1.55e-02 FER=1.60e-01
Epoch 29 Train Time 54.66490125656128s

Training epoch 30, Batch 500/1000: LR=9.98e-05, Loss=4.08e-02 BER=1.58e-02 FER=1.60e-01
Training epoch 30, Batch 1000/1000: LR=9.98e-05, Loss=4.04e-02 BER=1.56e-02 FER=1.59e-01
Epoch 30 Train Time 54.33378601074219s

Training epoch 31, Batch 500/1000: LR=9.98e-05, Loss=3.92e-02 BER=1.50e-02 FER=1.56e-01
Training epoch 31, Batch 1000/1000: LR=9.98e-05, Loss=3.96e-02 BER=1.53e-02 FER=1.57e-01
Epoch 31 Train Time 49.78895568847656s

Training epoch 32, Batch 500/1000: LR=9.98e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Training epoch 32, Batch 1000/1000: LR=9.98e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Epoch 32 Train Time 44.94086027145386s

Training epoch 33, Batch 500/1000: LR=9.98e-05, Loss=3.92e-02 BER=1.51e-02 FER=1.54e-01
Training epoch 33, Batch 1000/1000: LR=9.98e-05, Loss=3.89e-02 BER=1.51e-02 FER=1.53e-01
Epoch 33 Train Time 45.00072884559631s

Training epoch 34, Batch 500/1000: LR=9.97e-05, Loss=3.86e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 34, Batch 1000/1000: LR=9.97e-05, Loss=3.87e-02 BER=1.50e-02 FER=1.51e-01
Epoch 34 Train Time 45.2470703125s

Training epoch 35, Batch 500/1000: LR=9.97e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 35, Batch 1000/1000: LR=9.97e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Epoch 35 Train Time 45.31286907196045s

Training epoch 36, Batch 500/1000: LR=9.97e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Training epoch 36, Batch 1000/1000: LR=9.97e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Epoch 36 Train Time 45.24008870124817s

Training epoch 37, Batch 500/1000: LR=9.97e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.50e-01
Training epoch 37, Batch 1000/1000: LR=9.97e-05, Loss=3.82e-02 BER=1.49e-02 FER=1.49e-01
Epoch 37 Train Time 45.28796648979187s

Training epoch 38, Batch 500/1000: LR=9.97e-05, Loss=3.78e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 38, Batch 1000/1000: LR=9.97e-05, Loss=3.78e-02 BER=1.47e-02 FER=1.47e-01
Epoch 38 Train Time 44.856117725372314s

Training epoch 39, Batch 500/1000: LR=9.96e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.49e-01
Training epoch 39, Batch 1000/1000: LR=9.96e-05, Loss=3.81e-02 BER=1.49e-02 FER=1.48e-01
Epoch 39 Train Time 44.98577046394348s

Training epoch 40, Batch 500/1000: LR=9.96e-05, Loss=3.76e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 40, Batch 1000/1000: LR=9.96e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.46e-01
Epoch 40 Train Time 44.974794149398804s

Training epoch 41, Batch 500/1000: LR=9.96e-05, Loss=3.78e-02 BER=1.48e-02 FER=1.47e-01
Training epoch 41, Batch 1000/1000: LR=9.96e-05, Loss=3.77e-02 BER=1.48e-02 FER=1.46e-01
Epoch 41 Train Time 44.89202165603638s

Training epoch 42, Batch 500/1000: LR=9.96e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 42, Batch 1000/1000: LR=9.96e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.43e-01
Epoch 42 Train Time 67.51767659187317s

Training epoch 43, Batch 500/1000: LR=9.96e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 43, Batch 1000/1000: LR=9.96e-05, Loss=3.70e-02 BER=1.45e-02 FER=1.44e-01
Epoch 43 Train Time 45.83051538467407s

Training epoch 44, Batch 500/1000: LR=9.95e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 44, Batch 1000/1000: LR=9.95e-05, Loss=3.76e-02 BER=1.48e-02 FER=1.46e-01
Epoch 44 Train Time 44.7653591632843s

Training epoch 45, Batch 500/1000: LR=9.95e-05, Loss=3.66e-02 BER=1.44e-02 FER=1.41e-01
Training epoch 45, Batch 1000/1000: LR=9.95e-05, Loss=3.65e-02 BER=1.44e-02 FER=1.42e-01
Epoch 45 Train Time 44.61376452445984s

Training epoch 46, Batch 500/1000: LR=9.95e-05, Loss=3.63e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 46, Batch 1000/1000: LR=9.95e-05, Loss=3.60e-02 BER=1.41e-02 FER=1.41e-01
Epoch 46 Train Time 44.535972356796265s

Training epoch 47, Batch 500/1000: LR=9.95e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.44e-01
Training epoch 47, Batch 1000/1000: LR=9.95e-05, Loss=3.67e-02 BER=1.44e-02 FER=1.42e-01
Epoch 47 Train Time 44.62373733520508s

Training epoch 48, Batch 500/1000: LR=9.95e-05, Loss=3.55e-02 BER=1.40e-02 FER=1.38e-01
Training epoch 48, Batch 1000/1000: LR=9.95e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.39e-01
Epoch 48 Train Time 44.460174322128296s

Training epoch 49, Batch 500/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 49, Batch 1000/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Epoch 49 Train Time 44.564894914627075s

Training epoch 50, Batch 500/1000: LR=9.94e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 50, Batch 1000/1000: LR=9.94e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Epoch 50 Train Time 44.71648120880127s

Training epoch 51, Batch 500/1000: LR=9.94e-05, Loss=3.62e-02 BER=1.44e-02 FER=1.41e-01
Training epoch 51, Batch 1000/1000: LR=9.94e-05, Loss=3.60e-02 BER=1.43e-02 FER=1.40e-01
Epoch 51 Train Time 44.622735023498535s

Training epoch 52, Batch 500/1000: LR=9.94e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 52, Batch 1000/1000: LR=9.94e-05, Loss=3.56e-02 BER=1.41e-02 FER=1.38e-01
Epoch 52 Train Time 44.43723654747009s

Training epoch 53, Batch 500/1000: LR=9.93e-05, Loss=3.61e-02 BER=1.43e-02 FER=1.40e-01
Training epoch 53, Batch 1000/1000: LR=9.93e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.38e-01
Epoch 53 Train Time 44.77333974838257s

Training epoch 54, Batch 500/1000: LR=9.93e-05, Loss=3.53e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 54, Batch 1000/1000: LR=9.93e-05, Loss=3.52e-02 BER=1.39e-02 FER=1.36e-01
Epoch 54 Train Time 44.440229415893555s

Training epoch 55, Batch 500/1000: LR=9.93e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 55, Batch 1000/1000: LR=9.93e-05, Loss=3.53e-02 BER=1.40e-02 FER=1.37e-01
Epoch 55 Train Time 44.58783459663391s

Training epoch 56, Batch 500/1000: LR=9.93e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.36e-01
Training epoch 56, Batch 1000/1000: LR=9.93e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.35e-01
Epoch 56 Train Time 44.73446464538574s

Training epoch 57, Batch 500/1000: LR=9.92e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 57, Batch 1000/1000: LR=9.92e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.38e-01
Epoch 57 Train Time 44.50408101081848s

Training epoch 58, Batch 500/1000: LR=9.92e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.35e-01
Training epoch 58, Batch 1000/1000: LR=9.92e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 58 Train Time 44.44222140312195s

Training epoch 59, Batch 500/1000: LR=9.92e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 59, Batch 1000/1000: LR=9.92e-05, Loss=3.50e-02 BER=1.39e-02 FER=1.36e-01
Epoch 59 Train Time 44.48010540008545s

Training epoch 60, Batch 500/1000: LR=9.92e-05, Loss=3.56e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 60, Batch 1000/1000: LR=9.92e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Epoch 60 Train Time 44.492090463638306s

Training epoch 61, Batch 500/1000: LR=9.91e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 61, Batch 1000/1000: LR=9.91e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 61 Train Time 44.72845649719238s

Training epoch 62, Batch 500/1000: LR=9.91e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.36e-01
Training epoch 62, Batch 1000/1000: LR=9.91e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.36e-01
Epoch 62 Train Time 44.764371395111084s

Training epoch 63, Batch 500/1000: LR=9.91e-05, Loss=3.46e-02 BER=1.39e-02 FER=1.33e-01
Training epoch 63, Batch 1000/1000: LR=9.91e-05, Loss=3.48e-02 BER=1.39e-02 FER=1.35e-01
Epoch 63 Train Time 44.65664792060852s

Training epoch 64, Batch 500/1000: LR=9.90e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.33e-01
Training epoch 64, Batch 1000/1000: LR=9.90e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.34e-01
Epoch 64 Train Time 44.53993272781372s

Training epoch 65, Batch 500/1000: LR=9.90e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 65, Batch 1000/1000: LR=9.90e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.36e-01
Epoch 65 Train Time 44.54993510246277s

Training epoch 66, Batch 500/1000: LR=9.90e-05, Loss=3.37e-02 BER=1.34e-02 FER=1.32e-01
Training epoch 66, Batch 1000/1000: LR=9.90e-05, Loss=3.43e-02 BER=1.37e-02 FER=1.33e-01
Epoch 66 Train Time 44.38836407661438s

Training epoch 67, Batch 500/1000: LR=9.89e-05, Loss=3.42e-02 BER=1.36e-02 FER=1.32e-01
Training epoch 67, Batch 1000/1000: LR=9.89e-05, Loss=3.46e-02 BER=1.37e-02 FER=1.34e-01
Epoch 67 Train Time 44.62274146080017s

Training epoch 68, Batch 500/1000: LR=9.89e-05, Loss=3.47e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 68, Batch 1000/1000: LR=9.89e-05, Loss=3.45e-02 BER=1.38e-02 FER=1.34e-01
Epoch 68 Train Time 44.40532422065735s

Training epoch 69, Batch 500/1000: LR=9.89e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.33e-01
Training epoch 69, Batch 1000/1000: LR=9.89e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 69 Train Time 44.40232992172241s

Training epoch 70, Batch 500/1000: LR=9.88e-05, Loss=3.44e-02 BER=1.38e-02 FER=1.34e-01
Training epoch 70, Batch 1000/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.36e-02 FER=1.33e-01
Epoch 70 Train Time 44.633709192276s

Training epoch 71, Batch 500/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 71, Batch 1000/1000: LR=9.88e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 71 Train Time 44.55193066596985s

Training epoch 72, Batch 500/1000: LR=9.88e-05, Loss=3.41e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 72, Batch 1000/1000: LR=9.88e-05, Loss=3.40e-02 BER=1.35e-02 FER=1.32e-01
Epoch 72 Train Time 44.542954206466675s

Training epoch 73, Batch 500/1000: LR=9.87e-05, Loss=3.43e-02 BER=1.38e-02 FER=1.33e-01
Training epoch 73, Batch 1000/1000: LR=9.87e-05, Loss=3.39e-02 BER=1.36e-02 FER=1.32e-01
Epoch 73 Train Time 44.30259728431702s

Training epoch 74, Batch 500/1000: LR=9.87e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 74, Batch 1000/1000: LR=9.87e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 74 Train Time 44.731478691101074s

Training epoch 75, Batch 500/1000: LR=9.87e-05, Loss=3.35e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 75, Batch 1000/1000: LR=9.87e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 75 Train Time 44.38537621498108s

Training epoch 76, Batch 500/1000: LR=9.86e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 76, Batch 1000/1000: LR=9.86e-05, Loss=3.37e-02 BER=1.34e-02 FER=1.31e-01
Epoch 76 Train Time 44.712501525878906s

Training epoch 77, Batch 500/1000: LR=9.86e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 77, Batch 1000/1000: LR=9.86e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 77 Train Time 44.407315492630005s

Training epoch 78, Batch 500/1000: LR=9.86e-05, Loss=3.42e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 78, Batch 1000/1000: LR=9.86e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.32e-01
Epoch 78 Train Time 44.754411935806274s

Training epoch 79, Batch 500/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 79, Batch 1000/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.31e-01
Epoch 79 Train Time 44.894014835357666s

Training epoch 80, Batch 500/1000: LR=9.85e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 80, Batch 1000/1000: LR=9.85e-05, Loss=3.43e-02 BER=1.38e-02 FER=1.32e-01
Epoch 80 Train Time 44.80425524711609s

Training epoch 81, Batch 500/1000: LR=9.84e-05, Loss=3.38e-02 BER=1.34e-02 FER=1.30e-01
Training epoch 81, Batch 1000/1000: LR=9.84e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.31e-01
Epoch 81 Train Time 44.576863288879395s

Training epoch 82, Batch 500/1000: LR=9.84e-05, Loss=3.38e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 82, Batch 1000/1000: LR=9.84e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 82 Train Time 44.525999784469604s

Training epoch 83, Batch 500/1000: LR=9.84e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.30e-01
Training epoch 83, Batch 1000/1000: LR=9.84e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 83 Train Time 68.18617868423462s

Training epoch 84, Batch 500/1000: LR=9.83e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.30e-01
Training epoch 84, Batch 1000/1000: LR=9.83e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.30e-01
Epoch 84 Train Time 45.4495530128479s

Training epoch 85, Batch 500/1000: LR=9.83e-05, Loss=3.33e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 85, Batch 1000/1000: LR=9.83e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 85 Train Time 45.1293888092041s

Training epoch 86, Batch 500/1000: LR=9.82e-05, Loss=3.38e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 86, Batch 1000/1000: LR=9.82e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.30e-01
Epoch 86 Train Time 45.10345482826233s

Training epoch 87, Batch 500/1000: LR=9.82e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.31e-01
Training epoch 87, Batch 1000/1000: LR=9.82e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 87 Train Time 45.00372266769409s

Training epoch 88, Batch 500/1000: LR=9.82e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 88, Batch 1000/1000: LR=9.82e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 88 Train Time 45.34978795051575s

Training epoch 89, Batch 500/1000: LR=9.81e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 89, Batch 1000/1000: LR=9.81e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.30e-01
Epoch 89 Train Time 45.24408149719238s

Training epoch 90, Batch 500/1000: LR=9.81e-05, Loss=3.31e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 90, Batch 1000/1000: LR=9.81e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 90 Train Time 45.276989221572876s

Training epoch 91, Batch 500/1000: LR=9.80e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.28e-01
Training epoch 91, Batch 1000/1000: LR=9.80e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 91 Train Time 45.411630153656006s

Training epoch 92, Batch 500/1000: LR=9.80e-05, Loss=3.34e-02 BER=1.35e-02 FER=1.29e-01
Training epoch 92, Batch 1000/1000: LR=9.80e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.29e-01
Epoch 92 Train Time 45.08149719238281s

Training epoch 93, Batch 500/1000: LR=9.79e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.27e-01
Training epoch 93, Batch 1000/1000: LR=9.79e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 93 Train Time 45.190202474594116s

Training epoch 94, Batch 500/1000: LR=9.79e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 94, Batch 1000/1000: LR=9.79e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 94 Train Time 45.265023708343506s

Training epoch 95, Batch 500/1000: LR=9.79e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Training epoch 95, Batch 1000/1000: LR=9.79e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Epoch 95 Train Time 45.11642122268677s

Training epoch 96, Batch 500/1000: LR=9.78e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 96, Batch 1000/1000: LR=9.78e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 96 Train Time 45.43360209465027s

Training epoch 97, Batch 500/1000: LR=9.78e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 97, Batch 1000/1000: LR=9.78e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.28e-01
Epoch 97 Train Time 45.22313570976257s

Training epoch 98, Batch 500/1000: LR=9.77e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 98, Batch 1000/1000: LR=9.77e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.27e-01
Epoch 98 Train Time 44.941887855529785s

Training epoch 99, Batch 500/1000: LR=9.77e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 99, Batch 1000/1000: LR=9.77e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 99 Train Time 44.59182262420654s

Training epoch 100, Batch 500/1000: LR=9.76e-05, Loss=3.23e-02 BER=1.28e-02 FER=1.25e-01
Training epoch 100, Batch 1000/1000: LR=9.76e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 100 Train Time 44.51502823829651s

Training epoch 101, Batch 500/1000: LR=9.76e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 101, Batch 1000/1000: LR=9.76e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.28e-01
Epoch 101 Train Time 44.25871515274048s

Training epoch 102, Batch 500/1000: LR=9.75e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 102, Batch 1000/1000: LR=9.75e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 102 Train Time 44.43424320220947s

Training epoch 103, Batch 500/1000: LR=9.75e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 103, Batch 1000/1000: LR=9.75e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 103 Train Time 44.45817995071411s

Training epoch 104, Batch 500/1000: LR=9.74e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 104, Batch 1000/1000: LR=9.74e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 104 Train Time 44.5678870677948s

Training epoch 105, Batch 500/1000: LR=9.74e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 105, Batch 1000/1000: LR=9.74e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.27e-01
Epoch 105 Train Time 44.26671504974365s

Training epoch 106, Batch 500/1000: LR=9.73e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 106, Batch 1000/1000: LR=9.73e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 106 Train Time 44.50902223587036s

Training epoch 107, Batch 500/1000: LR=9.73e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.27e-01
Training epoch 107, Batch 1000/1000: LR=9.73e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.27e-01
Epoch 107 Train Time 44.57387113571167s

Training epoch 108, Batch 500/1000: LR=9.72e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 108, Batch 1000/1000: LR=9.72e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.26e-01
Epoch 108 Train Time 44.49208950996399s

Training epoch 109, Batch 500/1000: LR=9.72e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 109, Batch 1000/1000: LR=9.72e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 109 Train Time 44.374404191970825s

Training epoch 110, Batch 500/1000: LR=9.71e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 110, Batch 1000/1000: LR=9.71e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Epoch 110 Train Time 44.403326749801636s

Training epoch 111, Batch 500/1000: LR=9.71e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 111, Batch 1000/1000: LR=9.71e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 111 Train Time 44.66363072395325s

Training epoch 112, Batch 500/1000: LR=9.70e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 112, Batch 1000/1000: LR=9.70e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 112 Train Time 44.59880495071411s

Training epoch 113, Batch 500/1000: LR=9.70e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.27e-01
Training epoch 113, Batch 1000/1000: LR=9.70e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Epoch 113 Train Time 44.42227578163147s

Training epoch 114, Batch 500/1000: LR=9.69e-05, Loss=3.26e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 114, Batch 1000/1000: LR=9.69e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 114 Train Time 44.41429781913757s

Training epoch 115, Batch 500/1000: LR=9.69e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 115, Batch 1000/1000: LR=9.69e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 115 Train Time 44.432250022888184s

Training epoch 116, Batch 500/1000: LR=9.68e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 116, Batch 1000/1000: LR=9.68e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 116 Train Time 44.335506439208984s

Training epoch 117, Batch 500/1000: LR=9.67e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.25e-01
Training epoch 117, Batch 1000/1000: LR=9.67e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 117 Train Time 44.453192949295044s

Training epoch 118, Batch 500/1000: LR=9.67e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 118, Batch 1000/1000: LR=9.67e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 118 Train Time 44.414297580718994s

Training epoch 119, Batch 500/1000: LR=9.66e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 119, Batch 1000/1000: LR=9.66e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 119 Train Time 44.62473678588867s

Training epoch 120, Batch 500/1000: LR=9.66e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 120, Batch 1000/1000: LR=9.66e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 120 Train Time 44.620768785476685s

Training epoch 121, Batch 500/1000: LR=9.65e-05, Loss=3.31e-02 BER=1.34e-02 FER=1.28e-01
Training epoch 121, Batch 1000/1000: LR=9.65e-05, Loss=3.27e-02 BER=1.32e-02 FER=1.26e-01
Epoch 121 Train Time 44.507049798965454s

Training epoch 122, Batch 500/1000: LR=9.65e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 122, Batch 1000/1000: LR=9.65e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Epoch 122 Train Time 44.462169885635376s

Training epoch 123, Batch 500/1000: LR=9.64e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 123, Batch 1000/1000: LR=9.64e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 123 Train Time 65.69517469406128s

Training epoch 124, Batch 500/1000: LR=9.64e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 124, Batch 1000/1000: LR=9.64e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 124 Train Time 46.45085406303406s

Training epoch 125, Batch 500/1000: LR=9.63e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 125, Batch 1000/1000: LR=9.63e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 125 Train Time 45.82951378822327s

Training epoch 126, Batch 500/1000: LR=9.62e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 126, Batch 1000/1000: LR=9.62e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Epoch 126 Train Time 45.743746280670166s

Training epoch 127, Batch 500/1000: LR=9.62e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 127, Batch 1000/1000: LR=9.62e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 127 Train Time 45.7367639541626s

Training epoch 128, Batch 500/1000: LR=9.61e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 128, Batch 1000/1000: LR=9.61e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Epoch 128 Train Time 46.00504469871521s

Training epoch 129, Batch 500/1000: LR=9.61e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 129, Batch 1000/1000: LR=9.61e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 129 Train Time 45.90431547164917s

Training epoch 130, Batch 500/1000: LR=9.60e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 130, Batch 1000/1000: LR=9.60e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 130 Train Time 45.598135471343994s

Training epoch 131, Batch 500/1000: LR=9.59e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 131, Batch 1000/1000: LR=9.59e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 131 Train Time 45.68290948867798s

Training epoch 132, Batch 500/1000: LR=9.59e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 132, Batch 1000/1000: LR=9.59e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 132 Train Time 45.995073080062866s

Training epoch 133, Batch 500/1000: LR=9.58e-05, Loss=3.22e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 133, Batch 1000/1000: LR=9.58e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.23e-01
Epoch 133 Train Time 45.677916288375854s

Training epoch 134, Batch 500/1000: LR=9.57e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 134, Batch 1000/1000: LR=9.57e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 134 Train Time 45.73576521873474s

Training epoch 135, Batch 500/1000: LR=9.57e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 135, Batch 1000/1000: LR=9.57e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Epoch 135 Train Time 45.71282458305359s

Training epoch 136, Batch 500/1000: LR=9.56e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Training epoch 136, Batch 1000/1000: LR=9.56e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 136 Train Time 45.848434925079346s

Training epoch 137, Batch 500/1000: LR=9.56e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 137, Batch 1000/1000: LR=9.56e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 137 Train Time 45.6450080871582s

Training epoch 138, Batch 500/1000: LR=9.55e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 138, Batch 1000/1000: LR=9.55e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Epoch 138 Train Time 45.74374508857727s

Training epoch 139, Batch 500/1000: LR=9.54e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 139, Batch 1000/1000: LR=9.54e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.23e-01
Epoch 139 Train Time 45.84245157241821s

Training epoch 140, Batch 500/1000: LR=9.54e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 140, Batch 1000/1000: LR=9.54e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 140 Train Time 45.75571322441101s

Training epoch 141, Batch 500/1000: LR=9.53e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 141, Batch 1000/1000: LR=9.53e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 141 Train Time 45.10545063018799s

Training epoch 142, Batch 500/1000: LR=9.52e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 142, Batch 1000/1000: LR=9.52e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 142 Train Time 45.04862666130066s

Training epoch 143, Batch 500/1000: LR=9.52e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 143, Batch 1000/1000: LR=9.52e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 143 Train Time 44.825199604034424s

Training epoch 144, Batch 500/1000: LR=9.51e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 144, Batch 1000/1000: LR=9.51e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Epoch 144 Train Time 45.03763127326965s

Training epoch 145, Batch 500/1000: LR=9.50e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Training epoch 145, Batch 1000/1000: LR=9.50e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Epoch 145 Train Time 45.399662733078s

Training epoch 146, Batch 500/1000: LR=9.50e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 146, Batch 1000/1000: LR=9.50e-05, Loss=3.23e-02 BER=1.31e-02 FER=1.24e-01
Epoch 146 Train Time 44.921963930130005s

Training epoch 147, Batch 500/1000: LR=9.49e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.25e-01
Training epoch 147, Batch 1000/1000: LR=9.49e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.24e-01
Epoch 147 Train Time 45.0336434841156s

Training epoch 148, Batch 500/1000: LR=9.48e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 148, Batch 1000/1000: LR=9.48e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 148 Train Time 44.9050178527832s

Training epoch 149, Batch 500/1000: LR=9.47e-05, Loss=3.23e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 149, Batch 1000/1000: LR=9.47e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.22e-01
Epoch 149 Train Time 44.88005089759827s

Training epoch 150, Batch 500/1000: LR=9.47e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 150, Batch 1000/1000: LR=9.47e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 150 Train Time 45.059574604034424s

Training epoch 151, Batch 500/1000: LR=9.46e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 151, Batch 1000/1000: LR=9.46e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Epoch 151 Train Time 45.080517530441284s

Training epoch 152, Batch 500/1000: LR=9.45e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 152, Batch 1000/1000: LR=9.45e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Epoch 152 Train Time 44.945876598358154s

Training epoch 153, Batch 500/1000: LR=9.45e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 153, Batch 1000/1000: LR=9.45e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 153 Train Time 44.93789839744568s

Training epoch 154, Batch 500/1000: LR=9.44e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 154, Batch 1000/1000: LR=9.44e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Epoch 154 Train Time 44.87606430053711s

Training epoch 155, Batch 500/1000: LR=9.43e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 155, Batch 1000/1000: LR=9.43e-05, Loss=3.21e-02 BER=1.30e-02 FER=1.23e-01
Epoch 155 Train Time 45.08450675010681s

Training epoch 156, Batch 500/1000: LR=9.42e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 156, Batch 1000/1000: LR=9.42e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 156 Train Time 44.9508638381958s

Training epoch 157, Batch 500/1000: LR=9.42e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 157, Batch 1000/1000: LR=9.42e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.23e-01
Epoch 157 Train Time 45.2131621837616s

Training epoch 158, Batch 500/1000: LR=9.41e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 158, Batch 1000/1000: LR=9.41e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 158 Train Time 44.90897536277771s

Training epoch 159, Batch 500/1000: LR=9.40e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 159, Batch 1000/1000: LR=9.40e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.22e-01
Epoch 159 Train Time 45.12440013885498s

Training epoch 160, Batch 500/1000: LR=9.40e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 160, Batch 1000/1000: LR=9.40e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 160 Train Time 44.99474596977234s

Training epoch 161, Batch 500/1000: LR=9.39e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 161, Batch 1000/1000: LR=9.39e-05, Loss=3.18e-02 BER=1.27e-02 FER=1.21e-01
Epoch 161 Train Time 44.771342039108276s

Training epoch 162, Batch 500/1000: LR=9.38e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 162, Batch 1000/1000: LR=9.38e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Epoch 162 Train Time 44.795279026031494s

Training epoch 163, Batch 500/1000: LR=9.37e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 163, Batch 1000/1000: LR=9.37e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 163 Train Time 66.48918557167053s

Training epoch 164, Batch 500/1000: LR=9.37e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 164, Batch 1000/1000: LR=9.37e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 164 Train Time 47.727442502975464s

Training epoch 165, Batch 500/1000: LR=9.36e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 165, Batch 1000/1000: LR=9.36e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 165 Train Time 45.63503408432007s

Training epoch 166, Batch 500/1000: LR=9.35e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 166, Batch 1000/1000: LR=9.35e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 166 Train Time 45.379717111587524s

Training epoch 167, Batch 500/1000: LR=9.34e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 167, Batch 1000/1000: LR=9.34e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Epoch 167 Train Time 45.38570237159729s

Training epoch 168, Batch 500/1000: LR=9.33e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 168, Batch 1000/1000: LR=9.33e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 168 Train Time 45.0645592212677s

Training epoch 169, Batch 500/1000: LR=9.33e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 169, Batch 1000/1000: LR=9.33e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 169 Train Time 44.93989276885986s

Training epoch 170, Batch 500/1000: LR=9.32e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 170, Batch 1000/1000: LR=9.32e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 170 Train Time 44.43823313713074s

Training epoch 171, Batch 500/1000: LR=9.31e-05, Loss=3.16e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 171, Batch 1000/1000: LR=9.31e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Epoch 171 Train Time 44.56090593338013s

Training epoch 172, Batch 500/1000: LR=9.30e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 172, Batch 1000/1000: LR=9.30e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 172 Train Time 44.42227506637573s

Training epoch 173, Batch 500/1000: LR=9.29e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 173, Batch 1000/1000: LR=9.29e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 173 Train Time 44.58683657646179s

Training epoch 174, Batch 500/1000: LR=9.29e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 174, Batch 1000/1000: LR=9.29e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 174 Train Time 44.41429924964905s

Training epoch 175, Batch 500/1000: LR=9.28e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 175, Batch 1000/1000: LR=9.28e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 175 Train Time 44.568883657455444s

Training epoch 176, Batch 500/1000: LR=9.27e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 176, Batch 1000/1000: LR=9.27e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 176 Train Time 44.41728591918945s

Training epoch 177, Batch 500/1000: LR=9.26e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 177, Batch 1000/1000: LR=9.26e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 177 Train Time 44.72047972679138s

Training epoch 178, Batch 500/1000: LR=9.25e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 178, Batch 1000/1000: LR=9.25e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 178 Train Time 44.52303075790405s

Training epoch 179, Batch 500/1000: LR=9.25e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 179, Batch 1000/1000: LR=9.25e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 179 Train Time 44.772337198257446s

Training epoch 180, Batch 500/1000: LR=9.24e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.21e-01
Training epoch 180, Batch 1000/1000: LR=9.24e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Epoch 180 Train Time 44.55591893196106s

Training epoch 181, Batch 500/1000: LR=9.23e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 181, Batch 1000/1000: LR=9.23e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 181 Train Time 44.48211693763733s

Training epoch 182, Batch 500/1000: LR=9.22e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 182, Batch 1000/1000: LR=9.22e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.19e-01
Epoch 182 Train Time 44.52998900413513s

Training epoch 183, Batch 500/1000: LR=9.21e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 183, Batch 1000/1000: LR=9.21e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 183 Train Time 44.38936424255371s

Training epoch 184, Batch 500/1000: LR=9.20e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 184, Batch 1000/1000: LR=9.20e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Epoch 184 Train Time 44.621742963790894s

Training epoch 185, Batch 500/1000: LR=9.20e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 185, Batch 1000/1000: LR=9.20e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 185 Train Time 44.627729415893555s

Training epoch 186, Batch 500/1000: LR=9.19e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 186, Batch 1000/1000: LR=9.19e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 186 Train Time 44.470131397247314s

Training epoch 187, Batch 500/1000: LR=9.18e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 187, Batch 1000/1000: LR=9.18e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.19e-01
Epoch 187 Train Time 44.734432220458984s

Training epoch 188, Batch 500/1000: LR=9.17e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 188, Batch 1000/1000: LR=9.17e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.18e-01
Epoch 188 Train Time 44.574867963790894s

Training epoch 189, Batch 500/1000: LR=9.16e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 189, Batch 1000/1000: LR=9.16e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 189 Train Time 44.47513461112976s

Training epoch 190, Batch 500/1000: LR=9.15e-05, Loss=3.14e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 190, Batch 1000/1000: LR=9.15e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 190 Train Time 44.48311519622803s

Training epoch 191, Batch 500/1000: LR=9.14e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 191, Batch 1000/1000: LR=9.14e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 191 Train Time 44.5110387802124s

Training epoch 192, Batch 500/1000: LR=9.14e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.21e-01
Training epoch 192, Batch 1000/1000: LR=9.14e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 192 Train Time 44.54594707489014s

Training epoch 193, Batch 500/1000: LR=9.13e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 193, Batch 1000/1000: LR=9.13e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 193 Train Time 44.53693985939026s

Training epoch 194, Batch 500/1000: LR=9.12e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 194, Batch 1000/1000: LR=9.12e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 194 Train Time 44.398364782333374s

Training epoch 195, Batch 500/1000: LR=9.11e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 195, Batch 1000/1000: LR=9.11e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 195 Train Time 44.735440492630005s

Training epoch 196, Batch 500/1000: LR=9.10e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 196, Batch 1000/1000: LR=9.10e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 196 Train Time 44.472142457962036s

Training epoch 197, Batch 500/1000: LR=9.09e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 197, Batch 1000/1000: LR=9.09e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.20e-01
Epoch 197 Train Time 44.41130566596985s

Training epoch 198, Batch 500/1000: LR=9.08e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 198, Batch 1000/1000: LR=9.08e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 198 Train Time 44.437235593795776s

Training epoch 199, Batch 500/1000: LR=9.07e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 199, Batch 1000/1000: LR=9.07e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 199 Train Time 44.550931215286255s

Training epoch 200, Batch 500/1000: LR=9.06e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 200, Batch 1000/1000: LR=9.06e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 200 Train Time 44.549933671951294s

Training epoch 201, Batch 500/1000: LR=9.05e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 201, Batch 1000/1000: LR=9.05e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 201 Train Time 44.44720983505249s

Training epoch 202, Batch 500/1000: LR=9.05e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 202, Batch 1000/1000: LR=9.05e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 202 Train Time 44.84016036987305s

Training epoch 203, Batch 500/1000: LR=9.04e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 203, Batch 1000/1000: LR=9.04e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 203 Train Time 44.68158411979675s

Training epoch 204, Batch 500/1000: LR=9.03e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 204, Batch 1000/1000: LR=9.03e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 204 Train Time 68.49797821044922s

Training epoch 205, Batch 500/1000: LR=9.02e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 205, Batch 1000/1000: LR=9.02e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 205 Train Time 46.52066779136658s

Training epoch 206, Batch 500/1000: LR=9.01e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 206, Batch 1000/1000: LR=9.01e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 206 Train Time 45.72180247306824s

Training epoch 207, Batch 500/1000: LR=9.00e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 207, Batch 1000/1000: LR=9.00e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 207 Train Time 45.65098547935486s

Training epoch 208, Batch 500/1000: LR=8.99e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 208, Batch 1000/1000: LR=8.99e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 208 Train Time 45.589157819747925s

Training epoch 209, Batch 500/1000: LR=8.98e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 209, Batch 1000/1000: LR=8.98e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.19e-01
Epoch 209 Train Time 45.58616518974304s

Training epoch 210, Batch 500/1000: LR=8.97e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 210, Batch 1000/1000: LR=8.97e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 210 Train Time 45.75471544265747s

Training epoch 211, Batch 500/1000: LR=8.96e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.18e-01
Training epoch 211, Batch 1000/1000: LR=8.96e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 211 Train Time 45.6430139541626s

Training epoch 212, Batch 500/1000: LR=8.95e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 212, Batch 1000/1000: LR=8.95e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Epoch 212 Train Time 45.90231943130493s

Training epoch 213, Batch 500/1000: LR=8.94e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 213, Batch 1000/1000: LR=8.94e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 213 Train Time 45.542283058166504s

Training epoch 214, Batch 500/1000: LR=8.93e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 214, Batch 1000/1000: LR=8.93e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 214 Train Time 45.58915948867798s

Training epoch 215, Batch 500/1000: LR=8.92e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 215, Batch 1000/1000: LR=8.92e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 215 Train Time 45.837493658065796s

Training epoch 216, Batch 500/1000: LR=8.91e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 216, Batch 1000/1000: LR=8.91e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 216 Train Time 45.44055700302124s

Training epoch 217, Batch 500/1000: LR=8.90e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 217, Batch 1000/1000: LR=8.90e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.18e-01
Epoch 217 Train Time 45.57818555831909s

Training epoch 218, Batch 500/1000: LR=8.89e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 218, Batch 1000/1000: LR=8.89e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 218 Train Time 45.85245394706726s

Training epoch 219, Batch 500/1000: LR=8.88e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 219, Batch 1000/1000: LR=8.88e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 219 Train Time 45.615086793899536s

Training epoch 220, Batch 500/1000: LR=8.87e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 220, Batch 1000/1000: LR=8.87e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 220 Train Time 45.49241662025452s

Training epoch 221, Batch 500/1000: LR=8.86e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 221, Batch 1000/1000: LR=8.86e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 221 Train Time 45.74870276451111s

Training epoch 222, Batch 500/1000: LR=8.85e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 222, Batch 1000/1000: LR=8.85e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 222 Train Time 45.69889688491821s

Training epoch 223, Batch 500/1000: LR=8.84e-05, Loss=3.15e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 223, Batch 1000/1000: LR=8.84e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.19e-01
Epoch 223 Train Time 45.81554961204529s

Training epoch 224, Batch 500/1000: LR=8.83e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 224, Batch 1000/1000: LR=8.83e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 224 Train Time 45.58117914199829s

Training epoch 225, Batch 500/1000: LR=8.82e-05, Loss=3.03e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 225, Batch 1000/1000: LR=8.82e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 225 Train Time 45.55125880241394s

Training epoch 226, Batch 500/1000: LR=8.81e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 226, Batch 1000/1000: LR=8.81e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 226 Train Time 45.64600658416748s

Training epoch 227, Batch 500/1000: LR=8.80e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 227, Batch 1000/1000: LR=8.80e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 227 Train Time 45.167285442352295s

Training epoch 228, Batch 500/1000: LR=8.79e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 228, Batch 1000/1000: LR=8.79e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 228 Train Time 44.98576903343201s

Training epoch 229, Batch 500/1000: LR=8.78e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 229, Batch 1000/1000: LR=8.78e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 229 Train Time 45.20019721984863s

Training epoch 230, Batch 500/1000: LR=8.77e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 230, Batch 1000/1000: LR=8.77e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 230 Train Time 44.93291139602661s

Training epoch 231, Batch 500/1000: LR=8.76e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.19e-01
Training epoch 231, Batch 1000/1000: LR=8.76e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.19e-01
Epoch 231 Train Time 44.928924322128296s

Training epoch 232, Batch 500/1000: LR=8.75e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 232, Batch 1000/1000: LR=8.75e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 232 Train Time 44.928919315338135s

Training epoch 233, Batch 500/1000: LR=8.74e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 233, Batch 1000/1000: LR=8.74e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 233 Train Time 44.952858209609985s

Training epoch 234, Batch 500/1000: LR=8.73e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 234, Batch 1000/1000: LR=8.73e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Epoch 234 Train Time 44.95983958244324s

Training epoch 235, Batch 500/1000: LR=8.72e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 235, Batch 1000/1000: LR=8.72e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 235 Train Time 44.93690204620361s

Training epoch 236, Batch 500/1000: LR=8.71e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 236, Batch 1000/1000: LR=8.71e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 236 Train Time 44.806248903274536s

Training epoch 237, Batch 500/1000: LR=8.70e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 237, Batch 1000/1000: LR=8.70e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 237 Train Time 45.19221806526184s

Training epoch 238, Batch 500/1000: LR=8.69e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 238, Batch 1000/1000: LR=8.69e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 238 Train Time 45.24507212638855s

Training epoch 239, Batch 500/1000: LR=8.68e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 239, Batch 1000/1000: LR=8.68e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 239 Train Time 45.074533224105835s

Training epoch 240, Batch 500/1000: LR=8.67e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 240, Batch 1000/1000: LR=8.67e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 240 Train Time 45.07752466201782s

Training epoch 241, Batch 500/1000: LR=8.66e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 241, Batch 1000/1000: LR=8.66e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 241 Train Time 45.02765917778015s

Training epoch 242, Batch 500/1000: LR=8.65e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 242, Batch 1000/1000: LR=8.65e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 242 Train Time 44.9718074798584s

Training epoch 243, Batch 500/1000: LR=8.64e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 243, Batch 1000/1000: LR=8.64e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 243 Train Time 44.85611629486084s

Training epoch 244, Batch 500/1000: LR=8.63e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 244, Batch 1000/1000: LR=8.63e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 244 Train Time 109.29139447212219s

Training epoch 245, Batch 500/1000: LR=8.62e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 245, Batch 1000/1000: LR=8.62e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 245 Train Time 46.62937879562378s

Training epoch 246, Batch 500/1000: LR=8.60e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 246, Batch 1000/1000: LR=8.60e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Epoch 246 Train Time 45.9801127910614s

Training epoch 247, Batch 500/1000: LR=8.59e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 247, Batch 1000/1000: LR=8.59e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 247 Train Time 45.77963948249817s

Training epoch 248, Batch 500/1000: LR=8.58e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 248, Batch 1000/1000: LR=8.58e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Epoch 248 Train Time 45.688912868499756s

Training epoch 249, Batch 500/1000: LR=8.57e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 249, Batch 1000/1000: LR=8.57e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 249 Train Time 45.64500975608826s

Training epoch 250, Batch 500/1000: LR=8.56e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 250, Batch 1000/1000: LR=8.56e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 250 Train Time 46.350125312805176s

Training epoch 251, Batch 500/1000: LR=8.55e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 251, Batch 1000/1000: LR=8.55e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 251 Train Time 46.63536071777344s

Training epoch 252, Batch 500/1000: LR=8.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 252, Batch 1000/1000: LR=8.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 252 Train Time 45.467483043670654s

Training epoch 253, Batch 500/1000: LR=8.53e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 253, Batch 1000/1000: LR=8.53e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 253 Train Time 45.51335906982422s

Training epoch 254, Batch 500/1000: LR=8.52e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 254, Batch 1000/1000: LR=8.52e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 254 Train Time 45.13437271118164s

Training epoch 255, Batch 500/1000: LR=8.51e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 255, Batch 1000/1000: LR=8.51e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 255 Train Time 44.86509299278259s

Training epoch 256, Batch 500/1000: LR=8.49e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 256, Batch 1000/1000: LR=8.49e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 256 Train Time 44.99175477027893s

Training epoch 257, Batch 500/1000: LR=8.48e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 257, Batch 1000/1000: LR=8.48e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 257 Train Time 45.04660654067993s

Training epoch 258, Batch 500/1000: LR=8.47e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 258, Batch 1000/1000: LR=8.47e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 258 Train Time 45.145373582839966s

Training epoch 259, Batch 500/1000: LR=8.46e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 259, Batch 1000/1000: LR=8.46e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 259 Train Time 44.975796699523926s

Training epoch 260, Batch 500/1000: LR=8.45e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 260, Batch 1000/1000: LR=8.45e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 260 Train Time 45.005717515945435s

Training epoch 261, Batch 500/1000: LR=8.44e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 261, Batch 1000/1000: LR=8.44e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Epoch 261 Train Time 45.358773946762085s

Training epoch 262, Batch 500/1000: LR=8.43e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 262, Batch 1000/1000: LR=8.43e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 262 Train Time 44.99075722694397s

Training epoch 263, Batch 500/1000: LR=8.42e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 263, Batch 1000/1000: LR=8.42e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 263 Train Time 45.258042097091675s

Training epoch 264, Batch 500/1000: LR=8.40e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 264, Batch 1000/1000: LR=8.40e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 264 Train Time 45.240113973617554s

Training epoch 265, Batch 500/1000: LR=8.39e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 265, Batch 1000/1000: LR=8.39e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 265 Train Time 45.004718542099s

Training epoch 266, Batch 500/1000: LR=8.38e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 266, Batch 1000/1000: LR=8.38e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 266 Train Time 44.42228055000305s

Training epoch 267, Batch 500/1000: LR=8.37e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 267, Batch 1000/1000: LR=8.37e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 267 Train Time 44.39933156967163s

Training epoch 268, Batch 500/1000: LR=8.36e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 268, Batch 1000/1000: LR=8.36e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 268 Train Time 44.41629099845886s

Training epoch 269, Batch 500/1000: LR=8.35e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 269, Batch 1000/1000: LR=8.35e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 269 Train Time 44.834147930145264s

Training epoch 270, Batch 500/1000: LR=8.34e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 270, Batch 1000/1000: LR=8.34e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Epoch 270 Train Time 44.340495347976685s

Training epoch 271, Batch 500/1000: LR=8.32e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 271, Batch 1000/1000: LR=8.32e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 271 Train Time 44.42925786972046s

Training epoch 272, Batch 500/1000: LR=8.31e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 272, Batch 1000/1000: LR=8.31e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 272 Train Time 44.57885766029358s

Training epoch 273, Batch 500/1000: LR=8.30e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 273, Batch 1000/1000: LR=8.30e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 273 Train Time 44.40036582946777s

Training epoch 274, Batch 500/1000: LR=8.29e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 274, Batch 1000/1000: LR=8.29e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 274 Train Time 44.366427183151245s

Training epoch 275, Batch 500/1000: LR=8.28e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 275, Batch 1000/1000: LR=8.28e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 275 Train Time 44.48111629486084s

Training epoch 276, Batch 500/1000: LR=8.26e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 276, Batch 1000/1000: LR=8.26e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Epoch 276 Train Time 44.43324828147888s

Training epoch 277, Batch 500/1000: LR=8.25e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 277, Batch 1000/1000: LR=8.25e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 277 Train Time 44.631739139556885s

Training epoch 278, Batch 500/1000: LR=8.24e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 278, Batch 1000/1000: LR=8.24e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.17e-01
Epoch 278 Train Time 44.4761323928833s

Training epoch 279, Batch 500/1000: LR=8.23e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 279, Batch 1000/1000: LR=8.23e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 279 Train Time 44.39933705329895s

Training epoch 280, Batch 500/1000: LR=8.22e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 280, Batch 1000/1000: LR=8.22e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 280 Train Time 44.5100417137146s

Training epoch 281, Batch 500/1000: LR=8.21e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 281, Batch 1000/1000: LR=8.21e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 281 Train Time 44.69953441619873s

Training epoch 282, Batch 500/1000: LR=8.19e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 282, Batch 1000/1000: LR=8.19e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 282 Train Time 44.39936089515686s

Training epoch 283, Batch 500/1000: LR=8.18e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 283, Batch 1000/1000: LR=8.18e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 283 Train Time 44.39036297798157s

Training epoch 284, Batch 500/1000: LR=8.17e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 284, Batch 1000/1000: LR=8.17e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.16e-01
Epoch 284 Train Time 44.31755566596985s

Training epoch 285, Batch 500/1000: LR=8.16e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 285, Batch 1000/1000: LR=8.16e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 285 Train Time 131.9389078617096s

Training epoch 286, Batch 500/1000: LR=8.14e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 286, Batch 1000/1000: LR=8.14e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Epoch 286 Train Time 46.0200080871582s

Training epoch 287, Batch 500/1000: LR=8.13e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 287, Batch 1000/1000: LR=8.13e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 287 Train Time 45.10744380950928s

Training epoch 288, Batch 500/1000: LR=8.12e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 288, Batch 1000/1000: LR=8.12e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 288 Train Time 45.200196743011475s

Training epoch 289, Batch 500/1000: LR=8.11e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 289, Batch 1000/1000: LR=8.11e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 289 Train Time 44.71150302886963s

Training epoch 290, Batch 500/1000: LR=8.10e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 290, Batch 1000/1000: LR=8.10e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 290 Train Time 44.50603008270264s

Training epoch 291, Batch 500/1000: LR=8.08e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 291, Batch 1000/1000: LR=8.08e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 291 Train Time 44.54594445228577s

Training epoch 292, Batch 500/1000: LR=8.07e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 292, Batch 1000/1000: LR=8.07e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 292 Train Time 44.45917749404907s

Training epoch 293, Batch 500/1000: LR=8.06e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 293, Batch 1000/1000: LR=8.06e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 293 Train Time 44.60877728462219s

Training epoch 294, Batch 500/1000: LR=8.05e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 294, Batch 1000/1000: LR=8.05e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 294 Train Time 44.354480028152466s

Training epoch 295, Batch 500/1000: LR=8.03e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 295, Batch 1000/1000: LR=8.03e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 295 Train Time 44.512036085128784s

Training epoch 296, Batch 500/1000: LR=8.02e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 296, Batch 1000/1000: LR=8.02e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 296 Train Time 44.9319372177124s

Training epoch 297, Batch 500/1000: LR=8.01e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 297, Batch 1000/1000: LR=8.01e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 297 Train Time 44.58284616470337s

Training epoch 298, Batch 500/1000: LR=8.00e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.17e-01
Training epoch 298, Batch 1000/1000: LR=8.00e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 298 Train Time 44.49807333946228s

Training epoch 299, Batch 500/1000: LR=7.98e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 299, Batch 1000/1000: LR=7.98e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 299 Train Time 44.23976421356201s

Training epoch 300, Batch 500/1000: LR=7.97e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 300, Batch 1000/1000: LR=7.97e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Epoch 300 Train Time 45.04361438751221s


Test Loss 1: 2.31e-01 2: 1.21e-01 3: 4.42e-02
Test FER 1: 6.82e-01 2: 4.24e-01 3: 1.79e-01
Test BER 1: 9.51e-02 2: 4.97e-02 3: 1.75e-02
Test -ln(BER) 1: 2.35e+00 2: 3.00e+00 3: 4.04e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 64.7908399105072 s

Training epoch 301, Batch 500/1000: LR=7.96e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 301, Batch 1000/1000: LR=7.96e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 301 Train Time 44.45020127296448s

Training epoch 302, Batch 500/1000: LR=7.95e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 302, Batch 1000/1000: LR=7.95e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 302 Train Time 44.558910846710205s

Training epoch 303, Batch 500/1000: LR=7.93e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 303, Batch 1000/1000: LR=7.93e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 303 Train Time 44.53098678588867s

Training epoch 304, Batch 500/1000: LR=7.92e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 304, Batch 1000/1000: LR=7.92e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Epoch 304 Train Time 44.47214317321777s

Training epoch 305, Batch 500/1000: LR=7.91e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 305, Batch 1000/1000: LR=7.91e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 305 Train Time 44.50308609008789s

Training epoch 306, Batch 500/1000: LR=7.90e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 306, Batch 1000/1000: LR=7.90e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.17e-01
Epoch 306 Train Time 44.744415521621704s

Training epoch 307, Batch 500/1000: LR=7.88e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 307, Batch 1000/1000: LR=7.88e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 307 Train Time 44.31057357788086s

Training epoch 308, Batch 500/1000: LR=7.87e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 308, Batch 1000/1000: LR=7.87e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 308 Train Time 44.37540102005005s

Training epoch 309, Batch 500/1000: LR=7.86e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 309, Batch 1000/1000: LR=7.86e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 309 Train Time 44.42227530479431s

Training epoch 310, Batch 500/1000: LR=7.85e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 310, Batch 1000/1000: LR=7.85e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Epoch 310 Train Time 44.31855320930481s

Training epoch 311, Batch 500/1000: LR=7.83e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 311, Batch 1000/1000: LR=7.83e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 311 Train Time 44.48710250854492s

Training epoch 312, Batch 500/1000: LR=7.82e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 312, Batch 1000/1000: LR=7.82e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 312 Train Time 44.37639594078064s

Training epoch 313, Batch 500/1000: LR=7.81e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 313, Batch 1000/1000: LR=7.81e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 313 Train Time 44.50505471229553s

Training epoch 314, Batch 500/1000: LR=7.79e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 314, Batch 1000/1000: LR=7.79e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 314 Train Time 44.753392457962036s

Training epoch 315, Batch 500/1000: LR=7.78e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 315, Batch 1000/1000: LR=7.78e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 315 Train Time 44.59182286262512s

Training epoch 316, Batch 500/1000: LR=7.77e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 316, Batch 1000/1000: LR=7.77e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 316 Train Time 44.393351793289185s

Training epoch 317, Batch 500/1000: LR=7.75e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 317, Batch 1000/1000: LR=7.75e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Epoch 317 Train Time 44.37340784072876s

Training epoch 318, Batch 500/1000: LR=7.74e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 318, Batch 1000/1000: LR=7.74e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 318 Train Time 44.69255471229553s

Training epoch 319, Batch 500/1000: LR=7.73e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 319, Batch 1000/1000: LR=7.73e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 319 Train Time 44.67759323120117s

Training epoch 320, Batch 500/1000: LR=7.72e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 320, Batch 1000/1000: LR=7.72e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Epoch 320 Train Time 44.44720983505249s

Training epoch 321, Batch 500/1000: LR=7.70e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 321, Batch 1000/1000: LR=7.70e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Epoch 321 Train Time 44.90897536277771s

Training epoch 322, Batch 500/1000: LR=7.69e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 322, Batch 1000/1000: LR=7.69e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 322 Train Time 44.92593002319336s

Training epoch 323, Batch 500/1000: LR=7.68e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 323, Batch 1000/1000: LR=7.68e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 323 Train Time 44.33550810813904s

Training epoch 324, Batch 500/1000: LR=7.66e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 324, Batch 1000/1000: LR=7.66e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 324 Train Time 65.64568614959717s

Training epoch 325, Batch 500/1000: LR=7.65e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 325, Batch 1000/1000: LR=7.65e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 325 Train Time 47.55689859390259s

Training epoch 326, Batch 500/1000: LR=7.64e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 326, Batch 1000/1000: LR=7.64e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 326 Train Time 45.94819784164429s

Training epoch 327, Batch 500/1000: LR=7.62e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 327, Batch 1000/1000: LR=7.62e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 327 Train Time 45.874393939971924s

Training epoch 328, Batch 500/1000: LR=7.61e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 328, Batch 1000/1000: LR=7.61e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 328 Train Time 45.771669149398804s

Training epoch 329, Batch 500/1000: LR=7.60e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 329, Batch 1000/1000: LR=7.60e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 329 Train Time 45.01668739318848s

Training epoch 330, Batch 500/1000: LR=7.58e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 330, Batch 1000/1000: LR=7.58e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.15e-01
Epoch 330 Train Time 45.053590059280396s

Training epoch 331, Batch 500/1000: LR=7.57e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 331, Batch 1000/1000: LR=7.57e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 331 Train Time 45.22714829444885s

Training epoch 332, Batch 500/1000: LR=7.56e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 332, Batch 1000/1000: LR=7.56e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 332 Train Time 45.21415996551514s

Training epoch 333, Batch 500/1000: LR=7.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 333, Batch 1000/1000: LR=7.54e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 333 Train Time 45.013691902160645s

Training epoch 334, Batch 500/1000: LR=7.53e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 334, Batch 1000/1000: LR=7.53e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 334 Train Time 45.05259156227112s

Training epoch 335, Batch 500/1000: LR=7.52e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 335, Batch 1000/1000: LR=7.52e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 335 Train Time 45.30392050743103s

Training epoch 336, Batch 500/1000: LR=7.50e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.12e-01
Training epoch 336, Batch 1000/1000: LR=7.50e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 336 Train Time 45.136367321014404s

Training epoch 337, Batch 500/1000: LR=7.49e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 337, Batch 1000/1000: LR=7.49e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 337 Train Time 45.45850658416748s

Training epoch 338, Batch 500/1000: LR=7.48e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 338, Batch 1000/1000: LR=7.48e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 338 Train Time 45.22812294960022s

Training epoch 339, Batch 500/1000: LR=7.46e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 339, Batch 1000/1000: LR=7.46e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 339 Train Time 45.13636779785156s

Training epoch 340, Batch 500/1000: LR=7.45e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 340, Batch 1000/1000: LR=7.45e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Epoch 340 Train Time 44.4900963306427s

Training epoch 341, Batch 500/1000: LR=7.43e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 341, Batch 1000/1000: LR=7.43e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 341 Train Time 44.62772750854492s

Training epoch 342, Batch 500/1000: LR=7.42e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 342, Batch 1000/1000: LR=7.42e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 342 Train Time 44.4681761264801s

Training epoch 343, Batch 500/1000: LR=7.41e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 343, Batch 1000/1000: LR=7.41e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 343 Train Time 44.50605297088623s

Training epoch 344, Batch 500/1000: LR=7.39e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 344, Batch 1000/1000: LR=7.39e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.16e-01
Epoch 344 Train Time 44.30955386161804s

Training epoch 345, Batch 500/1000: LR=7.38e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 345, Batch 1000/1000: LR=7.38e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 345 Train Time 44.38338088989258s

Training epoch 346, Batch 500/1000: LR=7.37e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 346, Batch 1000/1000: LR=7.37e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 346 Train Time 44.31555128097534s

Training epoch 347, Batch 500/1000: LR=7.35e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 347, Batch 1000/1000: LR=7.35e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 347 Train Time 44.412301778793335s

Training epoch 348, Batch 500/1000: LR=7.34e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 348, Batch 1000/1000: LR=7.34e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 348 Train Time 44.32254362106323s

Training epoch 349, Batch 500/1000: LR=7.32e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 349, Batch 1000/1000: LR=7.32e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 349 Train Time 44.595810413360596s

Training epoch 350, Batch 500/1000: LR=7.31e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 350, Batch 1000/1000: LR=7.31e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.16e-01
Epoch 350 Train Time 44.539954662323s

Training epoch 351, Batch 500/1000: LR=7.30e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 351, Batch 1000/1000: LR=7.30e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 351 Train Time 44.414299726486206s

Training epoch 352, Batch 500/1000: LR=7.28e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 352, Batch 1000/1000: LR=7.28e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 352 Train Time 44.40532183647156s

Training epoch 353, Batch 500/1000: LR=7.27e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 353, Batch 1000/1000: LR=7.27e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Epoch 353 Train Time 44.44820785522461s

Training epoch 354, Batch 500/1000: LR=7.26e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 354, Batch 1000/1000: LR=7.26e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 354 Train Time 44.4531934261322s

Training epoch 355, Batch 500/1000: LR=7.24e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 355, Batch 1000/1000: LR=7.24e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 355 Train Time 44.4332480430603s

Training epoch 356, Batch 500/1000: LR=7.23e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 356, Batch 1000/1000: LR=7.23e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 356 Train Time 44.5549201965332s

Training epoch 357, Batch 500/1000: LR=7.21e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 357, Batch 1000/1000: LR=7.21e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 357 Train Time 44.76436138153076s

Training epoch 358, Batch 500/1000: LR=7.20e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 358, Batch 1000/1000: LR=7.20e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.16e-01
Epoch 358 Train Time 44.49807333946228s

Training epoch 359, Batch 500/1000: LR=7.19e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 359, Batch 1000/1000: LR=7.19e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 359 Train Time 44.6855731010437s

Training epoch 360, Batch 500/1000: LR=7.17e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 360, Batch 1000/1000: LR=7.17e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 360 Train Time 44.52599811553955s

Training epoch 361, Batch 500/1000: LR=7.16e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 361, Batch 1000/1000: LR=7.16e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 361 Train Time 44.641690254211426s

Training epoch 362, Batch 500/1000: LR=7.14e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 362, Batch 1000/1000: LR=7.14e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 362 Train Time 44.76436185836792s

Training epoch 363, Batch 500/1000: LR=7.13e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 363, Batch 1000/1000: LR=7.13e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 363 Train Time 44.53097462654114s

Training epoch 364, Batch 500/1000: LR=7.12e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 364, Batch 1000/1000: LR=7.12e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.14e-01
Epoch 364 Train Time 44.62872314453125s

Training epoch 365, Batch 500/1000: LR=7.10e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 365, Batch 1000/1000: LR=7.10e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 365 Train Time 68.3156328201294s

Training epoch 366, Batch 500/1000: LR=7.09e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 366, Batch 1000/1000: LR=7.09e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 366 Train Time 45.65799570083618s

Training epoch 367, Batch 500/1000: LR=7.07e-05, Loss=2.98e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 367, Batch 1000/1000: LR=7.07e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 367 Train Time 45.38971447944641s

Training epoch 368, Batch 500/1000: LR=7.06e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 368, Batch 1000/1000: LR=7.06e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Epoch 368 Train Time 45.14135456085205s

Training epoch 369, Batch 500/1000: LR=7.04e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 369, Batch 1000/1000: LR=7.04e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 369 Train Time 45.15930414199829s

Training epoch 370, Batch 500/1000: LR=7.03e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 370, Batch 1000/1000: LR=7.03e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 370 Train Time 45.068549394607544s

Training epoch 371, Batch 500/1000: LR=7.02e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 371, Batch 1000/1000: LR=7.02e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 371 Train Time 44.971808195114136s

Training epoch 372, Batch 500/1000: LR=7.00e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 372, Batch 1000/1000: LR=7.00e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 372 Train Time 45.066556215286255s

Training epoch 373, Batch 500/1000: LR=6.99e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 373, Batch 1000/1000: LR=6.99e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 373 Train Time 45.15928363800049s

Training epoch 374, Batch 500/1000: LR=6.97e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 374, Batch 1000/1000: LR=6.97e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 374 Train Time 45.12539863586426s

Training epoch 375, Batch 500/1000: LR=6.96e-05, Loss=3.04e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 375, Batch 1000/1000: LR=6.96e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 375 Train Time 45.175299644470215s

Training epoch 376, Batch 500/1000: LR=6.94e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 376, Batch 1000/1000: LR=6.94e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 376 Train Time 45.11143398284912s

Training epoch 377, Batch 500/1000: LR=6.93e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 377, Batch 1000/1000: LR=6.93e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 377 Train Time 45.40866017341614s

Training epoch 378, Batch 500/1000: LR=6.92e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 378, Batch 1000/1000: LR=6.92e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 378 Train Time 45.107444524765015s

Training epoch 379, Batch 500/1000: LR=6.90e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 379, Batch 1000/1000: LR=6.90e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 379 Train Time 44.983776807785034s

Training epoch 380, Batch 500/1000: LR=6.89e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 380, Batch 1000/1000: LR=6.89e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 380 Train Time 45.11642122268677s

Training epoch 381, Batch 500/1000: LR=6.87e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 381, Batch 1000/1000: LR=6.87e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 381 Train Time 45.01369547843933s

Training epoch 382, Batch 500/1000: LR=6.86e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 382, Batch 1000/1000: LR=6.86e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 382 Train Time 45.143348932266235s

Training epoch 383, Batch 500/1000: LR=6.84e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 383, Batch 1000/1000: LR=6.84e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 383 Train Time 44.27566909790039s

Training epoch 384, Batch 500/1000: LR=6.83e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 384, Batch 1000/1000: LR=6.83e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Epoch 384 Train Time 44.53796696662903s

Training epoch 385, Batch 500/1000: LR=6.81e-05, Loss=2.99e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 385, Batch 1000/1000: LR=6.81e-05, Loss=2.98e-02 BER=1.19e-02 FER=1.13e-01
Epoch 385 Train Time 44.77436423301697s

Training epoch 386, Batch 500/1000: LR=6.80e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 386, Batch 1000/1000: LR=6.80e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 386 Train Time 44.410308599472046s

Training epoch 387, Batch 500/1000: LR=6.79e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 387, Batch 1000/1000: LR=6.79e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 387 Train Time 44.586836099624634s

Training epoch 388, Batch 500/1000: LR=6.77e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 388, Batch 1000/1000: LR=6.77e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 388 Train Time 44.480124711990356s

Training epoch 389, Batch 500/1000: LR=6.76e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 389, Batch 1000/1000: LR=6.76e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 389 Train Time 44.31256866455078s

Training epoch 390, Batch 500/1000: LR=6.74e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 390, Batch 1000/1000: LR=6.74e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 390 Train Time 44.46316599845886s

Training epoch 391, Batch 500/1000: LR=6.73e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 391, Batch 1000/1000: LR=6.73e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 391 Train Time 44.548938512802124s

Training epoch 392, Batch 500/1000: LR=6.71e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 392, Batch 1000/1000: LR=6.71e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 392 Train Time 44.65664887428284s

Training epoch 393, Batch 500/1000: LR=6.70e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 393, Batch 1000/1000: LR=6.70e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 393 Train Time 44.66163611412048s

Training epoch 394, Batch 500/1000: LR=6.68e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 394, Batch 1000/1000: LR=6.68e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 394 Train Time 44.485108613967896s

Training epoch 395, Batch 500/1000: LR=6.67e-05, Loss=3.03e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 395, Batch 1000/1000: LR=6.67e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 395 Train Time 44.57586669921875s

Training epoch 396, Batch 500/1000: LR=6.65e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 396, Batch 1000/1000: LR=6.65e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 396 Train Time 44.34149169921875s

Training epoch 397, Batch 500/1000: LR=6.64e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 397, Batch 1000/1000: LR=6.64e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 397 Train Time 44.501065492630005s

Training epoch 398, Batch 500/1000: LR=6.62e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 398, Batch 1000/1000: LR=6.62e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 398 Train Time 44.40631699562073s

Training epoch 399, Batch 500/1000: LR=6.61e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 399, Batch 1000/1000: LR=6.61e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 399 Train Time 44.791284799575806s

Training epoch 400, Batch 500/1000: LR=6.59e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 400, Batch 1000/1000: LR=6.59e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Epoch 400 Train Time 44.76637864112854s

Training epoch 401, Batch 500/1000: LR=6.58e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 401, Batch 1000/1000: LR=6.58e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.15e-01
Epoch 401 Train Time 44.51203727722168s

Training epoch 402, Batch 500/1000: LR=6.56e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 402, Batch 1000/1000: LR=6.56e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 402 Train Time 44.44221067428589s

Training epoch 403, Batch 500/1000: LR=6.55e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 403, Batch 1000/1000: LR=6.55e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 403 Train Time 44.51303434371948s

Training epoch 404, Batch 500/1000: LR=6.54e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 404, Batch 1000/1000: LR=6.54e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 404 Train Time 44.605788230895996s

Training epoch 405, Batch 500/1000: LR=6.52e-05, Loss=3.03e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 405, Batch 1000/1000: LR=6.52e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 405 Train Time 44.56090497970581s

Training epoch 406, Batch 500/1000: LR=6.51e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 406, Batch 1000/1000: LR=6.51e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 406 Train Time 76.86074566841125s

Training epoch 407, Batch 500/1000: LR=6.49e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 407, Batch 1000/1000: LR=6.49e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 407 Train Time 46.07386112213135s

Training epoch 408, Batch 500/1000: LR=6.48e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 408, Batch 1000/1000: LR=6.48e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 408 Train Time 45.742772579193115s

Training epoch 409, Batch 500/1000: LR=6.46e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 409, Batch 1000/1000: LR=6.46e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Epoch 409 Train Time 45.708860874176025s

Training epoch 410, Batch 500/1000: LR=6.45e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 410, Batch 1000/1000: LR=6.45e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 410 Train Time 45.75174951553345s

Training epoch 411, Batch 500/1000: LR=6.43e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 411, Batch 1000/1000: LR=6.43e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 411 Train Time 45.441575050354004s

Training epoch 412, Batch 500/1000: LR=6.42e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 412, Batch 1000/1000: LR=6.42e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 412 Train Time 44.907976388931274s

Training epoch 413, Batch 500/1000: LR=6.40e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 413, Batch 1000/1000: LR=6.40e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 413 Train Time 45.585161209106445s

Training epoch 414, Batch 500/1000: LR=6.39e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 414, Batch 1000/1000: LR=6.39e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 414 Train Time 45.11243033409119s

Training epoch 415, Batch 500/1000: LR=6.37e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 415, Batch 1000/1000: LR=6.37e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 415 Train Time 44.89800453186035s

Training epoch 416, Batch 500/1000: LR=6.36e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 416, Batch 1000/1000: LR=6.36e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 416 Train Time 45.05757761001587s

Training epoch 417, Batch 500/1000: LR=6.34e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 417, Batch 1000/1000: LR=6.34e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 417 Train Time 45.248069524765015s

Training epoch 418, Batch 500/1000: LR=6.33e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.11e-01
Training epoch 418, Batch 1000/1000: LR=6.33e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 418 Train Time 44.93889832496643s

Training epoch 419, Batch 500/1000: LR=6.31e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 419, Batch 1000/1000: LR=6.31e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 419 Train Time 45.28299856185913s

Training epoch 420, Batch 500/1000: LR=6.30e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 420, Batch 1000/1000: LR=6.30e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 420 Train Time 45.01566791534424s

Training epoch 421, Batch 500/1000: LR=6.28e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 421, Batch 1000/1000: LR=6.28e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 421 Train Time 45.201194524765015s

Training epoch 422, Batch 500/1000: LR=6.27e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 422, Batch 1000/1000: LR=6.27e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 422 Train Time 45.12040948867798s

Training epoch 423, Batch 500/1000: LR=6.25e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 423, Batch 1000/1000: LR=6.25e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 423 Train Time 45.0546088218689s

Training epoch 424, Batch 500/1000: LR=6.24e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 424, Batch 1000/1000: LR=6.24e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 424 Train Time 45.0835075378418s

Training epoch 425, Batch 500/1000: LR=6.22e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 425, Batch 1000/1000: LR=6.22e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 425 Train Time 45.02366924285889s

Training epoch 426, Batch 500/1000: LR=6.21e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 426, Batch 1000/1000: LR=6.21e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Epoch 426 Train Time 45.00372338294983s

Training epoch 427, Batch 500/1000: LR=6.19e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 427, Batch 1000/1000: LR=6.19e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 427 Train Time 45.066553592681885s

Training epoch 428, Batch 500/1000: LR=6.18e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 428, Batch 1000/1000: LR=6.18e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 428 Train Time 44.971808195114136s

Training epoch 429, Batch 500/1000: LR=6.16e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 429, Batch 1000/1000: LR=6.16e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 429 Train Time 44.823232889175415s

Training epoch 430, Batch 500/1000: LR=6.14e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 430, Batch 1000/1000: LR=6.14e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.13e-01
Epoch 430 Train Time 45.00571823120117s

Training epoch 431, Batch 500/1000: LR=6.13e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 431, Batch 1000/1000: LR=6.13e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 431 Train Time 45.1682825088501s

Training epoch 432, Batch 500/1000: LR=6.11e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 432, Batch 1000/1000: LR=6.11e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Epoch 432 Train Time 44.79430294036865s

Training epoch 433, Batch 500/1000: LR=6.10e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 433, Batch 1000/1000: LR=6.10e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 433 Train Time 45.10545015335083s

Training epoch 434, Batch 500/1000: LR=6.08e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 434, Batch 1000/1000: LR=6.08e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 434 Train Time 45.042641162872314s

Training epoch 435, Batch 500/1000: LR=6.07e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 435, Batch 1000/1000: LR=6.07e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Epoch 435 Train Time 44.867085456848145s

Training epoch 436, Batch 500/1000: LR=6.05e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 436, Batch 1000/1000: LR=6.05e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 436 Train Time 45.034639835357666s

Training epoch 437, Batch 500/1000: LR=6.04e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 437, Batch 1000/1000: LR=6.04e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Epoch 437 Train Time 44.914957761764526s

Training epoch 438, Batch 500/1000: LR=6.02e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 438, Batch 1000/1000: LR=6.02e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Epoch 438 Train Time 45.13138151168823s

Training epoch 439, Batch 500/1000: LR=6.01e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 439, Batch 1000/1000: LR=6.01e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 439 Train Time 45.16328477859497s

Training epoch 440, Batch 500/1000: LR=5.99e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 440, Batch 1000/1000: LR=5.99e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 440 Train Time 45.02765870094299s

Training epoch 441, Batch 500/1000: LR=5.98e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 441, Batch 1000/1000: LR=5.98e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Epoch 441 Train Time 44.853134632110596s

Training epoch 442, Batch 500/1000: LR=5.96e-05, Loss=2.98e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 442, Batch 1000/1000: LR=5.96e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 442 Train Time 45.239093542099s

Training epoch 443, Batch 500/1000: LR=5.95e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 443, Batch 1000/1000: LR=5.95e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 443 Train Time 44.981780767440796s

Training epoch 444, Batch 500/1000: LR=5.93e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 444, Batch 1000/1000: LR=5.93e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 444 Train Time 44.90797829627991s

Training epoch 445, Batch 500/1000: LR=5.92e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 445, Batch 1000/1000: LR=5.92e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 445 Train Time 44.902991771698s

Training epoch 446, Batch 500/1000: LR=5.90e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 446, Batch 1000/1000: LR=5.90e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 446 Train Time 104.71329140663147s

Training epoch 447, Batch 500/1000: LR=5.89e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 447, Batch 1000/1000: LR=5.89e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 447 Train Time 46.340149879455566s

Training epoch 448, Batch 500/1000: LR=5.87e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 448, Batch 1000/1000: LR=5.87e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 448 Train Time 45.93922400474548s

Training epoch 449, Batch 500/1000: LR=5.86e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 449, Batch 1000/1000: LR=5.86e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.14e-01
Epoch 449 Train Time 45.78565335273743s

Training epoch 450, Batch 500/1000: LR=5.84e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 450, Batch 1000/1000: LR=5.84e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 450 Train Time 45.73776078224182s

Training epoch 451, Batch 500/1000: LR=5.82e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 451, Batch 1000/1000: LR=5.82e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 451 Train Time 45.98612022399902s

Training epoch 452, Batch 500/1000: LR=5.81e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 452, Batch 1000/1000: LR=5.81e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 452 Train Time 45.74773406982422s

Training epoch 453, Batch 500/1000: LR=5.79e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 453, Batch 1000/1000: LR=5.79e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 453 Train Time 45.86641502380371s

Training epoch 454, Batch 500/1000: LR=5.78e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 454, Batch 1000/1000: LR=5.78e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 454 Train Time 45.668946981430054s

Training epoch 455, Batch 500/1000: LR=5.76e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 455, Batch 1000/1000: LR=5.76e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 455 Train Time 45.72479510307312s

Training epoch 456, Batch 500/1000: LR=5.75e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 456, Batch 1000/1000: LR=5.75e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 456 Train Time 45.780646085739136s

Training epoch 457, Batch 500/1000: LR=5.73e-05, Loss=2.98e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 457, Batch 1000/1000: LR=5.73e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 457 Train Time 45.741740465164185s

Training epoch 458, Batch 500/1000: LR=5.72e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 458, Batch 1000/1000: LR=5.72e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 458 Train Time 46.46282196044922s

Training epoch 459, Batch 500/1000: LR=5.70e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 459, Batch 1000/1000: LR=5.70e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 459 Train Time 45.67293310165405s

Training epoch 460, Batch 500/1000: LR=5.69e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 460, Batch 1000/1000: LR=5.69e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 460 Train Time 45.46848011016846s

Training epoch 461, Batch 500/1000: LR=5.67e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 461, Batch 1000/1000: LR=5.67e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 461 Train Time 45.624064445495605s

Training epoch 462, Batch 500/1000: LR=5.65e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 462, Batch 1000/1000: LR=5.65e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 462 Train Time 45.66894316673279s

Training epoch 463, Batch 500/1000: LR=5.64e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 463, Batch 1000/1000: LR=5.64e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 463 Train Time 45.73875880241394s

Training epoch 464, Batch 500/1000: LR=5.62e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 464, Batch 1000/1000: LR=5.62e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 464 Train Time 45.66196250915527s

Training epoch 465, Batch 500/1000: LR=5.61e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 465, Batch 1000/1000: LR=5.61e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 465 Train Time 45.661959409713745s

Training epoch 466, Batch 500/1000: LR=5.59e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 466, Batch 1000/1000: LR=5.59e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 466 Train Time 45.92226719856262s

Training epoch 467, Batch 500/1000: LR=5.58e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.14e-01
Training epoch 467, Batch 1000/1000: LR=5.58e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Epoch 467 Train Time 45.684903144836426s

Training epoch 468, Batch 500/1000: LR=5.56e-05, Loss=3.01e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 468, Batch 1000/1000: LR=5.56e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Epoch 468 Train Time 45.703850507736206s

Training epoch 469, Batch 500/1000: LR=5.55e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.13e-01
Training epoch 469, Batch 1000/1000: LR=5.55e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 469 Train Time 45.58018112182617s

Training epoch 470, Batch 500/1000: LR=5.53e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 470, Batch 1000/1000: LR=5.53e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 470 Train Time 45.768675565719604s

Training epoch 471, Batch 500/1000: LR=5.52e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 471, Batch 1000/1000: LR=5.52e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Epoch 471 Train Time 45.64702773094177s

Training epoch 472, Batch 500/1000: LR=5.50e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 472, Batch 1000/1000: LR=5.50e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 472 Train Time 44.93992257118225s

Training epoch 473, Batch 500/1000: LR=5.48e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 473, Batch 1000/1000: LR=5.48e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 473 Train Time 45.02965307235718s

Training epoch 474, Batch 500/1000: LR=5.47e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 474, Batch 1000/1000: LR=5.47e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 474 Train Time 45.21116781234741s

Training epoch 475, Batch 500/1000: LR=5.45e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 475, Batch 1000/1000: LR=5.45e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 475 Train Time 44.91695237159729s

Training epoch 476, Batch 500/1000: LR=5.44e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 476, Batch 1000/1000: LR=5.44e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 476 Train Time 44.96981120109558s

Training epoch 477, Batch 500/1000: LR=5.42e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 477, Batch 1000/1000: LR=5.42e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 477 Train Time 45.04162096977234s

Training epoch 478, Batch 500/1000: LR=5.41e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 478, Batch 1000/1000: LR=5.41e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 478 Train Time 44.89201092720032s

Training epoch 479, Batch 500/1000: LR=5.39e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 479, Batch 1000/1000: LR=5.39e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 479 Train Time 44.90897583961487s

Training epoch 480, Batch 500/1000: LR=5.38e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 480, Batch 1000/1000: LR=5.38e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 480 Train Time 44.97978639602661s

Training epoch 481, Batch 500/1000: LR=5.36e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 481, Batch 1000/1000: LR=5.36e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.13e-01
Epoch 481 Train Time 45.1563138961792s

Training epoch 482, Batch 500/1000: LR=5.35e-05, Loss=3.01e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 482, Batch 1000/1000: LR=5.35e-05, Loss=2.98e-02 BER=1.19e-02 FER=1.12e-01
Epoch 482 Train Time 45.03463912010193s

Training epoch 483, Batch 500/1000: LR=5.33e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 483, Batch 1000/1000: LR=5.33e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 483 Train Time 45.02167558670044s

Training epoch 484, Batch 500/1000: LR=5.31e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 484, Batch 1000/1000: LR=5.31e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 484 Train Time 45.09348273277283s

Training epoch 485, Batch 500/1000: LR=5.30e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 485, Batch 1000/1000: LR=5.30e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 485 Train Time 45.18324279785156s

Training epoch 486, Batch 500/1000: LR=5.28e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 486, Batch 1000/1000: LR=5.28e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 486 Train Time 66.44954943656921s

Training epoch 487, Batch 500/1000: LR=5.27e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 487, Batch 1000/1000: LR=5.27e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Epoch 487 Train Time 46.35610890388489s

Training epoch 488, Batch 500/1000: LR=5.25e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 488, Batch 1000/1000: LR=5.25e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 488 Train Time 45.97911500930786s

Training epoch 489, Batch 500/1000: LR=5.24e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 489, Batch 1000/1000: LR=5.24e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 489 Train Time 45.75671148300171s

Training epoch 490, Batch 500/1000: LR=5.22e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 490, Batch 1000/1000: LR=5.22e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 490 Train Time 45.52832007408142s

Training epoch 491, Batch 500/1000: LR=5.21e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.12e-01
Training epoch 491, Batch 1000/1000: LR=5.21e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 491 Train Time 45.76867938041687s

Training epoch 492, Batch 500/1000: LR=5.19e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 492, Batch 1000/1000: LR=5.19e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 492 Train Time 45.78762698173523s

Training epoch 493, Batch 500/1000: LR=5.17e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 493, Batch 1000/1000: LR=5.17e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 493 Train Time 45.73376393318176s

Training epoch 494, Batch 500/1000: LR=5.16e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 494, Batch 1000/1000: LR=5.16e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 494 Train Time 45.49640488624573s

Training epoch 495, Batch 500/1000: LR=5.14e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 495, Batch 1000/1000: LR=5.14e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 495 Train Time 45.59015488624573s

Training epoch 496, Batch 500/1000: LR=5.13e-05, Loss=3.05e-02 BER=1.25e-02 FER=1.15e-01
Training epoch 496, Batch 1000/1000: LR=5.13e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.13e-01
Epoch 496 Train Time 45.973132848739624s

Training epoch 497, Batch 500/1000: LR=5.11e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 497, Batch 1000/1000: LR=5.11e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 497 Train Time 45.74374318122864s

Training epoch 498, Batch 500/1000: LR=5.10e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 498, Batch 1000/1000: LR=5.10e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 498 Train Time 45.81256055831909s

Training epoch 499, Batch 500/1000: LR=5.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 499, Batch 1000/1000: LR=5.08e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 499 Train Time 45.7966251373291s

Training epoch 500, Batch 500/1000: LR=5.07e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 500, Batch 1000/1000: LR=5.07e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 500 Train Time 45.854448556900024s

Training epoch 501, Batch 500/1000: LR=5.05e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 501, Batch 1000/1000: LR=5.05e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 501 Train Time 45.54228448867798s

Training epoch 502, Batch 500/1000: LR=5.03e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 502, Batch 1000/1000: LR=5.03e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 502 Train Time 45.80358266830444s

Training epoch 503, Batch 500/1000: LR=5.02e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 503, Batch 1000/1000: LR=5.02e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 503 Train Time 45.93523359298706s

Training epoch 504, Batch 500/1000: LR=5.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 504, Batch 1000/1000: LR=5.00e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 504 Train Time 45.69587302207947s

Training epoch 505, Batch 500/1000: LR=4.99e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 505, Batch 1000/1000: LR=4.99e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 505 Train Time 45.67692470550537s

Training epoch 506, Batch 500/1000: LR=4.97e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 506, Batch 1000/1000: LR=4.97e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 506 Train Time 45.549261808395386s

Training epoch 507, Batch 500/1000: LR=4.96e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 507, Batch 1000/1000: LR=4.96e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 507 Train Time 45.735759973526s

Training epoch 508, Batch 500/1000: LR=4.94e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 508, Batch 1000/1000: LR=4.94e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 508 Train Time 45.97113656997681s

Training epoch 509, Batch 500/1000: LR=4.93e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 509, Batch 1000/1000: LR=4.93e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.11e-01
Epoch 509 Train Time 45.77266716957092s

Training epoch 510, Batch 500/1000: LR=4.91e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 510, Batch 1000/1000: LR=4.91e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 510 Train Time 46.004071950912476s

Training epoch 511, Batch 500/1000: LR=4.89e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 511, Batch 1000/1000: LR=4.89e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 511 Train Time 45.58117723464966s

Training epoch 512, Batch 500/1000: LR=4.88e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 512, Batch 1000/1000: LR=4.88e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 512 Train Time 45.69387698173523s

Training epoch 513, Batch 500/1000: LR=4.86e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 513, Batch 1000/1000: LR=4.86e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 513 Train Time 45.687894105911255s

Training epoch 514, Batch 500/1000: LR=4.85e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 514, Batch 1000/1000: LR=4.85e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 514 Train Time 45.180251121520996s

Training epoch 515, Batch 500/1000: LR=4.83e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 515, Batch 1000/1000: LR=4.83e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 515 Train Time 45.11542344093323s

Training epoch 516, Batch 500/1000: LR=4.82e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 516, Batch 1000/1000: LR=4.82e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 516 Train Time 45.185229539871216s

Training epoch 517, Batch 500/1000: LR=4.80e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 517, Batch 1000/1000: LR=4.80e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 517 Train Time 45.01770806312561s

Training epoch 518, Batch 500/1000: LR=4.79e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 518, Batch 1000/1000: LR=4.79e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 518 Train Time 45.07152533531189s

Training epoch 519, Batch 500/1000: LR=4.77e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 519, Batch 1000/1000: LR=4.77e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 519 Train Time 44.831183433532715s

Training epoch 520, Batch 500/1000: LR=4.75e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 520, Batch 1000/1000: LR=4.75e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 520 Train Time 45.065558195114136s

Training epoch 521, Batch 500/1000: LR=4.74e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 521, Batch 1000/1000: LR=4.74e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 521 Train Time 44.93789744377136s

Training epoch 522, Batch 500/1000: LR=4.72e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 522, Batch 1000/1000: LR=4.72e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 522 Train Time 44.99871253967285s

Training epoch 523, Batch 500/1000: LR=4.71e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 523, Batch 1000/1000: LR=4.71e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 523 Train Time 44.91196632385254s

Training epoch 524, Batch 500/1000: LR=4.69e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 524, Batch 1000/1000: LR=4.69e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 524 Train Time 45.05860447883606s

Training epoch 525, Batch 500/1000: LR=4.68e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 525, Batch 1000/1000: LR=4.68e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 525 Train Time 44.966835021972656s

Training epoch 526, Batch 500/1000: LR=4.66e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 526, Batch 1000/1000: LR=4.66e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 526 Train Time 65.49173188209534s

Training epoch 527, Batch 500/1000: LR=4.65e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 527, Batch 1000/1000: LR=4.65e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 527 Train Time 46.341148376464844s

Training epoch 528, Batch 500/1000: LR=4.63e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 528, Batch 1000/1000: LR=4.63e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 528 Train Time 45.263023853302s

Training epoch 529, Batch 500/1000: LR=4.62e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 529, Batch 1000/1000: LR=4.62e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Epoch 529 Train Time 45.01868271827698s

Training epoch 530, Batch 500/1000: LR=4.60e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 530, Batch 1000/1000: LR=4.60e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 530 Train Time 45.103456020355225s

Training epoch 531, Batch 500/1000: LR=4.58e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 531, Batch 1000/1000: LR=4.58e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 531 Train Time 44.77035045623779s

Training epoch 532, Batch 500/1000: LR=4.57e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 532, Batch 1000/1000: LR=4.57e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 532 Train Time 44.9857714176178s

Training epoch 533, Batch 500/1000: LR=4.55e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 533, Batch 1000/1000: LR=4.55e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 533 Train Time 45.09647512435913s

Training epoch 534, Batch 500/1000: LR=4.54e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 534, Batch 1000/1000: LR=4.54e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 534 Train Time 44.94288468360901s

Training epoch 535, Batch 500/1000: LR=4.52e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 535, Batch 1000/1000: LR=4.52e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 535 Train Time 44.9229416847229s

Training epoch 536, Batch 500/1000: LR=4.51e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 536, Batch 1000/1000: LR=4.51e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 536 Train Time 45.08251094818115s

Training epoch 537, Batch 500/1000: LR=4.49e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 537, Batch 1000/1000: LR=4.49e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 537 Train Time 45.05857610702515s

Training epoch 538, Batch 500/1000: LR=4.48e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 538, Batch 1000/1000: LR=4.48e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 538 Train Time 44.88703536987305s

Training epoch 539, Batch 500/1000: LR=4.46e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 539, Batch 1000/1000: LR=4.46e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 539 Train Time 44.96582341194153s

Training epoch 540, Batch 500/1000: LR=4.45e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 540, Batch 1000/1000: LR=4.45e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 540 Train Time 45.005717277526855s

Training epoch 541, Batch 500/1000: LR=4.43e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 541, Batch 1000/1000: LR=4.43e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 541 Train Time 44.9967405796051s

Training epoch 542, Batch 500/1000: LR=4.41e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 542, Batch 1000/1000: LR=4.41e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 542 Train Time 44.81921577453613s

Training epoch 543, Batch 500/1000: LR=4.40e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 543, Batch 1000/1000: LR=4.40e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 543 Train Time 45.10544395446777s

Training epoch 544, Batch 500/1000: LR=4.38e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 544, Batch 1000/1000: LR=4.38e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 544 Train Time 44.96083617210388s

Training epoch 545, Batch 500/1000: LR=4.37e-05, Loss=2.98e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 545, Batch 1000/1000: LR=4.37e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 545 Train Time 44.965824842453s

Training epoch 546, Batch 500/1000: LR=4.35e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 546, Batch 1000/1000: LR=4.35e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 546 Train Time 44.93490529060364s

Training epoch 547, Batch 500/1000: LR=4.34e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 547, Batch 1000/1000: LR=4.34e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 547 Train Time 44.97279596328735s

Training epoch 548, Batch 500/1000: LR=4.32e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 548, Batch 1000/1000: LR=4.32e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 548 Train Time 45.12838888168335s

Training epoch 549, Batch 500/1000: LR=4.31e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 549, Batch 1000/1000: LR=4.31e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 549 Train Time 45.158308267593384s

Training epoch 550, Batch 500/1000: LR=4.29e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 550, Batch 1000/1000: LR=4.29e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 550 Train Time 45.05059790611267s

Training epoch 551, Batch 500/1000: LR=4.28e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 551, Batch 1000/1000: LR=4.28e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 551 Train Time 45.00970673561096s

Training epoch 552, Batch 500/1000: LR=4.26e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 552, Batch 1000/1000: LR=4.26e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 552 Train Time 44.87107467651367s

Training epoch 553, Batch 500/1000: LR=4.24e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 553, Batch 1000/1000: LR=4.24e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 553 Train Time 44.93191432952881s

Training epoch 554, Batch 500/1000: LR=4.23e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 554, Batch 1000/1000: LR=4.23e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 554 Train Time 44.92792463302612s

Training epoch 555, Batch 500/1000: LR=4.21e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 555, Batch 1000/1000: LR=4.21e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 555 Train Time 45.09547543525696s

Training epoch 556, Batch 500/1000: LR=4.20e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 556, Batch 1000/1000: LR=4.20e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 556 Train Time 44.80727219581604s

Training epoch 557, Batch 500/1000: LR=4.18e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 557, Batch 1000/1000: LR=4.18e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 557 Train Time 45.07054424285889s

Training epoch 558, Batch 500/1000: LR=4.17e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 558, Batch 1000/1000: LR=4.17e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 558 Train Time 45.10245943069458s

Training epoch 559, Batch 500/1000: LR=4.15e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 559, Batch 1000/1000: LR=4.15e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 559 Train Time 45.08450508117676s

Training epoch 560, Batch 500/1000: LR=4.14e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 560, Batch 1000/1000: LR=4.14e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 560 Train Time 44.87307143211365s

Training epoch 561, Batch 500/1000: LR=4.12e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 561, Batch 1000/1000: LR=4.12e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 561 Train Time 44.82619524002075s

Training epoch 562, Batch 500/1000: LR=4.11e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 562, Batch 1000/1000: LR=4.11e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 562 Train Time 44.8551185131073s

Training epoch 563, Batch 500/1000: LR=4.09e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 563, Batch 1000/1000: LR=4.09e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 563 Train Time 44.95385503768921s

Training epoch 564, Batch 500/1000: LR=4.08e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 564, Batch 1000/1000: LR=4.08e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 564 Train Time 45.27898645401001s

Training epoch 565, Batch 500/1000: LR=4.06e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 565, Batch 1000/1000: LR=4.06e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 565 Train Time 44.55492043495178s

Training epoch 566, Batch 500/1000: LR=4.05e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 566, Batch 1000/1000: LR=4.05e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 566 Train Time 44.357449769973755s

Training epoch 567, Batch 500/1000: LR=4.03e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 567, Batch 1000/1000: LR=4.03e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 567 Train Time 67.27535080909729s

Training epoch 568, Batch 500/1000: LR=4.02e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 568, Batch 1000/1000: LR=4.02e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 568 Train Time 45.38570046424866s

Training epoch 569, Batch 500/1000: LR=4.00e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 569, Batch 1000/1000: LR=4.00e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 569 Train Time 45.10844159126282s

Training epoch 570, Batch 500/1000: LR=3.99e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 570, Batch 1000/1000: LR=3.99e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Epoch 570 Train Time 45.03962564468384s

Training epoch 571, Batch 500/1000: LR=3.97e-05, Loss=3.00e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 571, Batch 1000/1000: LR=3.97e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 571 Train Time 46.15763998031616s

Training epoch 572, Batch 500/1000: LR=3.96e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 572, Batch 1000/1000: LR=3.96e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 572 Train Time 47.035292625427246s

Training epoch 573, Batch 500/1000: LR=3.94e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 573, Batch 1000/1000: LR=3.94e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 573 Train Time 47.65563488006592s

Training epoch 574, Batch 500/1000: LR=3.92e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 574, Batch 1000/1000: LR=3.92e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 574 Train Time 48.999042987823486s

Training epoch 575, Batch 500/1000: LR=3.91e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 575, Batch 1000/1000: LR=3.91e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 575 Train Time 53.90094470977783s

Training epoch 576, Batch 500/1000: LR=3.89e-05, Loss=3.00e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 576, Batch 1000/1000: LR=3.89e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 576 Train Time 54.41158413887024s

Training epoch 577, Batch 500/1000: LR=3.88e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 577, Batch 1000/1000: LR=3.88e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 577 Train Time 53.92088794708252s

Training epoch 578, Batch 500/1000: LR=3.86e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 578, Batch 1000/1000: LR=3.86e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 578 Train Time 53.62667775154114s

Training epoch 579, Batch 500/1000: LR=3.85e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 579, Batch 1000/1000: LR=3.85e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 579 Train Time 53.916903018951416s

Training epoch 580, Batch 500/1000: LR=3.83e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 580, Batch 1000/1000: LR=3.83e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 580 Train Time 53.81417775154114s

Training epoch 581, Batch 500/1000: LR=3.82e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 581, Batch 1000/1000: LR=3.82e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 581 Train Time 54.26796102523804s

Training epoch 582, Batch 500/1000: LR=3.80e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 582, Batch 1000/1000: LR=3.80e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 582 Train Time 54.25300312042236s

Training epoch 583, Batch 500/1000: LR=3.79e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 583, Batch 1000/1000: LR=3.79e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 583 Train Time 54.34076738357544s

Training epoch 584, Batch 500/1000: LR=3.77e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 584, Batch 1000/1000: LR=3.77e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 584 Train Time 54.19416117668152s

Training epoch 585, Batch 500/1000: LR=3.76e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 585, Batch 1000/1000: LR=3.76e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 585 Train Time 54.14529347419739s

Training epoch 586, Batch 500/1000: LR=3.74e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 586, Batch 1000/1000: LR=3.74e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 586 Train Time 54.20413303375244s

Training epoch 587, Batch 500/1000: LR=3.73e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 587, Batch 1000/1000: LR=3.73e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 587 Train Time 57.900290966033936s

Training epoch 588, Batch 500/1000: LR=3.71e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 588, Batch 1000/1000: LR=3.71e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 588 Train Time 54.055529832839966s

Training epoch 589, Batch 500/1000: LR=3.70e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 589, Batch 1000/1000: LR=3.70e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 589 Train Time 54.17522311210632s

Training epoch 590, Batch 500/1000: LR=3.68e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 590, Batch 1000/1000: LR=3.68e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 590 Train Time 54.14728569984436s

Training epoch 591, Batch 500/1000: LR=3.67e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 591, Batch 1000/1000: LR=3.67e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 591 Train Time 54.47939658164978s

Training epoch 592, Batch 500/1000: LR=3.65e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 592, Batch 1000/1000: LR=3.65e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 592 Train Time 54.3088538646698s

Training epoch 593, Batch 500/1000: LR=3.64e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 593, Batch 1000/1000: LR=3.64e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 593 Train Time 54.52527475357056s

Training epoch 594, Batch 500/1000: LR=3.62e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 594, Batch 1000/1000: LR=3.62e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Epoch 594 Train Time 54.5272696018219s

Training epoch 595, Batch 500/1000: LR=3.61e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 595, Batch 1000/1000: LR=3.61e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 595 Train Time 54.434489488601685s

Training epoch 596, Batch 500/1000: LR=3.59e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 596, Batch 1000/1000: LR=3.59e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 596 Train Time 54.108389139175415s

Training epoch 597, Batch 500/1000: LR=3.58e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 597, Batch 1000/1000: LR=3.58e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 597 Train Time 53.645625829696655s

Training epoch 598, Batch 500/1000: LR=3.56e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 598, Batch 1000/1000: LR=3.56e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 598 Train Time 53.39928483963013s

Training epoch 599, Batch 500/1000: LR=3.55e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 599, Batch 1000/1000: LR=3.55e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 599 Train Time 53.041242361068726s

Training epoch 600, Batch 500/1000: LR=3.54e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 600, Batch 1000/1000: LR=3.54e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 600 Train Time 52.473756551742554s


Test Loss 1: 2.28e-01 2: 1.18e-01 3: 4.30e-02
Test FER 1: 6.71e-01 2: 4.10e-01 3: 1.74e-01
Test BER 1: 9.44e-02 2: 4.87e-02 3: 1.72e-02
Test -ln(BER) 1: 2.36e+00 2: 3.02e+00 3: 4.06e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 74.1957015991211 s

Training epoch 601, Batch 500/1000: LR=3.52e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 601, Batch 1000/1000: LR=3.52e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 601 Train Time 52.53060579299927s

Training epoch 602, Batch 500/1000: LR=3.51e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 602, Batch 1000/1000: LR=3.51e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 602 Train Time 52.45580720901489s

Training epoch 603, Batch 500/1000: LR=3.49e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 603, Batch 1000/1000: LR=3.49e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 603 Train Time 52.70314288139343s

Training epoch 604, Batch 500/1000: LR=3.48e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 604, Batch 1000/1000: LR=3.48e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 604 Train Time 52.496697664260864s

Training epoch 605, Batch 500/1000: LR=3.46e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 605, Batch 1000/1000: LR=3.46e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 605 Train Time 52.53958249092102s

Training epoch 606, Batch 500/1000: LR=3.45e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 606, Batch 1000/1000: LR=3.45e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 606 Train Time 52.503700733184814s

Training epoch 607, Batch 500/1000: LR=3.43e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 607, Batch 1000/1000: LR=3.43e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 607 Train Time 52.29024791717529s

Training epoch 608, Batch 500/1000: LR=3.42e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 608, Batch 1000/1000: LR=3.42e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Epoch 608 Train Time 52.71610927581787s

Training epoch 609, Batch 500/1000: LR=3.40e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 609, Batch 1000/1000: LR=3.40e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Epoch 609 Train Time 52.462788105010986s

Training epoch 610, Batch 500/1000: LR=3.39e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 610, Batch 1000/1000: LR=3.39e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 610 Train Time 52.83180212974548s

Training epoch 611, Batch 500/1000: LR=3.37e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 611, Batch 1000/1000: LR=3.37e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 611 Train Time 52.61837029457092s

Training epoch 612, Batch 500/1000: LR=3.36e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 612, Batch 1000/1000: LR=3.36e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 612 Train Time 53.35340619087219s

Training epoch 613, Batch 500/1000: LR=3.34e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 613, Batch 1000/1000: LR=3.34e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 613 Train Time 54.71676325798035s

Training epoch 614, Batch 500/1000: LR=3.33e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 614, Batch 1000/1000: LR=3.33e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 614 Train Time 53.94682168960571s

Training epoch 615, Batch 500/1000: LR=3.31e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 615, Batch 1000/1000: LR=3.31e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 615 Train Time 53.72142171859741s

Training epoch 616, Batch 500/1000: LR=3.30e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 616, Batch 1000/1000: LR=3.30e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 616 Train Time 54.15127444267273s

Training epoch 617, Batch 500/1000: LR=3.29e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 617, Batch 1000/1000: LR=3.29e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 617 Train Time 53.75433611869812s

Training epoch 618, Batch 500/1000: LR=3.27e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 618, Batch 1000/1000: LR=3.27e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 618 Train Time 54.15626072883606s

Training epoch 619, Batch 500/1000: LR=3.26e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 619, Batch 1000/1000: LR=3.26e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 619 Train Time 54.207643270492554s

Training epoch 620, Batch 500/1000: LR=3.24e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 620, Batch 1000/1000: LR=3.24e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 620 Train Time 48.05109167098999s

Training epoch 621, Batch 500/1000: LR=3.23e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 621, Batch 1000/1000: LR=3.23e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 621 Train Time 47.78451943397522s

Training epoch 622, Batch 500/1000: LR=3.21e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 622, Batch 1000/1000: LR=3.21e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 622 Train Time 58.115679025650024s

Training epoch 623, Batch 500/1000: LR=3.20e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 623, Batch 1000/1000: LR=3.20e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 623 Train Time 65.18877601623535s

Training epoch 624, Batch 500/1000: LR=3.18e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 624, Batch 1000/1000: LR=3.18e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 624 Train Time 45.64700412750244s

Training epoch 625, Batch 500/1000: LR=3.17e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 625, Batch 1000/1000: LR=3.17e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 625 Train Time 45.0775260925293s

Training epoch 626, Batch 500/1000: LR=3.16e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 626, Batch 1000/1000: LR=3.16e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 626 Train Time 60.18115782737732s

Training epoch 627, Batch 500/1000: LR=3.14e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 627, Batch 1000/1000: LR=3.14e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 627 Train Time 67.52253842353821s

Training epoch 628, Batch 500/1000: LR=3.13e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 628, Batch 1000/1000: LR=3.13e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 628 Train Time 45.18523931503296s

Training epoch 629, Batch 500/1000: LR=3.11e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 629, Batch 1000/1000: LR=3.11e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 629 Train Time 44.90700316429138s

Training epoch 630, Batch 500/1000: LR=3.10e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 630, Batch 1000/1000: LR=3.10e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 630 Train Time 45.05059790611267s

Training epoch 631, Batch 500/1000: LR=3.08e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 631, Batch 1000/1000: LR=3.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 631 Train Time 45.09148812294006s

Training epoch 632, Batch 500/1000: LR=3.07e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 632, Batch 1000/1000: LR=3.07e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 632 Train Time 45.09051299095154s

Training epoch 633, Batch 500/1000: LR=3.06e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 633, Batch 1000/1000: LR=3.06e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 633 Train Time 44.975789308547974s

Training epoch 634, Batch 500/1000: LR=3.04e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 634, Batch 1000/1000: LR=3.04e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 634 Train Time 44.86908316612244s

Training epoch 635, Batch 500/1000: LR=3.03e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 635, Batch 1000/1000: LR=3.03e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 635 Train Time 44.92094326019287s

Training epoch 636, Batch 500/1000: LR=3.01e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 636, Batch 1000/1000: LR=3.01e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 636 Train Time 44.799267292022705s

Training epoch 637, Batch 500/1000: LR=3.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 637, Batch 1000/1000: LR=3.00e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 637 Train Time 45.00472044944763s

Training epoch 638, Batch 500/1000: LR=2.98e-05, Loss=3.00e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 638, Batch 1000/1000: LR=2.98e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 638 Train Time 44.95485472679138s

Training epoch 639, Batch 500/1000: LR=2.97e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 639, Batch 1000/1000: LR=2.97e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 639 Train Time 45.098490476608276s

Training epoch 640, Batch 500/1000: LR=2.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 640, Batch 1000/1000: LR=2.96e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 640 Train Time 44.86409664154053s

Training epoch 641, Batch 500/1000: LR=2.94e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 641, Batch 1000/1000: LR=2.94e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 641 Train Time 44.618749141693115s

Training epoch 642, Batch 500/1000: LR=2.93e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 642, Batch 1000/1000: LR=2.93e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 642 Train Time 44.74740719795227s

Training epoch 643, Batch 500/1000: LR=2.91e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 643, Batch 1000/1000: LR=2.91e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 643 Train Time 44.9977388381958s

Training epoch 644, Batch 500/1000: LR=2.90e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 644, Batch 1000/1000: LR=2.90e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 644 Train Time 44.78630471229553s

Training epoch 645, Batch 500/1000: LR=2.89e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 645, Batch 1000/1000: LR=2.89e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 645 Train Time 44.824223279953s

Training epoch 646, Batch 500/1000: LR=2.87e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 646, Batch 1000/1000: LR=2.87e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 646 Train Time 44.73843193054199s

Training epoch 647, Batch 500/1000: LR=2.86e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 647, Batch 1000/1000: LR=2.86e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 647 Train Time 44.92592811584473s

Training epoch 648, Batch 500/1000: LR=2.84e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 648, Batch 1000/1000: LR=2.84e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 648 Train Time 44.80226159095764s

Training epoch 649, Batch 500/1000: LR=2.83e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 649, Batch 1000/1000: LR=2.83e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 649 Train Time 44.74341678619385s

Training epoch 650, Batch 500/1000: LR=2.82e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 650, Batch 1000/1000: LR=2.82e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 650 Train Time 44.75448560714722s

Training epoch 651, Batch 500/1000: LR=2.80e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 651, Batch 1000/1000: LR=2.80e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 651 Train Time 44.67060947418213s

Training epoch 652, Batch 500/1000: LR=2.79e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 652, Batch 1000/1000: LR=2.79e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Epoch 652 Train Time 44.74441599845886s

Training epoch 653, Batch 500/1000: LR=2.78e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 653, Batch 1000/1000: LR=2.78e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 653 Train Time 44.68457651138306s

Training epoch 654, Batch 500/1000: LR=2.76e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 654, Batch 1000/1000: LR=2.76e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 654 Train Time 44.70651865005493s

Training epoch 655, Batch 500/1000: LR=2.75e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 655, Batch 1000/1000: LR=2.75e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 655 Train Time 44.791290521621704s

Training epoch 656, Batch 500/1000: LR=2.73e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 656, Batch 1000/1000: LR=2.73e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 656 Train Time 44.6446807384491s

Training epoch 657, Batch 500/1000: LR=2.72e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 657, Batch 1000/1000: LR=2.72e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 657 Train Time 44.84514546394348s

Training epoch 658, Batch 500/1000: LR=2.71e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 658, Batch 1000/1000: LR=2.71e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 658 Train Time 44.97380328178406s

Training epoch 659, Batch 500/1000: LR=2.69e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 659, Batch 1000/1000: LR=2.69e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 659 Train Time 44.73244643211365s

Training epoch 660, Batch 500/1000: LR=2.68e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 660, Batch 1000/1000: LR=2.68e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 660 Train Time 44.8132221698761s

Training epoch 661, Batch 500/1000: LR=2.67e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 661, Batch 1000/1000: LR=2.67e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 661 Train Time 44.737433671951294s

Training epoch 662, Batch 500/1000: LR=2.65e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 662, Batch 1000/1000: LR=2.65e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 662 Train Time 44.8341760635376s

Training epoch 663, Batch 500/1000: LR=2.64e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 663, Batch 1000/1000: LR=2.64e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 663 Train Time 44.87207293510437s

Training epoch 664, Batch 500/1000: LR=2.62e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 664, Batch 1000/1000: LR=2.62e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Epoch 664 Train Time 45.882373571395874s

Training epoch 665, Batch 500/1000: LR=2.61e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 665, Batch 1000/1000: LR=2.61e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 665 Train Time 45.57419776916504s

Training epoch 666, Batch 500/1000: LR=2.60e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 666, Batch 1000/1000: LR=2.60e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 666 Train Time 45.59613800048828s

Training epoch 667, Batch 500/1000: LR=2.58e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 667, Batch 1000/1000: LR=2.58e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 667 Train Time 46.4255051612854s

Training epoch 668, Batch 500/1000: LR=2.57e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 668, Batch 1000/1000: LR=2.57e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 668 Train Time 39.33470869064331s

Training epoch 669, Batch 500/1000: LR=2.56e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 669, Batch 1000/1000: LR=2.56e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 669 Train Time 39.27804160118103s

Training epoch 670, Batch 500/1000: LR=2.54e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 670, Batch 1000/1000: LR=2.54e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 670 Train Time 39.103997468948364s

Training epoch 671, Batch 500/1000: LR=2.53e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 671, Batch 1000/1000: LR=2.53e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 671 Train Time 39.1257266998291s

Training epoch 672, Batch 500/1000: LR=2.52e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 672, Batch 1000/1000: LR=2.52e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 672 Train Time 39.11917734146118s

Training epoch 673, Batch 500/1000: LR=2.50e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 673, Batch 1000/1000: LR=2.50e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 673 Train Time 39.13450074195862s

Training epoch 674, Batch 500/1000: LR=2.49e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 674, Batch 1000/1000: LR=2.49e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 674 Train Time 39.284579038619995s

Training epoch 675, Batch 500/1000: LR=2.48e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 675, Batch 1000/1000: LR=2.48e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 675 Train Time 40.88330626487732s

Training epoch 676, Batch 500/1000: LR=2.46e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 676, Batch 1000/1000: LR=2.46e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 676 Train Time 41.50543761253357s

Training epoch 677, Batch 500/1000: LR=2.45e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 677, Batch 1000/1000: LR=2.45e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 677 Train Time 39.31202268600464s

Training epoch 678, Batch 500/1000: LR=2.44e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 678, Batch 1000/1000: LR=2.44e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 678 Train Time 39.13938355445862s

Training epoch 679, Batch 500/1000: LR=2.42e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 679, Batch 1000/1000: LR=2.42e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 679 Train Time 39.133159160614014s

Training epoch 680, Batch 500/1000: LR=2.41e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 680, Batch 1000/1000: LR=2.41e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 680 Train Time 39.09022331237793s

Training epoch 681, Batch 500/1000: LR=2.40e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 681, Batch 1000/1000: LR=2.40e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 681 Train Time 39.09435772895813s

Training epoch 682, Batch 500/1000: LR=2.38e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 682, Batch 1000/1000: LR=2.38e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 682 Train Time 39.224398612976074s

Training epoch 683, Batch 500/1000: LR=2.37e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 683, Batch 1000/1000: LR=2.37e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 683 Train Time 39.11032295227051s

Training epoch 684, Batch 500/1000: LR=2.36e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 684, Batch 1000/1000: LR=2.36e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 684 Train Time 39.167632818222046s

Training epoch 685, Batch 500/1000: LR=2.35e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 685, Batch 1000/1000: LR=2.35e-05, Loss=2.90e-02 BER=1.16e-02 FER=1.09e-01
Epoch 685 Train Time 39.08965706825256s

Training epoch 686, Batch 500/1000: LR=2.33e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 686, Batch 1000/1000: LR=2.33e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 686 Train Time 39.10955262184143s

Training epoch 687, Batch 500/1000: LR=2.32e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 687, Batch 1000/1000: LR=2.32e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 687 Train Time 39.12174367904663s

Training epoch 688, Batch 500/1000: LR=2.31e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 688, Batch 1000/1000: LR=2.31e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 688 Train Time 39.088414430618286s

Training epoch 689, Batch 500/1000: LR=2.29e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 689, Batch 1000/1000: LR=2.29e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 689 Train Time 39.08172535896301s

Training epoch 690, Batch 500/1000: LR=2.28e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 690, Batch 1000/1000: LR=2.28e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 690 Train Time 39.12713003158569s

Training epoch 691, Batch 500/1000: LR=2.27e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 691, Batch 1000/1000: LR=2.27e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 691 Train Time 39.36643695831299s

Training epoch 692, Batch 500/1000: LR=2.25e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 692, Batch 1000/1000: LR=2.25e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 692 Train Time 39.10019016265869s

Training epoch 693, Batch 500/1000: LR=2.24e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 693, Batch 1000/1000: LR=2.24e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 693 Train Time 39.101829528808594s

Training epoch 694, Batch 500/1000: LR=2.23e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 694, Batch 1000/1000: LR=2.23e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 694 Train Time 39.08451008796692s

Training epoch 695, Batch 500/1000: LR=2.22e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 695, Batch 1000/1000: LR=2.22e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 695 Train Time 39.08357119560242s

Training epoch 696, Batch 500/1000: LR=2.20e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 696, Batch 1000/1000: LR=2.20e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 696 Train Time 39.10437560081482s

Training epoch 697, Batch 500/1000: LR=2.19e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 697, Batch 1000/1000: LR=2.19e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 697 Train Time 39.07646608352661s

Training epoch 698, Batch 500/1000: LR=2.18e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 698, Batch 1000/1000: LR=2.18e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 698 Train Time 39.1163866519928s

Training epoch 699, Batch 500/1000: LR=2.17e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 699, Batch 1000/1000: LR=2.17e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 699 Train Time 39.11349034309387s

Training epoch 700, Batch 500/1000: LR=2.15e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 700, Batch 1000/1000: LR=2.15e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 700 Train Time 39.13343381881714s

Training epoch 701, Batch 500/1000: LR=2.14e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 701, Batch 1000/1000: LR=2.14e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 701 Train Time 39.099671840667725s

Training epoch 702, Batch 500/1000: LR=2.13e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 702, Batch 1000/1000: LR=2.13e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 702 Train Time 39.111676931381226s

Training epoch 703, Batch 500/1000: LR=2.12e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 703, Batch 1000/1000: LR=2.12e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 703 Train Time 39.12988090515137s

Training epoch 704, Batch 500/1000: LR=2.10e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 704, Batch 1000/1000: LR=2.10e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 704 Train Time 39.13796067237854s

Training epoch 705, Batch 500/1000: LR=2.09e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 705, Batch 1000/1000: LR=2.09e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 705 Train Time 39.20327019691467s

Training epoch 706, Batch 500/1000: LR=2.08e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 706, Batch 1000/1000: LR=2.08e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Epoch 706 Train Time 39.09001874923706s

Training epoch 707, Batch 500/1000: LR=2.07e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 707, Batch 1000/1000: LR=2.07e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 707 Train Time 39.10124063491821s

Training epoch 708, Batch 500/1000: LR=2.05e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 708, Batch 1000/1000: LR=2.05e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 708 Train Time 39.14163160324097s

Training epoch 709, Batch 500/1000: LR=2.04e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 709, Batch 1000/1000: LR=2.04e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 709 Train Time 39.13931632041931s

Training epoch 710, Batch 500/1000: LR=2.03e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 710, Batch 1000/1000: LR=2.03e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 710 Train Time 39.10703134536743s

Training epoch 711, Batch 500/1000: LR=2.02e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 711, Batch 1000/1000: LR=2.02e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 711 Train Time 39.10758185386658s

Training epoch 712, Batch 500/1000: LR=2.00e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 712, Batch 1000/1000: LR=2.00e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 712 Train Time 39.09487962722778s

Training epoch 713, Batch 500/1000: LR=1.99e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 713, Batch 1000/1000: LR=1.99e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 713 Train Time 39.11271023750305s

Training epoch 714, Batch 500/1000: LR=1.98e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 714, Batch 1000/1000: LR=1.98e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 714 Train Time 39.20905518531799s

Training epoch 715, Batch 500/1000: LR=1.97e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 715, Batch 1000/1000: LR=1.97e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 715 Train Time 70.08632516860962s

Training epoch 716, Batch 500/1000: LR=1.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 716, Batch 1000/1000: LR=1.96e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 716 Train Time 39.77036476135254s

Training epoch 717, Batch 500/1000: LR=1.94e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 717, Batch 1000/1000: LR=1.94e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 717 Train Time 39.48559546470642s

Training epoch 718, Batch 500/1000: LR=1.93e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.10e-01
Training epoch 718, Batch 1000/1000: LR=1.93e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 718 Train Time 39.321592807769775s

Training epoch 719, Batch 500/1000: LR=1.92e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 719, Batch 1000/1000: LR=1.92e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 719 Train Time 39.29240965843201s

Training epoch 720, Batch 500/1000: LR=1.91e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 720, Batch 1000/1000: LR=1.91e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 720 Train Time 39.31648349761963s

Training epoch 721, Batch 500/1000: LR=1.89e-05, Loss=2.90e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 721, Batch 1000/1000: LR=1.89e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 721 Train Time 39.2791953086853s

Training epoch 722, Batch 500/1000: LR=1.88e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 722, Batch 1000/1000: LR=1.88e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 722 Train Time 39.49215078353882s

Training epoch 723, Batch 500/1000: LR=1.87e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 723, Batch 1000/1000: LR=1.87e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 723 Train Time 39.318713426589966s

Training epoch 724, Batch 500/1000: LR=1.86e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 724, Batch 1000/1000: LR=1.86e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 724 Train Time 39.30621695518494s

Training epoch 725, Batch 500/1000: LR=1.85e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 725, Batch 1000/1000: LR=1.85e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 725 Train Time 39.55996227264404s

Training epoch 726, Batch 500/1000: LR=1.84e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 726, Batch 1000/1000: LR=1.84e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 726 Train Time 39.33800435066223s

Training epoch 727, Batch 500/1000: LR=1.82e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 727, Batch 1000/1000: LR=1.82e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 727 Train Time 39.28312659263611s

Training epoch 728, Batch 500/1000: LR=1.81e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 728, Batch 1000/1000: LR=1.81e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 728 Train Time 39.294259786605835s

Training epoch 729, Batch 500/1000: LR=1.80e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 729, Batch 1000/1000: LR=1.80e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 729 Train Time 39.30750274658203s

Training epoch 730, Batch 500/1000: LR=1.79e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 730, Batch 1000/1000: LR=1.79e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 730 Train Time 39.3425087928772s

Training epoch 731, Batch 500/1000: LR=1.78e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 731, Batch 1000/1000: LR=1.78e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 731 Train Time 39.44265341758728s

Training epoch 732, Batch 500/1000: LR=1.76e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 732, Batch 1000/1000: LR=1.76e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 732 Train Time 39.327707052230835s

Training epoch 733, Batch 500/1000: LR=1.75e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 733, Batch 1000/1000: LR=1.75e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Epoch 733 Train Time 39.30427885055542s

Training epoch 734, Batch 500/1000: LR=1.74e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 734, Batch 1000/1000: LR=1.74e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 734 Train Time 39.385411500930786s

Training epoch 735, Batch 500/1000: LR=1.73e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 735, Batch 1000/1000: LR=1.73e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 735 Train Time 39.298317670822144s

Training epoch 736, Batch 500/1000: LR=1.72e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 736, Batch 1000/1000: LR=1.72e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 736 Train Time 39.29969358444214s

Training epoch 737, Batch 500/1000: LR=1.71e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 737, Batch 1000/1000: LR=1.71e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 737 Train Time 39.32059407234192s

Training epoch 738, Batch 500/1000: LR=1.70e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 738, Batch 1000/1000: LR=1.70e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 738 Train Time 39.295119524002075s

Training epoch 739, Batch 500/1000: LR=1.68e-05, Loss=2.95e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 739, Batch 1000/1000: LR=1.68e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 739 Train Time 39.269861698150635s

Training epoch 740, Batch 500/1000: LR=1.67e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 740, Batch 1000/1000: LR=1.67e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Epoch 740 Train Time 39.266024112701416s

Training epoch 741, Batch 500/1000: LR=1.66e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 741, Batch 1000/1000: LR=1.66e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 741 Train Time 39.33104419708252s

Training epoch 742, Batch 500/1000: LR=1.65e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 742, Batch 1000/1000: LR=1.65e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 742 Train Time 39.299705266952515s

Training epoch 743, Batch 500/1000: LR=1.64e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 743, Batch 1000/1000: LR=1.64e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 743 Train Time 39.453933000564575s

Training epoch 744, Batch 500/1000: LR=1.63e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 744, Batch 1000/1000: LR=1.63e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.10e-01
Epoch 744 Train Time 39.30406975746155s

Training epoch 745, Batch 500/1000: LR=1.62e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 745, Batch 1000/1000: LR=1.62e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 745 Train Time 39.27563834190369s

Training epoch 746, Batch 500/1000: LR=1.61e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 746, Batch 1000/1000: LR=1.61e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 746 Train Time 39.289419174194336s

Training epoch 747, Batch 500/1000: LR=1.59e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 747, Batch 1000/1000: LR=1.59e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 747 Train Time 39.33071517944336s

Training epoch 748, Batch 500/1000: LR=1.58e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 748, Batch 1000/1000: LR=1.58e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 748 Train Time 39.305638551712036s

Training epoch 749, Batch 500/1000: LR=1.57e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 749, Batch 1000/1000: LR=1.57e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 749 Train Time 39.29548192024231s

Training epoch 750, Batch 500/1000: LR=1.56e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 750, Batch 1000/1000: LR=1.56e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 750 Train Time 39.30817627906799s

Training epoch 751, Batch 500/1000: LR=1.55e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 751, Batch 1000/1000: LR=1.55e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 751 Train Time 39.45540118217468s

Training epoch 752, Batch 500/1000: LR=1.54e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 752, Batch 1000/1000: LR=1.54e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 752 Train Time 39.29617977142334s

Training epoch 753, Batch 500/1000: LR=1.53e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 753, Batch 1000/1000: LR=1.53e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Epoch 753 Train Time 39.29130148887634s

Training epoch 754, Batch 500/1000: LR=1.52e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 754, Batch 1000/1000: LR=1.52e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 754 Train Time 39.33912634849548s

Training epoch 755, Batch 500/1000: LR=1.51e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 755, Batch 1000/1000: LR=1.51e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 755 Train Time 39.28558921813965s

Training epoch 756, Batch 500/1000: LR=1.50e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 756, Batch 1000/1000: LR=1.50e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 756 Train Time 39.28382682800293s

Training epoch 757, Batch 500/1000: LR=1.48e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 757, Batch 1000/1000: LR=1.48e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 757 Train Time 39.29115867614746s

Training epoch 758, Batch 500/1000: LR=1.47e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 758, Batch 1000/1000: LR=1.47e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Epoch 758 Train Time 39.27750849723816s

Training epoch 759, Batch 500/1000: LR=1.46e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 759, Batch 1000/1000: LR=1.46e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 759 Train Time 39.0709023475647s

Training epoch 760, Batch 500/1000: LR=1.45e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 760, Batch 1000/1000: LR=1.45e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 760 Train Time 38.90376925468445s

Training epoch 761, Batch 500/1000: LR=1.44e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 761, Batch 1000/1000: LR=1.44e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 761 Train Time 38.88065981864929s

Training epoch 762, Batch 500/1000: LR=1.43e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 762, Batch 1000/1000: LR=1.43e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 762 Train Time 141.54596090316772s

Training epoch 763, Batch 500/1000: LR=1.42e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 763, Batch 1000/1000: LR=1.42e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 763 Train Time 39.03827214241028s

Training epoch 764, Batch 500/1000: LR=1.41e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 764, Batch 1000/1000: LR=1.41e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 764 Train Time 38.90373158454895s

Training epoch 765, Batch 500/1000: LR=1.40e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 765, Batch 1000/1000: LR=1.40e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 765 Train Time 38.87587285041809s

Training epoch 766, Batch 500/1000: LR=1.39e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 766, Batch 1000/1000: LR=1.39e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 766 Train Time 38.88370656967163s

Training epoch 767, Batch 500/1000: LR=1.38e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 767, Batch 1000/1000: LR=1.38e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 767 Train Time 38.87504839897156s

Training epoch 768, Batch 500/1000: LR=1.37e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 768, Batch 1000/1000: LR=1.37e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 768 Train Time 38.88433337211609s

Training epoch 769, Batch 500/1000: LR=1.36e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 769, Batch 1000/1000: LR=1.36e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 769 Train Time 38.897674322128296s

Training epoch 770, Batch 500/1000: LR=1.35e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 770, Batch 1000/1000: LR=1.35e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 770 Train Time 38.88510847091675s

Training epoch 771, Batch 500/1000: LR=1.34e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 771, Batch 1000/1000: LR=1.34e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 771 Train Time 38.866204500198364s

Training epoch 772, Batch 500/1000: LR=1.33e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 772, Batch 1000/1000: LR=1.33e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 772 Train Time 38.88652753829956s

Training epoch 773, Batch 500/1000: LR=1.32e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 773, Batch 1000/1000: LR=1.32e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 773 Train Time 39.01381492614746s

Training epoch 774, Batch 500/1000: LR=1.31e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 774, Batch 1000/1000: LR=1.31e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 774 Train Time 38.864574670791626s

Training epoch 775, Batch 500/1000: LR=1.30e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 775, Batch 1000/1000: LR=1.30e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 775 Train Time 38.90420413017273s

Training epoch 776, Batch 500/1000: LR=1.29e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 776, Batch 1000/1000: LR=1.29e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 776 Train Time 38.88512706756592s

Training epoch 777, Batch 500/1000: LR=1.28e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 777, Batch 1000/1000: LR=1.28e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 777 Train Time 38.878743410110474s

Training epoch 778, Batch 500/1000: LR=1.27e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 778, Batch 1000/1000: LR=1.27e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 778 Train Time 38.93642544746399s

Training epoch 779, Batch 500/1000: LR=1.26e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 779, Batch 1000/1000: LR=1.26e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 779 Train Time 38.90229105949402s

Training epoch 780, Batch 500/1000: LR=1.25e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 780, Batch 1000/1000: LR=1.25e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 780 Train Time 38.87552881240845s

Training epoch 781, Batch 500/1000: LR=1.24e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 781, Batch 1000/1000: LR=1.24e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 781 Train Time 38.866131067276s

Training epoch 782, Batch 500/1000: LR=1.23e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 782, Batch 1000/1000: LR=1.23e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 782 Train Time 38.92592263221741s

Training epoch 783, Batch 500/1000: LR=1.22e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 783, Batch 1000/1000: LR=1.22e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 783 Train Time 38.946409463882446s

Training epoch 784, Batch 500/1000: LR=1.21e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 784, Batch 1000/1000: LR=1.21e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 784 Train Time 38.87174201011658s

Training epoch 785, Batch 500/1000: LR=1.20e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 785, Batch 1000/1000: LR=1.20e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 785 Train Time 38.87748885154724s

Training epoch 786, Batch 500/1000: LR=1.19e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 786, Batch 1000/1000: LR=1.19e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 786 Train Time 38.87374806404114s

Training epoch 787, Batch 500/1000: LR=1.18e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 787, Batch 1000/1000: LR=1.18e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 787 Train Time 38.88563585281372s

Training epoch 788, Batch 500/1000: LR=1.17e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 788, Batch 1000/1000: LR=1.17e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 788 Train Time 38.8567419052124s

Training epoch 789, Batch 500/1000: LR=1.16e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.06e-01
Training epoch 789, Batch 1000/1000: LR=1.16e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 789 Train Time 38.87651515007019s

Training epoch 790, Batch 500/1000: LR=1.15e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 790, Batch 1000/1000: LR=1.15e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 790 Train Time 38.90201187133789s

Training epoch 791, Batch 500/1000: LR=1.14e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 791, Batch 1000/1000: LR=1.14e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 791 Train Time 38.91665172576904s

Training epoch 792, Batch 500/1000: LR=1.13e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 792, Batch 1000/1000: LR=1.13e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 792 Train Time 39.02591633796692s

Training epoch 793, Batch 500/1000: LR=1.12e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 793, Batch 1000/1000: LR=1.12e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 793 Train Time 38.891825437545776s

Training epoch 794, Batch 500/1000: LR=1.11e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 794, Batch 1000/1000: LR=1.11e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 794 Train Time 38.885194063186646s

Training epoch 795, Batch 500/1000: LR=1.10e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 795, Batch 1000/1000: LR=1.10e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 795 Train Time 38.86909079551697s

Training epoch 796, Batch 500/1000: LR=1.09e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 796, Batch 1000/1000: LR=1.09e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 796 Train Time 38.878403425216675s

Training epoch 797, Batch 500/1000: LR=1.08e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 797, Batch 1000/1000: LR=1.08e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 797 Train Time 38.888834714889526s

Training epoch 798, Batch 500/1000: LR=1.07e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 798, Batch 1000/1000: LR=1.07e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 798 Train Time 38.891223430633545s

Training epoch 799, Batch 500/1000: LR=1.06e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 799, Batch 1000/1000: LR=1.06e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 799 Train Time 38.913665771484375s

Training epoch 800, Batch 500/1000: LR=1.05e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 800, Batch 1000/1000: LR=1.05e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 800 Train Time 38.88053321838379s

Training epoch 801, Batch 500/1000: LR=1.05e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 801, Batch 1000/1000: LR=1.05e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 801 Train Time 38.98316049575806s

Training epoch 802, Batch 500/1000: LR=1.04e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 802, Batch 1000/1000: LR=1.04e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 802 Train Time 38.89227890968323s

Training epoch 803, Batch 500/1000: LR=1.03e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 803, Batch 1000/1000: LR=1.03e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 803 Train Time 38.87005543708801s

Training epoch 804, Batch 500/1000: LR=1.02e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 804, Batch 1000/1000: LR=1.02e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 804 Train Time 38.870940923690796s

Training epoch 805, Batch 500/1000: LR=1.01e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 805, Batch 1000/1000: LR=1.01e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 805 Train Time 39.10209679603577s

Training epoch 806, Batch 500/1000: LR=1.00e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 806, Batch 1000/1000: LR=1.00e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 806 Train Time 38.93092489242554s

Training epoch 807, Batch 500/1000: LR=9.91e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 807, Batch 1000/1000: LR=9.91e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 807 Train Time 38.899949073791504s

Training epoch 808, Batch 500/1000: LR=9.82e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 808, Batch 1000/1000: LR=9.82e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 808 Train Time 38.88879179954529s

Training epoch 809, Batch 500/1000: LR=9.74e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 809, Batch 1000/1000: LR=9.74e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 809 Train Time 59.4656777381897s

Training epoch 810, Batch 500/1000: LR=9.65e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 810, Batch 1000/1000: LR=9.65e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 810 Train Time 39.387969732284546s

Training epoch 811, Batch 500/1000: LR=9.56e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 811, Batch 1000/1000: LR=9.56e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 811 Train Time 39.29366874694824s

Training epoch 812, Batch 500/1000: LR=9.47e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 812, Batch 1000/1000: LR=9.47e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 812 Train Time 38.95572900772095s

Training epoch 813, Batch 500/1000: LR=9.39e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 813, Batch 1000/1000: LR=9.39e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 813 Train Time 39.01244020462036s

Training epoch 814, Batch 500/1000: LR=9.30e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 814, Batch 1000/1000: LR=9.30e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 814 Train Time 38.88361692428589s

Training epoch 815, Batch 500/1000: LR=9.21e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 815, Batch 1000/1000: LR=9.21e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 815 Train Time 38.90942740440369s

Training epoch 816, Batch 500/1000: LR=9.13e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 816, Batch 1000/1000: LR=9.13e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 816 Train Time 38.89625024795532s

Training epoch 817, Batch 500/1000: LR=9.04e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 817, Batch 1000/1000: LR=9.04e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 817 Train Time 38.91745162010193s

Training epoch 818, Batch 500/1000: LR=8.96e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 818, Batch 1000/1000: LR=8.96e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 818 Train Time 38.90735054016113s

Training epoch 819, Batch 500/1000: LR=8.87e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 819, Batch 1000/1000: LR=8.87e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 819 Train Time 39.25666785240173s

Training epoch 820, Batch 500/1000: LR=8.79e-06, Loss=2.99e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 820, Batch 1000/1000: LR=8.79e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 820 Train Time 39.647271156311035s

Training epoch 821, Batch 500/1000: LR=8.71e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 821, Batch 1000/1000: LR=8.71e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 821 Train Time 39.199084520339966s

Training epoch 822, Batch 500/1000: LR=8.62e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 822, Batch 1000/1000: LR=8.62e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 822 Train Time 39.28237199783325s

Training epoch 823, Batch 500/1000: LR=8.54e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 823, Batch 1000/1000: LR=8.54e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 823 Train Time 39.17710471153259s

Training epoch 824, Batch 500/1000: LR=8.46e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 824, Batch 1000/1000: LR=8.46e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Epoch 824 Train Time 39.158403635025024s

Training epoch 825, Batch 500/1000: LR=8.38e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 825, Batch 1000/1000: LR=8.38e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 825 Train Time 39.16625690460205s

Training epoch 826, Batch 500/1000: LR=8.29e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 826, Batch 1000/1000: LR=8.29e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 826 Train Time 39.2814826965332s

Training epoch 827, Batch 500/1000: LR=8.21e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 827, Batch 1000/1000: LR=8.21e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 827 Train Time 39.15579056739807s

Training epoch 828, Batch 500/1000: LR=8.13e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 828, Batch 1000/1000: LR=8.13e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 828 Train Time 39.146687507629395s

Training epoch 829, Batch 500/1000: LR=8.05e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 829, Batch 1000/1000: LR=8.05e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 829 Train Time 39.126179456710815s

Training epoch 830, Batch 500/1000: LR=7.97e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 830, Batch 1000/1000: LR=7.97e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 830 Train Time 39.19884943962097s

Training epoch 831, Batch 500/1000: LR=7.89e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 831, Batch 1000/1000: LR=7.89e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 831 Train Time 39.26657438278198s

Training epoch 832, Batch 500/1000: LR=7.81e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 832, Batch 1000/1000: LR=7.81e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 832 Train Time 39.15210843086243s

Training epoch 833, Batch 500/1000: LR=7.74e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 833, Batch 1000/1000: LR=7.74e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 833 Train Time 39.16236114501953s

Training epoch 834, Batch 500/1000: LR=7.66e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.09e-01
Training epoch 834, Batch 1000/1000: LR=7.66e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 834 Train Time 39.120134592056274s

Training epoch 835, Batch 500/1000: LR=7.58e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 835, Batch 1000/1000: LR=7.58e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 835 Train Time 39.252429485321045s

Training epoch 836, Batch 500/1000: LR=7.50e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 836, Batch 1000/1000: LR=7.50e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 836 Train Time 39.14325404167175s

Training epoch 837, Batch 500/1000: LR=7.43e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 837, Batch 1000/1000: LR=7.43e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 837 Train Time 39.134382247924805s

Training epoch 838, Batch 500/1000: LR=7.35e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 838, Batch 1000/1000: LR=7.35e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 838 Train Time 39.158994913101196s

Training epoch 839, Batch 500/1000: LR=7.27e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 839, Batch 1000/1000: LR=7.27e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 839 Train Time 39.270843744277954s

Training epoch 840, Batch 500/1000: LR=7.20e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 840, Batch 1000/1000: LR=7.20e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 840 Train Time 39.22499489784241s

Training epoch 841, Batch 500/1000: LR=7.12e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 841, Batch 1000/1000: LR=7.12e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 841 Train Time 39.140533685684204s

Training epoch 842, Batch 500/1000: LR=7.05e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 842, Batch 1000/1000: LR=7.05e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 842 Train Time 39.142730474472046s

Training epoch 843, Batch 500/1000: LR=6.97e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 843, Batch 1000/1000: LR=6.97e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 843 Train Time 39.177159547805786s

Training epoch 844, Batch 500/1000: LR=6.90e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 844, Batch 1000/1000: LR=6.90e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 844 Train Time 39.15927839279175s

Training epoch 845, Batch 500/1000: LR=6.83e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 845, Batch 1000/1000: LR=6.83e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 845 Train Time 39.11550259590149s

Training epoch 846, Batch 500/1000: LR=6.75e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 846, Batch 1000/1000: LR=6.75e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 846 Train Time 39.13254761695862s

Training epoch 847, Batch 500/1000: LR=6.68e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 847, Batch 1000/1000: LR=6.68e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 847 Train Time 39.16241908073425s

Training epoch 848, Batch 500/1000: LR=6.61e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 848, Batch 1000/1000: LR=6.61e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 848 Train Time 39.154712438583374s

Training epoch 849, Batch 500/1000: LR=6.54e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 849, Batch 1000/1000: LR=6.54e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 849 Train Time 39.26630139350891s

Training epoch 850, Batch 500/1000: LR=6.47e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 850, Batch 1000/1000: LR=6.47e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 850 Train Time 39.14715600013733s

Training epoch 851, Batch 500/1000: LR=6.40e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 851, Batch 1000/1000: LR=6.40e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 851 Train Time 39.147969007492065s

Training epoch 852, Batch 500/1000: LR=6.32e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 852, Batch 1000/1000: LR=6.32e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 852 Train Time 39.13012099266052s

Training epoch 853, Batch 500/1000: LR=6.25e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 853, Batch 1000/1000: LR=6.25e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 853 Train Time 39.10011410713196s

Training epoch 854, Batch 500/1000: LR=6.19e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 854, Batch 1000/1000: LR=6.19e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 854 Train Time 38.8828649520874s

Training epoch 855, Batch 500/1000: LR=6.12e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 855, Batch 1000/1000: LR=6.12e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 855 Train Time 38.88228940963745s

Training epoch 856, Batch 500/1000: LR=6.05e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 856, Batch 1000/1000: LR=6.05e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 856 Train Time 38.895793437957764s

Training epoch 857, Batch 500/1000: LR=5.98e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 857, Batch 1000/1000: LR=5.98e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 857 Train Time 38.87714457511902s

Training epoch 858, Batch 500/1000: LR=5.91e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 858, Batch 1000/1000: LR=5.91e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 858 Train Time 39.0222225189209s

Training epoch 859, Batch 500/1000: LR=5.84e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 859, Batch 1000/1000: LR=5.84e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 859 Train Time 38.89929246902466s

Training epoch 860, Batch 500/1000: LR=5.78e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 860, Batch 1000/1000: LR=5.78e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 860 Train Time 38.889294385910034s

Training epoch 861, Batch 500/1000: LR=5.71e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 861, Batch 1000/1000: LR=5.71e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 861 Train Time 38.92294359207153s

Training epoch 862, Batch 500/1000: LR=5.65e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 862, Batch 1000/1000: LR=5.65e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 862 Train Time 38.9066276550293s

Training epoch 863, Batch 500/1000: LR=5.58e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 863, Batch 1000/1000: LR=5.58e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Epoch 863 Train Time 38.90628457069397s

Training epoch 864, Batch 500/1000: LR=5.51e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 864, Batch 1000/1000: LR=5.51e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 864 Train Time 38.959738969802856s

Training epoch 865, Batch 500/1000: LR=5.45e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 865, Batch 1000/1000: LR=5.45e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 865 Train Time 38.90344285964966s

Training epoch 866, Batch 500/1000: LR=5.39e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 866, Batch 1000/1000: LR=5.39e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 866 Train Time 93.40669512748718s

Training epoch 867, Batch 500/1000: LR=5.32e-06, Loss=2.99e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 867, Batch 1000/1000: LR=5.32e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 867 Train Time 39.50668454170227s

Training epoch 868, Batch 500/1000: LR=5.26e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 868, Batch 1000/1000: LR=5.26e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 868 Train Time 39.29627823829651s

Training epoch 869, Batch 500/1000: LR=5.20e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 869, Batch 1000/1000: LR=5.20e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 869 Train Time 39.268697023391724s

Training epoch 870, Batch 500/1000: LR=5.13e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 870, Batch 1000/1000: LR=5.13e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 870 Train Time 39.28422236442566s

Training epoch 871, Batch 500/1000: LR=5.07e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 871, Batch 1000/1000: LR=5.07e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 871 Train Time 39.27853345870972s

Training epoch 872, Batch 500/1000: LR=5.01e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 872, Batch 1000/1000: LR=5.01e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 872 Train Time 39.300209283828735s

Training epoch 873, Batch 500/1000: LR=4.95e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 873, Batch 1000/1000: LR=4.95e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 873 Train Time 39.3226203918457s

Training epoch 874, Batch 500/1000: LR=4.89e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 874, Batch 1000/1000: LR=4.89e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 874 Train Time 39.377190351486206s

Training epoch 875, Batch 500/1000: LR=4.83e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 875, Batch 1000/1000: LR=4.83e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 875 Train Time 39.30551815032959s

Training epoch 876, Batch 500/1000: LR=4.77e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 876, Batch 1000/1000: LR=4.77e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Epoch 876 Train Time 39.553298473358154s

Training epoch 877, Batch 500/1000: LR=4.71e-06, Loss=2.99e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 877, Batch 1000/1000: LR=4.71e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 877 Train Time 39.292715311050415s

Training epoch 878, Batch 500/1000: LR=4.65e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 878, Batch 1000/1000: LR=4.65e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 878 Train Time 39.329944133758545s

Training epoch 879, Batch 500/1000: LR=4.59e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 879, Batch 1000/1000: LR=4.59e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 879 Train Time 39.30550742149353s

Training epoch 880, Batch 500/1000: LR=4.53e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 880, Batch 1000/1000: LR=4.53e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 880 Train Time 39.28374171257019s

Training epoch 881, Batch 500/1000: LR=4.48e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 881, Batch 1000/1000: LR=4.48e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 881 Train Time 39.28397607803345s

Training epoch 882, Batch 500/1000: LR=4.42e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 882, Batch 1000/1000: LR=4.42e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 882 Train Time 39.39410042762756s

Training epoch 883, Batch 500/1000: LR=4.36e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 883, Batch 1000/1000: LR=4.36e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 883 Train Time 39.28700280189514s

Training epoch 884, Batch 500/1000: LR=4.31e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 884, Batch 1000/1000: LR=4.31e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 884 Train Time 39.34294128417969s

Training epoch 885, Batch 500/1000: LR=4.25e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 885, Batch 1000/1000: LR=4.25e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 885 Train Time 39.398284912109375s

Training epoch 886, Batch 500/1000: LR=4.20e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 886, Batch 1000/1000: LR=4.20e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 886 Train Time 39.28510141372681s

Training epoch 887, Batch 500/1000: LR=4.14e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 887, Batch 1000/1000: LR=4.14e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 887 Train Time 39.28274965286255s

Training epoch 888, Batch 500/1000: LR=4.09e-06, Loss=2.87e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 888, Batch 1000/1000: LR=4.09e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 888 Train Time 39.30626559257507s

Training epoch 889, Batch 500/1000: LR=4.03e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 889, Batch 1000/1000: LR=4.03e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 889 Train Time 39.3263943195343s

Training epoch 890, Batch 500/1000: LR=3.98e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 890, Batch 1000/1000: LR=3.98e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 890 Train Time 39.24475169181824s

Training epoch 891, Batch 500/1000: LR=3.93e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 891, Batch 1000/1000: LR=3.93e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 891 Train Time 39.31529903411865s

Training epoch 892, Batch 500/1000: LR=3.87e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 892, Batch 1000/1000: LR=3.87e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 892 Train Time 39.31471824645996s

Training epoch 893, Batch 500/1000: LR=3.82e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 893, Batch 1000/1000: LR=3.82e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 893 Train Time 39.29954981803894s

Training epoch 894, Batch 500/1000: LR=3.77e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 894, Batch 1000/1000: LR=3.77e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 894 Train Time 39.39621067047119s

Training epoch 895, Batch 500/1000: LR=3.72e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 895, Batch 1000/1000: LR=3.72e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 895 Train Time 39.30577325820923s

Training epoch 896, Batch 500/1000: LR=3.67e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 896, Batch 1000/1000: LR=3.67e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 896 Train Time 39.603126764297485s

Training epoch 897, Batch 500/1000: LR=3.62e-06, Loss=2.87e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 897, Batch 1000/1000: LR=3.62e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 897 Train Time 39.31264114379883s

Training epoch 898, Batch 500/1000: LR=3.57e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 898, Batch 1000/1000: LR=3.57e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 898 Train Time 39.300047159194946s

Training epoch 899, Batch 500/1000: LR=3.52e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 899, Batch 1000/1000: LR=3.52e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 899 Train Time 39.27078866958618s

Training epoch 900, Batch 500/1000: LR=3.47e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 900, Batch 1000/1000: LR=3.47e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 900 Train Time 39.27449369430542s


Test Loss 1: 2.26e-01 2: 1.16e-01 3: 4.16e-02
Test FER 1: 6.65e-01 2: 4.06e-01 3: 1.66e-01
Test BER 1: 9.38e-02 2: 4.81e-02 3: 1.65e-02
Test -ln(BER) 1: 2.37e+00 2: 3.04e+00 3: 4.10e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 57.540203332901 s

Training epoch 901, Batch 500/1000: LR=3.42e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 901, Batch 1000/1000: LR=3.42e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 901 Train Time 39.434003591537476s

Training epoch 902, Batch 500/1000: LR=3.37e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 902, Batch 1000/1000: LR=3.37e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 902 Train Time 39.34291195869446s

Training epoch 903, Batch 500/1000: LR=3.33e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 903, Batch 1000/1000: LR=3.33e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 903 Train Time 38.97868990898132s

Training epoch 904, Batch 500/1000: LR=3.28e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 904, Batch 1000/1000: LR=3.28e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Epoch 904 Train Time 38.868815183639526s

Training epoch 905, Batch 500/1000: LR=3.23e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 905, Batch 1000/1000: LR=3.23e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 905 Train Time 38.900150299072266s

Training epoch 906, Batch 500/1000: LR=3.19e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 906, Batch 1000/1000: LR=3.19e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 906 Train Time 38.87839388847351s

Training epoch 907, Batch 500/1000: LR=3.14e-06, Loss=2.96e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 907, Batch 1000/1000: LR=3.14e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 907 Train Time 38.889506816864014s

Training epoch 908, Batch 500/1000: LR=3.10e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 908, Batch 1000/1000: LR=3.10e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 908 Train Time 38.96165347099304s

Training epoch 909, Batch 500/1000: LR=3.05e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 909, Batch 1000/1000: LR=3.05e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 909 Train Time 38.865525007247925s

Training epoch 910, Batch 500/1000: LR=3.01e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 910, Batch 1000/1000: LR=3.01e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Epoch 910 Train Time 38.8723361492157s

Training epoch 911, Batch 500/1000: LR=2.97e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 911, Batch 1000/1000: LR=2.97e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 911 Train Time 104.82154440879822s

Training epoch 912, Batch 500/1000: LR=2.92e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 912, Batch 1000/1000: LR=2.92e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 912 Train Time 39.51775550842285s

Training epoch 913, Batch 500/1000: LR=2.88e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 913, Batch 1000/1000: LR=2.88e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 913 Train Time 38.86935877799988s

Training epoch 914, Batch 500/1000: LR=2.84e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 914, Batch 1000/1000: LR=2.84e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 914 Train Time 38.85519337654114s

Training epoch 915, Batch 500/1000: LR=2.80e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 915, Batch 1000/1000: LR=2.80e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 915 Train Time 38.88389277458191s

Training epoch 916, Batch 500/1000: LR=2.75e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 916, Batch 1000/1000: LR=2.75e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 916 Train Time 39.221696853637695s

Training epoch 917, Batch 500/1000: LR=2.71e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 917, Batch 1000/1000: LR=2.71e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 917 Train Time 38.8817195892334s

Training epoch 918, Batch 500/1000: LR=2.67e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 918, Batch 1000/1000: LR=2.67e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 918 Train Time 38.89535880088806s

Training epoch 919, Batch 500/1000: LR=2.63e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 919, Batch 1000/1000: LR=2.63e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 919 Train Time 38.855122566223145s

Training epoch 920, Batch 500/1000: LR=2.59e-06, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 920, Batch 1000/1000: LR=2.59e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 920 Train Time 38.892826795578s

Training epoch 921, Batch 500/1000: LR=2.56e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 921, Batch 1000/1000: LR=2.56e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 921 Train Time 39.17603659629822s

Training epoch 922, Batch 500/1000: LR=2.52e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 922, Batch 1000/1000: LR=2.52e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 922 Train Time 39.102866411209106s

Training epoch 923, Batch 500/1000: LR=2.48e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 923, Batch 1000/1000: LR=2.48e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 923 Train Time 38.890387773513794s

Training epoch 924, Batch 500/1000: LR=2.44e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 924, Batch 1000/1000: LR=2.44e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 924 Train Time 38.87694191932678s

Training epoch 925, Batch 500/1000: LR=2.40e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 925, Batch 1000/1000: LR=2.40e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 925 Train Time 38.86511206626892s

Training epoch 926, Batch 500/1000: LR=2.37e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 926, Batch 1000/1000: LR=2.37e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 926 Train Time 38.89458250999451s

Training epoch 927, Batch 500/1000: LR=2.33e-06, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 927, Batch 1000/1000: LR=2.33e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 927 Train Time 38.937790870666504s

Training epoch 928, Batch 500/1000: LR=2.30e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 928, Batch 1000/1000: LR=2.30e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 928 Train Time 38.93410396575928s

Training epoch 929, Batch 500/1000: LR=2.26e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 929, Batch 1000/1000: LR=2.26e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 929 Train Time 38.84754395484924s

Training epoch 930, Batch 500/1000: LR=2.23e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 930, Batch 1000/1000: LR=2.23e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 930 Train Time 38.882739782333374s

Training epoch 931, Batch 500/1000: LR=2.19e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 931, Batch 1000/1000: LR=2.19e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 931 Train Time 38.86530089378357s

Training epoch 932, Batch 500/1000: LR=2.16e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 932, Batch 1000/1000: LR=2.16e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 932 Train Time 38.85945153236389s

Training epoch 933, Batch 500/1000: LR=2.13e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 933, Batch 1000/1000: LR=2.13e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 933 Train Time 39.02251148223877s

Training epoch 934, Batch 500/1000: LR=2.09e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 934, Batch 1000/1000: LR=2.09e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 934 Train Time 38.86028695106506s

Training epoch 935, Batch 500/1000: LR=2.06e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 935, Batch 1000/1000: LR=2.06e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 935 Train Time 38.84103202819824s

Training epoch 936, Batch 500/1000: LR=2.03e-06, Loss=2.96e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 936, Batch 1000/1000: LR=2.03e-06, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Epoch 936 Train Time 38.904725313186646s

Training epoch 937, Batch 500/1000: LR=2.00e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 937, Batch 1000/1000: LR=2.00e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 937 Train Time 38.87025690078735s

Training epoch 938, Batch 500/1000: LR=1.97e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 938, Batch 1000/1000: LR=1.97e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 938 Train Time 38.88608384132385s

Training epoch 939, Batch 500/1000: LR=1.94e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 939, Batch 1000/1000: LR=1.94e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 939 Train Time 38.86935472488403s

Training epoch 940, Batch 500/1000: LR=1.91e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 940, Batch 1000/1000: LR=1.91e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 940 Train Time 38.92722845077515s

Training epoch 941, Batch 500/1000: LR=1.88e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 941, Batch 1000/1000: LR=1.88e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 941 Train Time 38.99678301811218s

Training epoch 942, Batch 500/1000: LR=1.85e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 942, Batch 1000/1000: LR=1.85e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 942 Train Time 38.89738154411316s

Training epoch 943, Batch 500/1000: LR=1.82e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 943, Batch 1000/1000: LR=1.82e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 943 Train Time 38.85199499130249s

Training epoch 944, Batch 500/1000: LR=1.79e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 944, Batch 1000/1000: LR=1.79e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 944 Train Time 38.8817982673645s

Training epoch 945, Batch 500/1000: LR=1.76e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 945, Batch 1000/1000: LR=1.76e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 945 Train Time 38.87708568572998s

Training epoch 946, Batch 500/1000: LR=1.74e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 946, Batch 1000/1000: LR=1.74e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 946 Train Time 38.85823154449463s

Training epoch 947, Batch 500/1000: LR=1.71e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 947, Batch 1000/1000: LR=1.71e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 947 Train Time 38.88029432296753s

Training epoch 948, Batch 500/1000: LR=1.68e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 948, Batch 1000/1000: LR=1.68e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 948 Train Time 38.89788246154785s

Training epoch 949, Batch 500/1000: LR=1.66e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 949, Batch 1000/1000: LR=1.66e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 949 Train Time 40.55992794036865s

Training epoch 950, Batch 500/1000: LR=1.63e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 950, Batch 1000/1000: LR=1.63e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 950 Train Time 39.43218111991882s

Training epoch 951, Batch 500/1000: LR=1.61e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 951, Batch 1000/1000: LR=1.61e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 951 Train Time 39.184890270233154s

Training epoch 952, Batch 500/1000: LR=1.59e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 952, Batch 1000/1000: LR=1.59e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 952 Train Time 39.204848527908325s

Training epoch 953, Batch 500/1000: LR=1.56e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 953, Batch 1000/1000: LR=1.56e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 953 Train Time 39.43344330787659s

Training epoch 954, Batch 500/1000: LR=1.54e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 954, Batch 1000/1000: LR=1.54e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 954 Train Time 39.20327639579773s

Training epoch 955, Batch 500/1000: LR=1.52e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 955, Batch 1000/1000: LR=1.52e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 955 Train Time 39.23170471191406s

Training epoch 956, Batch 500/1000: LR=1.49e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 956, Batch 1000/1000: LR=1.49e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 956 Train Time 39.30213260650635s

Training epoch 957, Batch 500/1000: LR=1.47e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 957, Batch 1000/1000: LR=1.47e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 957 Train Time 39.22066903114319s

Training epoch 958, Batch 500/1000: LR=1.45e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 958, Batch 1000/1000: LR=1.45e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 958 Train Time 39.33286762237549s

Training epoch 959, Batch 500/1000: LR=1.43e-06, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 959, Batch 1000/1000: LR=1.43e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 959 Train Time 39.18263530731201s

Training epoch 960, Batch 500/1000: LR=1.41e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 960, Batch 1000/1000: LR=1.41e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 960 Train Time 39.25571846961975s

Training epoch 961, Batch 500/1000: LR=1.39e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 961, Batch 1000/1000: LR=1.39e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 961 Train Time 39.20099425315857s

Training epoch 962, Batch 500/1000: LR=1.37e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 962, Batch 1000/1000: LR=1.37e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 962 Train Time 39.18151926994324s

Training epoch 963, Batch 500/1000: LR=1.35e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 963, Batch 1000/1000: LR=1.35e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 963 Train Time 39.23389554023743s

Training epoch 964, Batch 500/1000: LR=1.33e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 964, Batch 1000/1000: LR=1.33e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 964 Train Time 39.207104444503784s

Training epoch 965, Batch 500/1000: LR=1.32e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 965, Batch 1000/1000: LR=1.32e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 965 Train Time 39.282999753952026s

Training epoch 966, Batch 500/1000: LR=1.30e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 966, Batch 1000/1000: LR=1.30e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 966 Train Time 39.119603395462036s

Training epoch 967, Batch 500/1000: LR=1.28e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 967, Batch 1000/1000: LR=1.28e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 967 Train Time 39.25415015220642s

Training epoch 968, Batch 500/1000: LR=1.27e-06, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 968, Batch 1000/1000: LR=1.27e-06, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 968 Train Time 39.1982901096344s

Training epoch 969, Batch 500/1000: LR=1.25e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 969, Batch 1000/1000: LR=1.25e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 969 Train Time 39.11729621887207s

Training epoch 970, Batch 500/1000: LR=1.23e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 970, Batch 1000/1000: LR=1.23e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 970 Train Time 39.07930874824524s

Training epoch 971, Batch 500/1000: LR=1.22e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 971, Batch 1000/1000: LR=1.22e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 971 Train Time 39.14355134963989s

Training epoch 972, Batch 500/1000: LR=1.21e-06, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 972, Batch 1000/1000: LR=1.21e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 972 Train Time 39.170416831970215s

Training epoch 973, Batch 500/1000: LR=1.19e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 973, Batch 1000/1000: LR=1.19e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 973 Train Time 39.08894729614258s

Training epoch 974, Batch 500/1000: LR=1.18e-06, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 974, Batch 1000/1000: LR=1.18e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 974 Train Time 39.13091278076172s

Training epoch 975, Batch 500/1000: LR=1.17e-06, Loss=2.99e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 975, Batch 1000/1000: LR=1.17e-06, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 975 Train Time 39.16770100593567s

Training epoch 976, Batch 500/1000: LR=1.15e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 976, Batch 1000/1000: LR=1.15e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 976 Train Time 39.13136672973633s

Training epoch 977, Batch 500/1000: LR=1.14e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 977, Batch 1000/1000: LR=1.14e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 977 Train Time 39.1906304359436s

Training epoch 978, Batch 500/1000: LR=1.13e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 978, Batch 1000/1000: LR=1.13e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 978 Train Time 39.13384556770325s

Training epoch 979, Batch 500/1000: LR=1.12e-06, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 979, Batch 1000/1000: LR=1.12e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 979 Train Time 39.19200611114502s

Training epoch 980, Batch 500/1000: LR=1.11e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 980, Batch 1000/1000: LR=1.11e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 980 Train Time 39.073880195617676s

Training epoch 981, Batch 500/1000: LR=1.10e-06, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 981, Batch 1000/1000: LR=1.10e-06, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 981 Train Time 39.12302851676941s

Training epoch 982, Batch 500/1000: LR=1.09e-06, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 982, Batch 1000/1000: LR=1.09e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 982 Train Time 39.16141986846924s

Training epoch 983, Batch 500/1000: LR=1.08e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 983, Batch 1000/1000: LR=1.08e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 983 Train Time 39.12287473678589s

Training epoch 984, Batch 500/1000: LR=1.07e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 984, Batch 1000/1000: LR=1.07e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 984 Train Time 39.12786912918091s

Training epoch 985, Batch 500/1000: LR=1.06e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 985, Batch 1000/1000: LR=1.06e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 985 Train Time 39.09565210342407s

Training epoch 986, Batch 500/1000: LR=1.05e-06, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 986, Batch 1000/1000: LR=1.05e-06, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 986 Train Time 39.12602972984314s

Training epoch 987, Batch 500/1000: LR=1.05e-06, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 987, Batch 1000/1000: LR=1.05e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 987 Train Time 39.14571237564087s

Training epoch 988, Batch 500/1000: LR=1.04e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 988, Batch 1000/1000: LR=1.04e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 988 Train Time 39.22629141807556s

Training epoch 989, Batch 500/1000: LR=1.04e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 989, Batch 1000/1000: LR=1.04e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 989 Train Time 39.09945344924927s

Training epoch 990, Batch 500/1000: LR=1.03e-06, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 990, Batch 1000/1000: LR=1.03e-06, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 990 Train Time 39.11379337310791s

Training epoch 991, Batch 500/1000: LR=1.02e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 991, Batch 1000/1000: LR=1.02e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 991 Train Time 39.093169927597046s

Training epoch 992, Batch 500/1000: LR=1.02e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 992, Batch 1000/1000: LR=1.02e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 992 Train Time 39.11652135848999s

Training epoch 993, Batch 500/1000: LR=1.02e-06, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 993, Batch 1000/1000: LR=1.02e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 993 Train Time 39.11666798591614s

Training epoch 994, Batch 500/1000: LR=1.01e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 994, Batch 1000/1000: LR=1.01e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 994 Train Time 39.10530877113342s

Training epoch 995, Batch 500/1000: LR=1.01e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 995, Batch 1000/1000: LR=1.01e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 995 Train Time 39.14914798736572s

Training epoch 996, Batch 500/1000: LR=1.01e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 996, Batch 1000/1000: LR=1.01e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 996 Train Time 101.89313864707947s

Training epoch 997, Batch 500/1000: LR=1.00e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 997, Batch 1000/1000: LR=1.00e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 997 Train Time 39.66117548942566s

Training epoch 998, Batch 500/1000: LR=1.00e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 998, Batch 1000/1000: LR=1.00e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 998 Train Time 39.29810810089111s

Training epoch 999, Batch 500/1000: LR=1.00e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 999, Batch 1000/1000: LR=1.00e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 999 Train Time 38.897955894470215s

Training epoch 1000, Batch 500/1000: LR=1.00e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1000, Batch 1000/1000: LR=1.00e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1000 Train Time 38.87745761871338s


Test Loss 1: 2.27e-01 2: 1.17e-01 3: 4.12e-02
Test FER 1: 6.65e-01 2: 4.06e-01 3: 1.66e-01
Test BER 1: 9.41e-02 2: 4.81e-02 3: 1.65e-02
Test -ln(BER) 1: 2.36e+00 2: 3.03e+00 3: 4.11e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 56.41622281074524 s

