Path to model/logs: Results_ECCT\LDPC__Code_n_49_k_24__05_11_2022_10_17_33
Namespace(epochs=2000, workers=0, lr=0.0001, gpus='0', batch_size=128, test_batch_size=2048, seed=42, code_type='LDPC', code_k=24, code_n=49, standardize=False, N_dec=6, d_model=32, h=8, code=<__main__.Code object at 0x00000245CA552470>, path='Results_ECCT\\LDPC__Code_n_49_k_24__05_11_2022_10_17_33')
Self-Attention Sparsity Ratio=72.26%, Self-Attention Complexity Ratio=13.87%
Mask:
 tensor([[[[False,  True,  True,  ...,  True,  True,  True],
          [ True, False,  True,  ...,  True,  True,  True],
          [ True,  True, False,  ...,  True,  True,  True],
          ...,
          [ True,  True,  True,  ..., False,  True,  True],
          [ True,  True,  True,  ...,  True, False,  True],
          [ True,  True,  True,  ...,  True,  True, False]]]])
ECC_Transformer(
  (decoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Linear(in_features=32, out_features=32, bias=True)
            (2): Linear(in_features=32, out_features=32, bias=True)
            (3): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=32, out_features=128, bias=True)
          (w_2): Linear(in_features=128, out_features=32, bias=True)
          (dropout): Dropout(p=0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (oned_final_embed): Sequential(
    (0): Linear(in_features=32, out_features=1, bias=True)
  )
  (out_fc): Linear(in_features=77, out_features=49, bias=True)
)
# of Parameters: 82671
Training epoch 1, Batch 500/1000: LR=1.00e-04, Loss=2.50e-01 BER=8.23e-02 FER=8.53e-01
Training epoch 1, Batch 1000/1000: LR=1.00e-04, Loss=2.19e-01 BER=6.81e-02 FER=8.41e-01
Epoch 1 Train Time 39.97304034233093s


Test Loss 4: 1.95e-01 5: 1.36e-01 6: 8.49e-02
Test FER 4: 9.48e-01 5: 8.61e-01 6: 6.99e-01
Test BER 4: 5.84e-02 5: 3.95e-02 6: 2.42e-02
Test -ln(BER) 4: 2.84e+00 5: 3.23e+00 6: 3.72e+00
# of testing samples: [100352.0, 100352.0, 100352.0]
 Test Time 56.41322898864746 s

Training epoch 2, Batch 500/1000: LR=1.00e-04, Loss=1.72e-01 BER=5.33e-02 FER=8.15e-01
Training epoch 2, Batch 1000/1000: LR=1.00e-04, Loss=1.64e-01 BER=5.22e-02 FER=7.74e-01
Epoch 2 Train Time 38.540149450302124s

Training epoch 3, Batch 500/1000: LR=1.00e-04, Loss=1.45e-01 BER=4.81e-02 FER=6.36e-01
Training epoch 3, Batch 1000/1000: LR=1.00e-04, Loss=1.40e-01 BER=4.68e-02 FER=6.09e-01
Epoch 3 Train Time 38.57020401954651s

Training epoch 4, Batch 500/1000: LR=1.00e-04, Loss=1.29e-01 BER=4.40e-02 FER=5.50e-01
Training epoch 4, Batch 1000/1000: LR=1.00e-04, Loss=1.26e-01 BER=4.32e-02 FER=5.37e-01
Epoch 4 Train Time 38.62944054603577s

Training epoch 5, Batch 500/1000: LR=1.00e-04, Loss=1.19e-01 BER=4.12e-02 FER=5.07e-01
Training epoch 5, Batch 1000/1000: LR=1.00e-04, Loss=1.17e-01 BER=4.07e-02 FER=4.99e-01
Epoch 5 Train Time 38.77741456031799s

Training epoch 6, Batch 500/1000: LR=1.00e-04, Loss=1.11e-01 BER=3.92e-02 FER=4.80e-01
Training epoch 6, Batch 1000/1000: LR=1.00e-04, Loss=1.09e-01 BER=3.88e-02 FER=4.77e-01
Epoch 6 Train Time 39.500553131103516s

Training epoch 7, Batch 500/1000: LR=1.00e-04, Loss=1.04e-01 BER=3.75e-02 FER=4.63e-01
Training epoch 7, Batch 1000/1000: LR=1.00e-04, Loss=1.02e-01 BER=3.70e-02 FER=4.60e-01
Epoch 7 Train Time 39.06770706176758s

Training epoch 8, Batch 500/1000: LR=1.00e-04, Loss=9.68e-02 BER=3.56e-02 FER=4.46e-01
Training epoch 8, Batch 1000/1000: LR=1.00e-04, Loss=9.49e-02 BER=3.51e-02 FER=4.41e-01
Epoch 8 Train Time 38.762972593307495s

Training epoch 9, Batch 500/1000: LR=1.00e-04, Loss=8.97e-02 BER=3.38e-02 FER=4.24e-01
Training epoch 9, Batch 1000/1000: LR=1.00e-04, Loss=8.79e-02 BER=3.31e-02 FER=4.17e-01
Epoch 9 Train Time 38.63814878463745s

Training epoch 10, Batch 500/1000: LR=1.00e-04, Loss=8.35e-02 BER=3.16e-02 FER=4.00e-01
Training epoch 10, Batch 1000/1000: LR=1.00e-04, Loss=8.25e-02 BER=3.12e-02 FER=3.94e-01
Epoch 10 Train Time 38.83500552177429s

Training epoch 11, Batch 500/1000: LR=1.00e-04, Loss=7.86e-02 BER=2.99e-02 FER=3.76e-01
Training epoch 11, Batch 1000/1000: LR=1.00e-04, Loss=7.74e-02 BER=2.94e-02 FER=3.70e-01
Epoch 11 Train Time 39.11989712715149s

Training epoch 12, Batch 500/1000: LR=1.00e-04, Loss=7.38e-02 BER=2.81e-02 FER=3.52e-01
Training epoch 12, Batch 1000/1000: LR=1.00e-04, Loss=7.30e-02 BER=2.78e-02 FER=3.48e-01
Epoch 12 Train Time 39.612589836120605s

Training epoch 13, Batch 500/1000: LR=1.00e-04, Loss=7.04e-02 BER=2.67e-02 FER=3.34e-01
Training epoch 13, Batch 1000/1000: LR=1.00e-04, Loss=6.94e-02 BER=2.64e-02 FER=3.29e-01
Epoch 13 Train Time 38.71599245071411s

Training epoch 14, Batch 500/1000: LR=1.00e-04, Loss=6.68e-02 BER=2.53e-02 FER=3.13e-01
Training epoch 14, Batch 1000/1000: LR=1.00e-04, Loss=6.58e-02 BER=2.50e-02 FER=3.08e-01
Epoch 14 Train Time 38.60350799560547s

Training epoch 15, Batch 500/1000: LR=1.00e-04, Loss=6.36e-02 BER=2.41e-02 FER=2.96e-01
Training epoch 15, Batch 1000/1000: LR=1.00e-04, Loss=6.24e-02 BER=2.37e-02 FER=2.90e-01
Epoch 15 Train Time 38.84065341949463s

Training epoch 16, Batch 500/1000: LR=1.00e-04, Loss=5.96e-02 BER=2.26e-02 FER=2.76e-01
Training epoch 16, Batch 1000/1000: LR=1.00e-04, Loss=5.91e-02 BER=2.23e-02 FER=2.72e-01
Epoch 16 Train Time 38.58815670013428s

Training epoch 17, Batch 500/1000: LR=1.00e-04, Loss=5.74e-02 BER=2.17e-02 FER=2.64e-01
Training epoch 17, Batch 1000/1000: LR=1.00e-04, Loss=5.67e-02 BER=2.14e-02 FER=2.59e-01
Epoch 17 Train Time 38.56076955795288s

Training epoch 18, Batch 500/1000: LR=1.00e-04, Loss=5.50e-02 BER=2.08e-02 FER=2.49e-01
Training epoch 18, Batch 1000/1000: LR=1.00e-04, Loss=5.41e-02 BER=2.05e-02 FER=2.43e-01
Epoch 18 Train Time 38.6157021522522s

Training epoch 19, Batch 500/1000: LR=1.00e-04, Loss=5.21e-02 BER=1.96e-02 FER=2.29e-01
Training epoch 19, Batch 1000/1000: LR=1.00e-04, Loss=5.16e-02 BER=1.95e-02 FER=2.25e-01
Epoch 19 Train Time 38.567126512527466s

Training epoch 20, Batch 500/1000: LR=1.00e-04, Loss=4.90e-02 BER=1.84e-02 FER=2.09e-01
Training epoch 20, Batch 1000/1000: LR=1.00e-04, Loss=4.88e-02 BER=1.84e-02 FER=2.09e-01
Epoch 20 Train Time 38.87398290634155s

Training epoch 21, Batch 500/1000: LR=1.00e-04, Loss=4.69e-02 BER=1.77e-02 FER=1.98e-01
Training epoch 21, Batch 1000/1000: LR=1.00e-04, Loss=4.64e-02 BER=1.76e-02 FER=1.96e-01
Epoch 21 Train Time 38.62896490097046s

Training epoch 22, Batch 500/1000: LR=1.00e-04, Loss=4.64e-02 BER=1.76e-02 FER=1.94e-01
Training epoch 22, Batch 1000/1000: LR=1.00e-04, Loss=4.58e-02 BER=1.74e-02 FER=1.91e-01
Epoch 22 Train Time 38.59596800804138s

Training epoch 23, Batch 500/1000: LR=1.00e-04, Loss=4.43e-02 BER=1.68e-02 FER=1.84e-01
Training epoch 23, Batch 1000/1000: LR=1.00e-04, Loss=4.42e-02 BER=1.68e-02 FER=1.83e-01
Epoch 23 Train Time 38.36962413787842s

Training epoch 24, Batch 500/1000: LR=1.00e-04, Loss=4.37e-02 BER=1.66e-02 FER=1.78e-01
Training epoch 24, Batch 1000/1000: LR=1.00e-04, Loss=4.39e-02 BER=1.68e-02 FER=1.79e-01
Epoch 24 Train Time 38.324756145477295s

Training epoch 25, Batch 500/1000: LR=1.00e-04, Loss=4.33e-02 BER=1.65e-02 FER=1.75e-01
Training epoch 25, Batch 1000/1000: LR=1.00e-04, Loss=4.27e-02 BER=1.63e-02 FER=1.73e-01
Epoch 25 Train Time 38.31996726989746s

Training epoch 26, Batch 500/1000: LR=1.00e-04, Loss=4.12e-02 BER=1.56e-02 FER=1.66e-01
Training epoch 26, Batch 1000/1000: LR=1.00e-04, Loss=4.15e-02 BER=1.58e-02 FER=1.68e-01
Epoch 26 Train Time 38.27467703819275s

Training epoch 27, Batch 500/1000: LR=1.00e-04, Loss=4.09e-02 BER=1.57e-02 FER=1.64e-01
Training epoch 27, Batch 1000/1000: LR=1.00e-04, Loss=4.14e-02 BER=1.58e-02 FER=1.65e-01
Epoch 27 Train Time 38.308685064315796s

Training epoch 28, Batch 500/1000: LR=1.00e-04, Loss=4.14e-02 BER=1.60e-02 FER=1.67e-01
Training epoch 28, Batch 1000/1000: LR=1.00e-04, Loss=4.11e-02 BER=1.58e-02 FER=1.65e-01
Epoch 28 Train Time 38.300042152404785s

Training epoch 29, Batch 500/1000: LR=1.00e-04, Loss=4.02e-02 BER=1.54e-02 FER=1.59e-01
Training epoch 29, Batch 1000/1000: LR=1.00e-04, Loss=4.03e-02 BER=1.55e-02 FER=1.60e-01
Epoch 29 Train Time 38.3702929019928s

Training epoch 30, Batch 500/1000: LR=9.99e-05, Loss=4.08e-02 BER=1.58e-02 FER=1.60e-01
Training epoch 30, Batch 1000/1000: LR=9.99e-05, Loss=4.04e-02 BER=1.56e-02 FER=1.59e-01
Epoch 30 Train Time 38.34299945831299s

Training epoch 31, Batch 500/1000: LR=9.99e-05, Loss=3.92e-02 BER=1.50e-02 FER=1.56e-01
Training epoch 31, Batch 1000/1000: LR=9.99e-05, Loss=3.96e-02 BER=1.53e-02 FER=1.57e-01
Epoch 31 Train Time 38.31939935684204s

Training epoch 32, Batch 500/1000: LR=9.99e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Training epoch 32, Batch 1000/1000: LR=9.99e-05, Loss=3.93e-02 BER=1.51e-02 FER=1.55e-01
Epoch 32 Train Time 38.24607253074646s

Training epoch 33, Batch 500/1000: LR=9.99e-05, Loss=3.92e-02 BER=1.51e-02 FER=1.54e-01
Training epoch 33, Batch 1000/1000: LR=9.99e-05, Loss=3.89e-02 BER=1.51e-02 FER=1.53e-01
Epoch 33 Train Time 38.261783838272095s

Training epoch 34, Batch 500/1000: LR=9.99e-05, Loss=3.86e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 34, Batch 1000/1000: LR=9.99e-05, Loss=3.87e-02 BER=1.50e-02 FER=1.51e-01
Epoch 34 Train Time 38.24290108680725s

Training epoch 35, Batch 500/1000: LR=9.99e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Training epoch 35, Batch 1000/1000: LR=9.99e-05, Loss=3.85e-02 BER=1.49e-02 FER=1.51e-01
Epoch 35 Train Time 38.28231692314148s

Training epoch 36, Batch 500/1000: LR=9.99e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Training epoch 36, Batch 1000/1000: LR=9.99e-05, Loss=3.75e-02 BER=1.46e-02 FER=1.47e-01
Epoch 36 Train Time 38.241454124450684s

Training epoch 37, Batch 500/1000: LR=9.99e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.50e-01
Training epoch 37, Batch 1000/1000: LR=9.99e-05, Loss=3.82e-02 BER=1.49e-02 FER=1.49e-01
Epoch 37 Train Time 38.2428035736084s

Training epoch 38, Batch 500/1000: LR=9.99e-05, Loss=3.77e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 38, Batch 1000/1000: LR=9.99e-05, Loss=3.78e-02 BER=1.47e-02 FER=1.47e-01
Epoch 38 Train Time 38.26143956184387s

Training epoch 39, Batch 500/1000: LR=9.99e-05, Loss=3.84e-02 BER=1.50e-02 FER=1.49e-01
Training epoch 39, Batch 1000/1000: LR=9.99e-05, Loss=3.81e-02 BER=1.49e-02 FER=1.48e-01
Epoch 39 Train Time 38.26717948913574s

Training epoch 40, Batch 500/1000: LR=9.99e-05, Loss=3.76e-02 BER=1.47e-02 FER=1.46e-01
Training epoch 40, Batch 1000/1000: LR=9.99e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.46e-01
Epoch 40 Train Time 38.328959226608276s

Training epoch 41, Batch 500/1000: LR=9.99e-05, Loss=3.78e-02 BER=1.48e-02 FER=1.47e-01
Training epoch 41, Batch 1000/1000: LR=9.99e-05, Loss=3.77e-02 BER=1.48e-02 FER=1.46e-01
Epoch 41 Train Time 38.26716208457947s

Training epoch 42, Batch 500/1000: LR=9.99e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 42, Batch 1000/1000: LR=9.99e-05, Loss=3.66e-02 BER=1.43e-02 FER=1.43e-01
Epoch 42 Train Time 38.232386350631714s

Training epoch 43, Batch 500/1000: LR=9.99e-05, Loss=3.73e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 43, Batch 1000/1000: LR=9.99e-05, Loss=3.70e-02 BER=1.45e-02 FER=1.44e-01
Epoch 43 Train Time 38.26867985725403s

Training epoch 44, Batch 500/1000: LR=9.99e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.45e-01
Training epoch 44, Batch 1000/1000: LR=9.99e-05, Loss=3.76e-02 BER=1.48e-02 FER=1.46e-01
Epoch 44 Train Time 38.249194622039795s

Training epoch 45, Batch 500/1000: LR=9.99e-05, Loss=3.66e-02 BER=1.44e-02 FER=1.42e-01
Training epoch 45, Batch 1000/1000: LR=9.99e-05, Loss=3.65e-02 BER=1.44e-02 FER=1.42e-01
Epoch 45 Train Time 38.23674941062927s

Training epoch 46, Batch 500/1000: LR=9.99e-05, Loss=3.63e-02 BER=1.43e-02 FER=1.42e-01
Training epoch 46, Batch 1000/1000: LR=9.99e-05, Loss=3.59e-02 BER=1.41e-02 FER=1.41e-01
Epoch 46 Train Time 38.27206873893738s

Training epoch 47, Batch 500/1000: LR=9.99e-05, Loss=3.72e-02 BER=1.46e-02 FER=1.43e-01
Training epoch 47, Batch 1000/1000: LR=9.99e-05, Loss=3.67e-02 BER=1.44e-02 FER=1.42e-01
Epoch 47 Train Time 38.245163917541504s

Training epoch 48, Batch 500/1000: LR=9.99e-05, Loss=3.55e-02 BER=1.40e-02 FER=1.38e-01
Training epoch 48, Batch 1000/1000: LR=9.99e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.39e-01
Epoch 48 Train Time 38.253690242767334s

Training epoch 49, Batch 500/1000: LR=9.99e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 49, Batch 1000/1000: LR=9.99e-05, Loss=3.60e-02 BER=1.42e-02 FER=1.40e-01
Epoch 49 Train Time 38.36563324928284s

Training epoch 50, Batch 500/1000: LR=9.99e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 50, Batch 1000/1000: LR=9.99e-05, Loss=3.59e-02 BER=1.42e-02 FER=1.39e-01
Epoch 50 Train Time 38.2616810798645s

Training epoch 51, Batch 500/1000: LR=9.98e-05, Loss=3.62e-02 BER=1.44e-02 FER=1.41e-01
Training epoch 51, Batch 1000/1000: LR=9.98e-05, Loss=3.60e-02 BER=1.43e-02 FER=1.40e-01
Epoch 51 Train Time 38.28698182106018s

Training epoch 52, Batch 500/1000: LR=9.98e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.40e-01
Training epoch 52, Batch 1000/1000: LR=9.98e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.38e-01
Epoch 52 Train Time 38.27350902557373s

Training epoch 53, Batch 500/1000: LR=9.98e-05, Loss=3.61e-02 BER=1.43e-02 FER=1.39e-01
Training epoch 53, Batch 1000/1000: LR=9.98e-05, Loss=3.57e-02 BER=1.41e-02 FER=1.38e-01
Epoch 53 Train Time 38.246047258377075s

Training epoch 54, Batch 500/1000: LR=9.98e-05, Loss=3.53e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 54, Batch 1000/1000: LR=9.98e-05, Loss=3.52e-02 BER=1.39e-02 FER=1.36e-01
Epoch 54 Train Time 38.271374464035034s

Training epoch 55, Batch 500/1000: LR=9.98e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 55, Batch 1000/1000: LR=9.98e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.37e-01
Epoch 55 Train Time 38.26305866241455s

Training epoch 56, Batch 500/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.35e-01
Training epoch 56, Batch 1000/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.38e-02 FER=1.35e-01
Epoch 56 Train Time 38.2444908618927s

Training epoch 57, Batch 500/1000: LR=9.98e-05, Loss=3.57e-02 BER=1.42e-02 FER=1.39e-01
Training epoch 57, Batch 1000/1000: LR=9.98e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.38e-01
Epoch 57 Train Time 38.26452875137329s

Training epoch 58, Batch 500/1000: LR=9.98e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.35e-01
Training epoch 58, Batch 1000/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 58 Train Time 38.26038956642151s

Training epoch 59, Batch 500/1000: LR=9.98e-05, Loss=3.54e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 59, Batch 1000/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.36e-01
Epoch 59 Train Time 38.34768843650818s

Training epoch 60, Batch 500/1000: LR=9.98e-05, Loss=3.56e-02 BER=1.41e-02 FER=1.37e-01
Training epoch 60, Batch 1000/1000: LR=9.98e-05, Loss=3.55e-02 BER=1.41e-02 FER=1.37e-01
Epoch 60 Train Time 38.23544263839722s

Training epoch 61, Batch 500/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 61, Batch 1000/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.35e-01
Epoch 61 Train Time 73.76227688789368s

Training epoch 62, Batch 500/1000: LR=9.98e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.36e-01
Training epoch 62, Batch 1000/1000: LR=9.98e-05, Loss=3.52e-02 BER=1.40e-02 FER=1.36e-01
Epoch 62 Train Time 38.83948826789856s

Training epoch 63, Batch 500/1000: LR=9.98e-05, Loss=3.46e-02 BER=1.39e-02 FER=1.33e-01
Training epoch 63, Batch 1000/1000: LR=9.98e-05, Loss=3.48e-02 BER=1.39e-02 FER=1.35e-01
Epoch 63 Train Time 38.66743183135986s

Training epoch 64, Batch 500/1000: LR=9.98e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.33e-01
Training epoch 64, Batch 1000/1000: LR=9.98e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.33e-01
Epoch 64 Train Time 38.67861843109131s

Training epoch 65, Batch 500/1000: LR=9.98e-05, Loss=3.51e-02 BER=1.40e-02 FER=1.37e-01
Training epoch 65, Batch 1000/1000: LR=9.98e-05, Loss=3.49e-02 BER=1.39e-02 FER=1.36e-01
Epoch 65 Train Time 38.63500714302063s

Training epoch 66, Batch 500/1000: LR=9.97e-05, Loss=3.37e-02 BER=1.34e-02 FER=1.32e-01
Training epoch 66, Batch 1000/1000: LR=9.97e-05, Loss=3.43e-02 BER=1.37e-02 FER=1.33e-01
Epoch 66 Train Time 38.654465675354004s

Training epoch 67, Batch 500/1000: LR=9.97e-05, Loss=3.42e-02 BER=1.36e-02 FER=1.32e-01
Training epoch 67, Batch 1000/1000: LR=9.97e-05, Loss=3.45e-02 BER=1.37e-02 FER=1.34e-01
Epoch 67 Train Time 38.64184236526489s

Training epoch 68, Batch 500/1000: LR=9.97e-05, Loss=3.47e-02 BER=1.39e-02 FER=1.35e-01
Training epoch 68, Batch 1000/1000: LR=9.97e-05, Loss=3.45e-02 BER=1.38e-02 FER=1.34e-01
Epoch 68 Train Time 38.631462812423706s

Training epoch 69, Batch 500/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.33e-01
Training epoch 69, Batch 1000/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 69 Train Time 38.66153573989868s

Training epoch 70, Batch 500/1000: LR=9.97e-05, Loss=3.44e-02 BER=1.38e-02 FER=1.34e-01
Training epoch 70, Batch 1000/1000: LR=9.97e-05, Loss=3.41e-02 BER=1.36e-02 FER=1.33e-01
Epoch 70 Train Time 38.71988105773926s

Training epoch 71, Batch 500/1000: LR=9.97e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.33e-01
Training epoch 71, Batch 1000/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 71 Train Time 38.753483057022095s

Training epoch 72, Batch 500/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 72, Batch 1000/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.35e-02 FER=1.32e-01
Epoch 72 Train Time 38.636433362960815s

Training epoch 73, Batch 500/1000: LR=9.97e-05, Loss=3.43e-02 BER=1.38e-02 FER=1.33e-01
Training epoch 73, Batch 1000/1000: LR=9.97e-05, Loss=3.38e-02 BER=1.36e-02 FER=1.32e-01
Epoch 73 Train Time 38.627458810806274s

Training epoch 74, Batch 500/1000: LR=9.97e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.32e-01
Training epoch 74, Batch 1000/1000: LR=9.97e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.32e-01
Epoch 74 Train Time 38.635313272476196s

Training epoch 75, Batch 500/1000: LR=9.97e-05, Loss=3.35e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 75, Batch 1000/1000: LR=9.97e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 75 Train Time 38.63186454772949s

Training epoch 76, Batch 500/1000: LR=9.97e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 76, Batch 1000/1000: LR=9.97e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.31e-01
Epoch 76 Train Time 38.683260440826416s

Training epoch 77, Batch 500/1000: LR=9.96e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 77, Batch 1000/1000: LR=9.96e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 77 Train Time 38.66508221626282s

Training epoch 78, Batch 500/1000: LR=9.96e-05, Loss=3.42e-02 BER=1.37e-02 FER=1.32e-01
Training epoch 78, Batch 1000/1000: LR=9.96e-05, Loss=3.41e-02 BER=1.37e-02 FER=1.32e-01
Epoch 78 Train Time 38.658058643341064s

Training epoch 79, Batch 500/1000: LR=9.96e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 79, Batch 1000/1000: LR=9.96e-05, Loss=3.40e-02 BER=1.36e-02 FER=1.31e-01
Epoch 79 Train Time 38.633886098861694s

Training epoch 80, Batch 500/1000: LR=9.96e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.31e-01
Training epoch 80, Batch 1000/1000: LR=9.96e-05, Loss=3.42e-02 BER=1.38e-02 FER=1.32e-01
Epoch 80 Train Time 38.7476372718811s

Training epoch 81, Batch 500/1000: LR=9.96e-05, Loss=3.38e-02 BER=1.34e-02 FER=1.30e-01
Training epoch 81, Batch 1000/1000: LR=9.96e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.31e-01
Epoch 81 Train Time 38.608222246170044s

Training epoch 82, Batch 500/1000: LR=9.96e-05, Loss=3.38e-02 BER=1.35e-02 FER=1.31e-01
Training epoch 82, Batch 1000/1000: LR=9.96e-05, Loss=3.36e-02 BER=1.34e-02 FER=1.30e-01
Epoch 82 Train Time 38.597267150878906s

Training epoch 83, Batch 500/1000: LR=9.96e-05, Loss=3.32e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 83, Batch 1000/1000: LR=9.96e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 83 Train Time 38.227609395980835s

Training epoch 84, Batch 500/1000: LR=9.96e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.30e-01
Training epoch 84, Batch 1000/1000: LR=9.96e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.30e-01
Epoch 84 Train Time 38.25896596908569s

Training epoch 85, Batch 500/1000: LR=9.96e-05, Loss=3.33e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 85, Batch 1000/1000: LR=9.96e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 85 Train Time 38.221070289611816s

Training epoch 86, Batch 500/1000: LR=9.96e-05, Loss=3.38e-02 BER=1.36e-02 FER=1.30e-01
Training epoch 86, Batch 1000/1000: LR=9.96e-05, Loss=3.35e-02 BER=1.34e-02 FER=1.30e-01
Epoch 86 Train Time 38.23171043395996s

Training epoch 87, Batch 500/1000: LR=9.95e-05, Loss=3.40e-02 BER=1.37e-02 FER=1.31e-01
Training epoch 87, Batch 1000/1000: LR=9.95e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.30e-01
Epoch 87 Train Time 38.22241806983948s

Training epoch 88, Batch 500/1000: LR=9.95e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 88, Batch 1000/1000: LR=9.95e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Epoch 88 Train Time 38.20465350151062s

Training epoch 89, Batch 500/1000: LR=9.95e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 89, Batch 1000/1000: LR=9.95e-05, Loss=3.37e-02 BER=1.35e-02 FER=1.30e-01
Epoch 89 Train Time 38.40030121803284s

Training epoch 90, Batch 500/1000: LR=9.95e-05, Loss=3.31e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 90, Batch 1000/1000: LR=9.95e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 90 Train Time 38.28484630584717s

Training epoch 91, Batch 500/1000: LR=9.95e-05, Loss=3.36e-02 BER=1.35e-02 FER=1.28e-01
Training epoch 91, Batch 1000/1000: LR=9.95e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 91 Train Time 38.2347686290741s

Training epoch 92, Batch 500/1000: LR=9.95e-05, Loss=3.34e-02 BER=1.35e-02 FER=1.29e-01
Training epoch 92, Batch 1000/1000: LR=9.95e-05, Loss=3.35e-02 BER=1.35e-02 FER=1.29e-01
Epoch 92 Train Time 38.26196765899658s

Training epoch 93, Batch 500/1000: LR=9.95e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.27e-01
Training epoch 93, Batch 1000/1000: LR=9.95e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Epoch 93 Train Time 38.22219800949097s

Training epoch 94, Batch 500/1000: LR=9.95e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 94, Batch 1000/1000: LR=9.95e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.29e-01
Epoch 94 Train Time 38.25197410583496s

Training epoch 95, Batch 500/1000: LR=9.95e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.28e-01
Training epoch 95, Batch 1000/1000: LR=9.95e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Epoch 95 Train Time 38.24283218383789s

Training epoch 96, Batch 500/1000: LR=9.94e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 96, Batch 1000/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 96 Train Time 38.22583723068237s

Training epoch 97, Batch 500/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 97, Batch 1000/1000: LR=9.94e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.28e-01
Epoch 97 Train Time 38.23625206947327s

Training epoch 98, Batch 500/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 98, Batch 1000/1000: LR=9.94e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.27e-01
Epoch 98 Train Time 38.23029851913452s

Training epoch 99, Batch 500/1000: LR=9.94e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.28e-01
Training epoch 99, Batch 1000/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 99 Train Time 38.344905853271484s

Training epoch 100, Batch 500/1000: LR=9.94e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.25e-01
Training epoch 100, Batch 1000/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 100 Train Time 38.28359127044678s

Training epoch 101, Batch 500/1000: LR=9.94e-05, Loss=3.34e-02 BER=1.34e-02 FER=1.29e-01
Training epoch 101, Batch 1000/1000: LR=9.94e-05, Loss=3.33e-02 BER=1.34e-02 FER=1.28e-01
Epoch 101 Train Time 38.223209857940674s

Training epoch 102, Batch 500/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 102, Batch 1000/1000: LR=9.94e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 102 Train Time 38.20388960838318s

Training epoch 103, Batch 500/1000: LR=9.94e-05, Loss=3.32e-02 BER=1.33e-02 FER=1.29e-01
Training epoch 103, Batch 1000/1000: LR=9.94e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Epoch 103 Train Time 38.233062505722046s

Training epoch 104, Batch 500/1000: LR=9.94e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 104, Batch 1000/1000: LR=9.94e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 104 Train Time 38.21597695350647s

Training epoch 105, Batch 500/1000: LR=9.93e-05, Loss=3.29e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 105, Batch 1000/1000: LR=9.93e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.27e-01
Epoch 105 Train Time 38.23757028579712s

Training epoch 106, Batch 500/1000: LR=9.93e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 106, Batch 1000/1000: LR=9.93e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 106 Train Time 38.22889304161072s

Training epoch 107, Batch 500/1000: LR=9.93e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.26e-01
Training epoch 107, Batch 1000/1000: LR=9.93e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.27e-01
Epoch 107 Train Time 38.260986328125s

Training epoch 108, Batch 500/1000: LR=9.93e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 108, Batch 1000/1000: LR=9.93e-05, Loss=3.25e-02 BER=1.30e-02 FER=1.26e-01
Epoch 108 Train Time 90.2578239440918s

Training epoch 109, Batch 500/1000: LR=9.93e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 109, Batch 1000/1000: LR=9.93e-05, Loss=3.28e-02 BER=1.31e-02 FER=1.26e-01
Epoch 109 Train Time 39.01712465286255s

Training epoch 110, Batch 500/1000: LR=9.93e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 110, Batch 1000/1000: LR=9.93e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Epoch 110 Train Time 39.272409439086914s

Training epoch 111, Batch 500/1000: LR=9.93e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 111, Batch 1000/1000: LR=9.93e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 111 Train Time 39.01868939399719s

Training epoch 112, Batch 500/1000: LR=9.92e-05, Loss=3.30e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 112, Batch 1000/1000: LR=9.92e-05, Loss=3.31e-02 BER=1.33e-02 FER=1.28e-01
Epoch 112 Train Time 38.75527024269104s

Training epoch 113, Batch 500/1000: LR=9.92e-05, Loss=3.30e-02 BER=1.33e-02 FER=1.27e-01
Training epoch 113, Batch 1000/1000: LR=9.92e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.26e-01
Epoch 113 Train Time 38.26168966293335s

Training epoch 114, Batch 500/1000: LR=9.92e-05, Loss=3.26e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 114, Batch 1000/1000: LR=9.92e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 114 Train Time 38.245604515075684s

Training epoch 115, Batch 500/1000: LR=9.92e-05, Loss=3.29e-02 BER=1.32e-02 FER=1.27e-01
Training epoch 115, Batch 1000/1000: LR=9.92e-05, Loss=3.28e-02 BER=1.32e-02 FER=1.26e-01
Epoch 115 Train Time 38.23866868019104s

Training epoch 116, Batch 500/1000: LR=9.92e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 116, Batch 1000/1000: LR=9.92e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Epoch 116 Train Time 38.22830629348755s

Training epoch 117, Batch 500/1000: LR=9.92e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 117, Batch 1000/1000: LR=9.92e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 117 Train Time 38.24154591560364s

Training epoch 118, Batch 500/1000: LR=9.92e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 118, Batch 1000/1000: LR=9.92e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 118 Train Time 38.25165295600891s

Training epoch 119, Batch 500/1000: LR=9.92e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 119, Batch 1000/1000: LR=9.92e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 119 Train Time 38.24715995788574s

Training epoch 120, Batch 500/1000: LR=9.91e-05, Loss=3.27e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 120, Batch 1000/1000: LR=9.91e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.25e-01
Epoch 120 Train Time 38.2221794128418s

Training epoch 121, Batch 500/1000: LR=9.91e-05, Loss=3.31e-02 BER=1.34e-02 FER=1.28e-01
Training epoch 121, Batch 1000/1000: LR=9.91e-05, Loss=3.27e-02 BER=1.32e-02 FER=1.26e-01
Epoch 121 Train Time 38.214553356170654s

Training epoch 122, Batch 500/1000: LR=9.91e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 122, Batch 1000/1000: LR=9.91e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.24e-01
Epoch 122 Train Time 38.337751388549805s

Training epoch 123, Batch 500/1000: LR=9.91e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 123, Batch 1000/1000: LR=9.91e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 123 Train Time 38.28250503540039s

Training epoch 124, Batch 500/1000: LR=9.91e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 124, Batch 1000/1000: LR=9.91e-05, Loss=3.24e-02 BER=1.31e-02 FER=1.25e-01
Epoch 124 Train Time 38.27561378479004s

Training epoch 125, Batch 500/1000: LR=9.91e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 125, Batch 1000/1000: LR=9.91e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 125 Train Time 38.22630739212036s

Training epoch 126, Batch 500/1000: LR=9.90e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 126, Batch 1000/1000: LR=9.90e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Epoch 126 Train Time 38.21257543563843s

Training epoch 127, Batch 500/1000: LR=9.90e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 127, Batch 1000/1000: LR=9.90e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Epoch 127 Train Time 38.23989486694336s

Training epoch 128, Batch 500/1000: LR=9.90e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 128, Batch 1000/1000: LR=9.90e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 128 Train Time 38.2245192527771s

Training epoch 129, Batch 500/1000: LR=9.90e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 129, Batch 1000/1000: LR=9.90e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 129 Train Time 38.22687292098999s

Training epoch 130, Batch 500/1000: LR=9.90e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 130, Batch 1000/1000: LR=9.90e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 130 Train Time 38.27357769012451s

Training epoch 131, Batch 500/1000: LR=9.90e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.26e-01
Training epoch 131, Batch 1000/1000: LR=9.90e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.25e-01
Epoch 131 Train Time 38.28665781021118s

Training epoch 132, Batch 500/1000: LR=9.90e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.25e-01
Training epoch 132, Batch 1000/1000: LR=9.90e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.23e-01
Epoch 132 Train Time 38.372241497039795s

Training epoch 133, Batch 500/1000: LR=9.89e-05, Loss=3.22e-02 BER=1.28e-02 FER=1.23e-01
Training epoch 133, Batch 1000/1000: LR=9.89e-05, Loss=3.23e-02 BER=1.29e-02 FER=1.23e-01
Epoch 133 Train Time 38.249255657196045s

Training epoch 134, Batch 500/1000: LR=9.89e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 134, Batch 1000/1000: LR=9.89e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.24e-01
Epoch 134 Train Time 38.206430435180664s

Training epoch 135, Batch 500/1000: LR=9.89e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 135, Batch 1000/1000: LR=9.89e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Epoch 135 Train Time 38.213390827178955s

Training epoch 136, Batch 500/1000: LR=9.89e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 136, Batch 1000/1000: LR=9.89e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 136 Train Time 38.26658844947815s

Training epoch 137, Batch 500/1000: LR=9.89e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 137, Batch 1000/1000: LR=9.89e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 137 Train Time 38.264294385910034s

Training epoch 138, Batch 500/1000: LR=9.89e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 138, Batch 1000/1000: LR=9.89e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 138 Train Time 38.21105456352234s

Training epoch 139, Batch 500/1000: LR=9.88e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 139, Batch 1000/1000: LR=9.88e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Epoch 139 Train Time 38.244383335113525s

Training epoch 140, Batch 500/1000: LR=9.88e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 140, Batch 1000/1000: LR=9.88e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 140 Train Time 38.254151582717896s

Training epoch 141, Batch 500/1000: LR=9.88e-05, Loss=3.21e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 141, Batch 1000/1000: LR=9.88e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 141 Train Time 38.37758469581604s

Training epoch 142, Batch 500/1000: LR=9.88e-05, Loss=3.26e-02 BER=1.32e-02 FER=1.26e-01
Training epoch 142, Batch 1000/1000: LR=9.88e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Epoch 142 Train Time 38.21074366569519s

Training epoch 143, Batch 500/1000: LR=9.88e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 143, Batch 1000/1000: LR=9.88e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 143 Train Time 38.197078704833984s

Training epoch 144, Batch 500/1000: LR=9.88e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 144, Batch 1000/1000: LR=9.88e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Epoch 144 Train Time 38.211751222610474s

Training epoch 145, Batch 500/1000: LR=9.87e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.25e-01
Training epoch 145, Batch 1000/1000: LR=9.87e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Epoch 145 Train Time 38.24575066566467s

Training epoch 146, Batch 500/1000: LR=9.87e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 146, Batch 1000/1000: LR=9.87e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.24e-01
Epoch 146 Train Time 38.221423387527466s

Training epoch 147, Batch 500/1000: LR=9.87e-05, Loss=3.29e-02 BER=1.33e-02 FER=1.25e-01
Training epoch 147, Batch 1000/1000: LR=9.87e-05, Loss=3.25e-02 BER=1.31e-02 FER=1.24e-01
Epoch 147 Train Time 38.240214824676514s

Training epoch 148, Batch 500/1000: LR=9.87e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Training epoch 148, Batch 1000/1000: LR=9.87e-05, Loss=3.24e-02 BER=1.30e-02 FER=1.23e-01
Epoch 148 Train Time 38.208240032196045s

Training epoch 149, Batch 500/1000: LR=9.87e-05, Loss=3.23e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 149, Batch 1000/1000: LR=9.87e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.22e-01
Epoch 149 Train Time 38.22206974029541s

Training epoch 150, Batch 500/1000: LR=9.87e-05, Loss=3.26e-02 BER=1.31e-02 FER=1.24e-01
Training epoch 150, Batch 1000/1000: LR=9.87e-05, Loss=3.23e-02 BER=1.30e-02 FER=1.23e-01
Epoch 150 Train Time 38.26877951622009s

Training epoch 151, Batch 500/1000: LR=9.86e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 151, Batch 1000/1000: LR=9.86e-05, Loss=3.20e-02 BER=1.28e-02 FER=1.22e-01
Epoch 151 Train Time 38.340051889419556s

Training epoch 152, Batch 500/1000: LR=9.86e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 152, Batch 1000/1000: LR=9.86e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Epoch 152 Train Time 38.22479820251465s

Training epoch 153, Batch 500/1000: LR=9.86e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 153, Batch 1000/1000: LR=9.86e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.23e-01
Epoch 153 Train Time 38.23230981826782s

Training epoch 154, Batch 500/1000: LR=9.86e-05, Loss=3.22e-02 BER=1.30e-02 FER=1.24e-01
Training epoch 154, Batch 1000/1000: LR=9.86e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Epoch 154 Train Time 38.240679025650024s

Training epoch 155, Batch 500/1000: LR=9.86e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.23e-01
Training epoch 155, Batch 1000/1000: LR=9.86e-05, Loss=3.21e-02 BER=1.30e-02 FER=1.23e-01
Epoch 155 Train Time 38.24442172050476s

Training epoch 156, Batch 500/1000: LR=9.85e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.22e-01
Training epoch 156, Batch 1000/1000: LR=9.85e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 156 Train Time 56.73801898956299s

Training epoch 157, Batch 500/1000: LR=9.85e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.24e-01
Training epoch 157, Batch 1000/1000: LR=9.85e-05, Loss=3.22e-02 BER=1.29e-02 FER=1.23e-01
Epoch 157 Train Time 38.89769458770752s

Training epoch 158, Batch 500/1000: LR=9.85e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 158, Batch 1000/1000: LR=9.85e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 158 Train Time 38.68423771858215s

Training epoch 159, Batch 500/1000: LR=9.85e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 159, Batch 1000/1000: LR=9.85e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 159 Train Time 38.68369936943054s

Training epoch 160, Batch 500/1000: LR=9.85e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.22e-01
Training epoch 160, Batch 1000/1000: LR=9.85e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 160 Train Time 38.801278829574585s

Training epoch 161, Batch 500/1000: LR=9.84e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 161, Batch 1000/1000: LR=9.84e-05, Loss=3.18e-02 BER=1.27e-02 FER=1.21e-01
Epoch 161 Train Time 38.65083694458008s

Training epoch 162, Batch 500/1000: LR=9.84e-05, Loss=3.19e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 162, Batch 1000/1000: LR=9.84e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Epoch 162 Train Time 38.64136838912964s

Training epoch 163, Batch 500/1000: LR=9.84e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 163, Batch 1000/1000: LR=9.84e-05, Loss=3.19e-02 BER=1.28e-02 FER=1.22e-01
Epoch 163 Train Time 38.64599895477295s

Training epoch 164, Batch 500/1000: LR=9.84e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 164, Batch 1000/1000: LR=9.84e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 164 Train Time 38.64537334442139s

Training epoch 165, Batch 500/1000: LR=9.84e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 165, Batch 1000/1000: LR=9.84e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 165 Train Time 38.651345014572144s

Training epoch 166, Batch 500/1000: LR=9.83e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 166, Batch 1000/1000: LR=9.83e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 166 Train Time 38.652876138687134s

Training epoch 167, Batch 500/1000: LR=9.83e-05, Loss=3.20e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 167, Batch 1000/1000: LR=9.83e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Epoch 167 Train Time 38.634164810180664s

Training epoch 168, Batch 500/1000: LR=9.83e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.19e-01
Training epoch 168, Batch 1000/1000: LR=9.83e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 168 Train Time 38.69805860519409s

Training epoch 169, Batch 500/1000: LR=9.83e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 169, Batch 1000/1000: LR=9.83e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 169 Train Time 38.798062801361084s

Training epoch 170, Batch 500/1000: LR=9.83e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 170, Batch 1000/1000: LR=9.83e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.19e-01
Epoch 170 Train Time 38.688316106796265s

Training epoch 171, Batch 500/1000: LR=9.82e-05, Loss=3.16e-02 BER=1.26e-02 FER=1.21e-01
Training epoch 171, Batch 1000/1000: LR=9.82e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.21e-01
Epoch 171 Train Time 38.66564679145813s

Training epoch 172, Batch 500/1000: LR=9.82e-05, Loss=3.15e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 172, Batch 1000/1000: LR=9.82e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 172 Train Time 38.690816164016724s

Training epoch 173, Batch 500/1000: LR=9.82e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 173, Batch 1000/1000: LR=9.82e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 173 Train Time 38.67376971244812s

Training epoch 174, Batch 500/1000: LR=9.82e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 174, Batch 1000/1000: LR=9.82e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 174 Train Time 38.644113302230835s

Training epoch 175, Batch 500/1000: LR=9.82e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.22e-01
Training epoch 175, Batch 1000/1000: LR=9.82e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 175 Train Time 38.66408681869507s

Training epoch 176, Batch 500/1000: LR=9.81e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 176, Batch 1000/1000: LR=9.81e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 176 Train Time 38.65640306472778s

Training epoch 177, Batch 500/1000: LR=9.81e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 177, Batch 1000/1000: LR=9.81e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 177 Train Time 38.663278102874756s

Training epoch 178, Batch 500/1000: LR=9.81e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 178, Batch 1000/1000: LR=9.81e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 178 Train Time 38.62770986557007s

Training epoch 179, Batch 500/1000: LR=9.81e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 179, Batch 1000/1000: LR=9.81e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 179 Train Time 39.0525598526001s

Training epoch 180, Batch 500/1000: LR=9.81e-05, Loss=3.18e-02 BER=1.29e-02 FER=1.22e-01
Training epoch 180, Batch 1000/1000: LR=9.81e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Epoch 180 Train Time 38.47489857673645s

Training epoch 181, Batch 500/1000: LR=9.80e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 181, Batch 1000/1000: LR=9.80e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 181 Train Time 38.29970908164978s

Training epoch 182, Batch 500/1000: LR=9.80e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 182, Batch 1000/1000: LR=9.80e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 182 Train Time 38.27197551727295s

Training epoch 183, Batch 500/1000: LR=9.80e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 183, Batch 1000/1000: LR=9.80e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 183 Train Time 38.27048587799072s

Training epoch 184, Batch 500/1000: LR=9.80e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 184, Batch 1000/1000: LR=9.80e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.21e-01
Epoch 184 Train Time 38.26663112640381s

Training epoch 185, Batch 500/1000: LR=9.79e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 185, Batch 1000/1000: LR=9.79e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 185 Train Time 38.252702474594116s

Training epoch 186, Batch 500/1000: LR=9.79e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 186, Batch 1000/1000: LR=9.79e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Epoch 186 Train Time 38.26728940010071s

Training epoch 187, Batch 500/1000: LR=9.79e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 187, Batch 1000/1000: LR=9.79e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.19e-01
Epoch 187 Train Time 38.27717852592468s

Training epoch 188, Batch 500/1000: LR=9.79e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 188, Batch 1000/1000: LR=9.79e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 188 Train Time 38.286855697631836s

Training epoch 189, Batch 500/1000: LR=9.79e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Training epoch 189, Batch 1000/1000: LR=9.79e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.21e-01
Epoch 189 Train Time 38.35304880142212s

Training epoch 190, Batch 500/1000: LR=9.78e-05, Loss=3.14e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 190, Batch 1000/1000: LR=9.78e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 190 Train Time 38.261937856674194s

Training epoch 191, Batch 500/1000: LR=9.78e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 191, Batch 1000/1000: LR=9.78e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 191 Train Time 38.24422883987427s

Training epoch 192, Batch 500/1000: LR=9.78e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.21e-01
Training epoch 192, Batch 1000/1000: LR=9.78e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.20e-01
Epoch 192 Train Time 38.260624170303345s

Training epoch 193, Batch 500/1000: LR=9.78e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 193, Batch 1000/1000: LR=9.78e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 193 Train Time 38.37595057487488s

Training epoch 194, Batch 500/1000: LR=9.77e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 194, Batch 1000/1000: LR=9.77e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 194 Train Time 38.25817322731018s

Training epoch 195, Batch 500/1000: LR=9.77e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 195, Batch 1000/1000: LR=9.77e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.20e-01
Epoch 195 Train Time 38.287517070770264s

Training epoch 196, Batch 500/1000: LR=9.77e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 196, Batch 1000/1000: LR=9.77e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 196 Train Time 38.43399095535278s

Training epoch 197, Batch 500/1000: LR=9.77e-05, Loss=3.18e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 197, Batch 1000/1000: LR=9.77e-05, Loss=3.17e-02 BER=1.27e-02 FER=1.20e-01
Epoch 197 Train Time 40.37790489196777s

Training epoch 198, Batch 500/1000: LR=9.76e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 198, Batch 1000/1000: LR=9.76e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 198 Train Time 38.90527534484863s

Training epoch 199, Batch 500/1000: LR=9.76e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 199, Batch 1000/1000: LR=9.76e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Epoch 199 Train Time 38.72026562690735s

Training epoch 200, Batch 500/1000: LR=9.76e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 200, Batch 1000/1000: LR=9.76e-05, Loss=3.14e-02 BER=1.25e-02 FER=1.20e-01
Epoch 200 Train Time 38.41055083274841s

Training epoch 201, Batch 500/1000: LR=9.76e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 201, Batch 1000/1000: LR=9.76e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 201 Train Time 38.366191387176514s

Training epoch 202, Batch 500/1000: LR=9.76e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 202, Batch 1000/1000: LR=9.76e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Epoch 202 Train Time 38.780961751937866s

Training epoch 203, Batch 500/1000: LR=9.75e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 203, Batch 1000/1000: LR=9.75e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 203 Train Time 38.56824445724487s

Training epoch 204, Batch 500/1000: LR=9.75e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 204, Batch 1000/1000: LR=9.75e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 204 Train Time 38.45554852485657s

Training epoch 205, Batch 500/1000: LR=9.75e-05, Loss=3.17e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 205, Batch 1000/1000: LR=9.75e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.21e-01
Epoch 205 Train Time 38.42205572128296s

Training epoch 206, Batch 500/1000: LR=9.75e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 206, Batch 1000/1000: LR=9.75e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 206 Train Time 38.37988257408142s

Training epoch 207, Batch 500/1000: LR=9.74e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 207, Batch 1000/1000: LR=9.74e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 207 Train Time 38.54884314537048s

Training epoch 208, Batch 500/1000: LR=9.74e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 208, Batch 1000/1000: LR=9.74e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.18e-01
Epoch 208 Train Time 38.34352684020996s

Training epoch 209, Batch 500/1000: LR=9.74e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 209, Batch 1000/1000: LR=9.74e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 209 Train Time 38.33387041091919s

Training epoch 210, Batch 500/1000: LR=9.74e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 210, Batch 1000/1000: LR=9.74e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 210 Train Time 38.33401012420654s

Training epoch 211, Batch 500/1000: LR=9.73e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.18e-01
Training epoch 211, Batch 1000/1000: LR=9.73e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 211 Train Time 38.35160946846008s

Training epoch 212, Batch 500/1000: LR=9.73e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 212, Batch 1000/1000: LR=9.73e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Epoch 212 Train Time 38.374836683273315s

Training epoch 213, Batch 500/1000: LR=9.73e-05, Loss=3.16e-02 BER=1.28e-02 FER=1.21e-01
Training epoch 213, Batch 1000/1000: LR=9.73e-05, Loss=3.15e-02 BER=1.27e-02 FER=1.20e-01
Epoch 213 Train Time 38.40691375732422s

Training epoch 214, Batch 500/1000: LR=9.73e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 214, Batch 1000/1000: LR=9.73e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 214 Train Time 38.26870822906494s

Training epoch 215, Batch 500/1000: LR=9.72e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 215, Batch 1000/1000: LR=9.72e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 215 Train Time 38.2892427444458s

Training epoch 216, Batch 500/1000: LR=9.72e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 216, Batch 1000/1000: LR=9.72e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.20e-01
Epoch 216 Train Time 38.3775634765625s

Training epoch 217, Batch 500/1000: LR=9.72e-05, Loss=3.13e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 217, Batch 1000/1000: LR=9.72e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 217 Train Time 38.366235971450806s

Training epoch 218, Batch 500/1000: LR=9.72e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 218, Batch 1000/1000: LR=9.72e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 218 Train Time 38.2969446182251s

Training epoch 219, Batch 500/1000: LR=9.71e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 219, Batch 1000/1000: LR=9.71e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 219 Train Time 38.30494713783264s

Training epoch 220, Batch 500/1000: LR=9.71e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 220, Batch 1000/1000: LR=9.71e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 220 Train Time 38.340015172958374s

Training epoch 221, Batch 500/1000: LR=9.71e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 221, Batch 1000/1000: LR=9.71e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 221 Train Time 38.32228636741638s

Training epoch 222, Batch 500/1000: LR=9.70e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 222, Batch 1000/1000: LR=9.70e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 222 Train Time 38.30581760406494s

Training epoch 223, Batch 500/1000: LR=9.70e-05, Loss=3.15e-02 BER=1.28e-02 FER=1.20e-01
Training epoch 223, Batch 1000/1000: LR=9.70e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.19e-01
Epoch 223 Train Time 38.32784724235535s

Training epoch 224, Batch 500/1000: LR=9.70e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 224, Batch 1000/1000: LR=9.70e-05, Loss=3.12e-02 BER=1.25e-02 FER=1.19e-01
Epoch 224 Train Time 38.290820360183716s

Training epoch 225, Batch 500/1000: LR=9.70e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 225, Batch 1000/1000: LR=9.70e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 225 Train Time 38.30378770828247s

Training epoch 226, Batch 500/1000: LR=9.69e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 226, Batch 1000/1000: LR=9.69e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.18e-01
Epoch 226 Train Time 38.27435088157654s

Training epoch 227, Batch 500/1000: LR=9.69e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 227, Batch 1000/1000: LR=9.69e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 227 Train Time 38.2955060005188s

Training epoch 228, Batch 500/1000: LR=9.69e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 228, Batch 1000/1000: LR=9.69e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 228 Train Time 38.27825117111206s

Training epoch 229, Batch 500/1000: LR=9.69e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 229, Batch 1000/1000: LR=9.69e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.19e-01
Epoch 229 Train Time 38.42507719993591s

Training epoch 230, Batch 500/1000: LR=9.68e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 230, Batch 1000/1000: LR=9.68e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 230 Train Time 38.33661651611328s

Training epoch 231, Batch 500/1000: LR=9.68e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.19e-01
Training epoch 231, Batch 1000/1000: LR=9.68e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Epoch 231 Train Time 38.30761456489563s

Training epoch 232, Batch 500/1000: LR=9.68e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 232, Batch 1000/1000: LR=9.68e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 232 Train Time 38.309537172317505s

Training epoch 233, Batch 500/1000: LR=9.67e-05, Loss=3.16e-02 BER=1.27e-02 FER=1.20e-01
Training epoch 233, Batch 1000/1000: LR=9.67e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 233 Train Time 38.38548135757446s

Training epoch 234, Batch 500/1000: LR=9.67e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 234, Batch 1000/1000: LR=9.67e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Epoch 234 Train Time 38.32702660560608s

Training epoch 235, Batch 500/1000: LR=9.67e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 235, Batch 1000/1000: LR=9.67e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 235 Train Time 38.30494284629822s

Training epoch 236, Batch 500/1000: LR=9.67e-05, Loss=3.16e-02 BER=1.26e-02 FER=1.20e-01
Training epoch 236, Batch 1000/1000: LR=9.67e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.19e-01
Epoch 236 Train Time 38.30983924865723s

Training epoch 237, Batch 500/1000: LR=9.66e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 237, Batch 1000/1000: LR=9.66e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.17e-01
Epoch 237 Train Time 38.3085777759552s

Training epoch 238, Batch 500/1000: LR=9.66e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 238, Batch 1000/1000: LR=9.66e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 238 Train Time 38.314136266708374s

Training epoch 239, Batch 500/1000: LR=9.66e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 239, Batch 1000/1000: LR=9.66e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 239 Train Time 38.39995622634888s

Training epoch 240, Batch 500/1000: LR=9.66e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 240, Batch 1000/1000: LR=9.66e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 240 Train Time 38.28537321090698s

Training epoch 241, Batch 500/1000: LR=9.65e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 241, Batch 1000/1000: LR=9.65e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 241 Train Time 38.24577069282532s

Training epoch 242, Batch 500/1000: LR=9.65e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 242, Batch 1000/1000: LR=9.65e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 242 Train Time 38.3099799156189s

Training epoch 243, Batch 500/1000: LR=9.65e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 243, Batch 1000/1000: LR=9.65e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Epoch 243 Train Time 38.31463146209717s

Training epoch 244, Batch 500/1000: LR=9.64e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.19e-01
Training epoch 244, Batch 1000/1000: LR=9.64e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 244 Train Time 38.319809675216675s

Training epoch 245, Batch 500/1000: LR=9.64e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 245, Batch 1000/1000: LR=9.64e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 245 Train Time 74.59600925445557s

Training epoch 246, Batch 500/1000: LR=9.64e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 246, Batch 1000/1000: LR=9.64e-05, Loss=3.13e-02 BER=1.26e-02 FER=1.18e-01
Epoch 246 Train Time 38.61213183403015s

Training epoch 247, Batch 500/1000: LR=9.64e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 247, Batch 1000/1000: LR=9.64e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 247 Train Time 38.37872338294983s

Training epoch 248, Batch 500/1000: LR=9.63e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 248, Batch 1000/1000: LR=9.63e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Epoch 248 Train Time 38.26719784736633s

Training epoch 249, Batch 500/1000: LR=9.63e-05, Loss=3.10e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 249, Batch 1000/1000: LR=9.63e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 249 Train Time 38.26503801345825s

Training epoch 250, Batch 500/1000: LR=9.63e-05, Loss=3.14e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 250, Batch 1000/1000: LR=9.63e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 250 Train Time 38.27639055252075s

Training epoch 251, Batch 500/1000: LR=9.62e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 251, Batch 1000/1000: LR=9.62e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 251 Train Time 38.25022268295288s

Training epoch 252, Batch 500/1000: LR=9.62e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 252, Batch 1000/1000: LR=9.62e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 252 Train Time 38.24013876914978s

Training epoch 253, Batch 500/1000: LR=9.62e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 253, Batch 1000/1000: LR=9.62e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 253 Train Time 38.747952938079834s

Training epoch 254, Batch 500/1000: LR=9.61e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Training epoch 254, Batch 1000/1000: LR=9.61e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 254 Train Time 38.271140575408936s

Training epoch 255, Batch 500/1000: LR=9.61e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 255, Batch 1000/1000: LR=9.61e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 255 Train Time 38.25900340080261s

Training epoch 256, Batch 500/1000: LR=9.61e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 256, Batch 1000/1000: LR=9.61e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 256 Train Time 38.43127107620239s

Training epoch 257, Batch 500/1000: LR=9.61e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 257, Batch 1000/1000: LR=9.61e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 257 Train Time 38.271023988723755s

Training epoch 258, Batch 500/1000: LR=9.60e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 258, Batch 1000/1000: LR=9.60e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Epoch 258 Train Time 38.25352597236633s

Training epoch 259, Batch 500/1000: LR=9.60e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 259, Batch 1000/1000: LR=9.60e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.17e-01
Epoch 259 Train Time 38.25863337516785s

Training epoch 260, Batch 500/1000: LR=9.60e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 260, Batch 1000/1000: LR=9.60e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 260 Train Time 38.290982484817505s

Training epoch 261, Batch 500/1000: LR=9.59e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 261, Batch 1000/1000: LR=9.59e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Epoch 261 Train Time 38.28721809387207s

Training epoch 262, Batch 500/1000: LR=9.59e-05, Loss=3.14e-02 BER=1.26e-02 FER=1.18e-01
Training epoch 262, Batch 1000/1000: LR=9.59e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 262 Train Time 38.25260853767395s

Training epoch 263, Batch 500/1000: LR=9.59e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 263, Batch 1000/1000: LR=9.59e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 263 Train Time 38.26684308052063s

Training epoch 264, Batch 500/1000: LR=9.58e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 264, Batch 1000/1000: LR=9.58e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 264 Train Time 38.31579327583313s

Training epoch 265, Batch 500/1000: LR=9.58e-05, Loss=3.04e-02 BER=1.21e-02 FER=1.16e-01
Training epoch 265, Batch 1000/1000: LR=9.58e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.17e-01
Epoch 265 Train Time 38.240209102630615s

Training epoch 266, Batch 500/1000: LR=9.58e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 266, Batch 1000/1000: LR=9.58e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 266 Train Time 38.247318267822266s

Training epoch 267, Batch 500/1000: LR=9.57e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 267, Batch 1000/1000: LR=9.57e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 267 Train Time 38.2191743850708s

Training epoch 268, Batch 500/1000: LR=9.57e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 268, Batch 1000/1000: LR=9.57e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 268 Train Time 38.24779677391052s

Training epoch 269, Batch 500/1000: LR=9.57e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 269, Batch 1000/1000: LR=9.57e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 269 Train Time 38.25789785385132s

Training epoch 270, Batch 500/1000: LR=9.56e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 270, Batch 1000/1000: LR=9.56e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Epoch 270 Train Time 38.24359083175659s

Training epoch 271, Batch 500/1000: LR=9.56e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 271, Batch 1000/1000: LR=9.56e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 271 Train Time 38.23513078689575s

Training epoch 272, Batch 500/1000: LR=9.56e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 272, Batch 1000/1000: LR=9.56e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 272 Train Time 38.27606749534607s

Training epoch 273, Batch 500/1000: LR=9.56e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 273, Batch 1000/1000: LR=9.56e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 273 Train Time 38.32784962654114s

Training epoch 274, Batch 500/1000: LR=9.55e-05, Loss=3.07e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 274, Batch 1000/1000: LR=9.55e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 274 Train Time 38.327658891677856s

Training epoch 275, Batch 500/1000: LR=9.55e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 275, Batch 1000/1000: LR=9.55e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.18e-01
Epoch 275 Train Time 38.364628314971924s

Training epoch 276, Batch 500/1000: LR=9.55e-05, Loss=3.12e-02 BER=1.26e-02 FER=1.19e-01
Training epoch 276, Batch 1000/1000: LR=9.55e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Epoch 276 Train Time 38.278483152389526s

Training epoch 277, Batch 500/1000: LR=9.54e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 277, Batch 1000/1000: LR=9.54e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Epoch 277 Train Time 38.2752206325531s

Training epoch 278, Batch 500/1000: LR=9.54e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 278, Batch 1000/1000: LR=9.54e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.17e-01
Epoch 278 Train Time 38.23353862762451s

Training epoch 279, Batch 500/1000: LR=9.54e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 279, Batch 1000/1000: LR=9.54e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 279 Train Time 38.211625814437866s

Training epoch 280, Batch 500/1000: LR=9.53e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 280, Batch 1000/1000: LR=9.53e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 280 Train Time 38.25302839279175s

Training epoch 281, Batch 500/1000: LR=9.53e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 281, Batch 1000/1000: LR=9.53e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Epoch 281 Train Time 38.27512860298157s

Training epoch 282, Batch 500/1000: LR=9.53e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 282, Batch 1000/1000: LR=9.53e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 282 Train Time 38.25394415855408s

Training epoch 283, Batch 500/1000: LR=9.52e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 283, Batch 1000/1000: LR=9.52e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 283 Train Time 38.40179181098938s

Training epoch 284, Batch 500/1000: LR=9.52e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 284, Batch 1000/1000: LR=9.52e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 284 Train Time 38.27212929725647s

Training epoch 285, Batch 500/1000: LR=9.52e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 285, Batch 1000/1000: LR=9.52e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 285 Train Time 38.246028900146484s

Training epoch 286, Batch 500/1000: LR=9.51e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 286, Batch 1000/1000: LR=9.51e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Epoch 286 Train Time 38.316243171691895s

Training epoch 287, Batch 500/1000: LR=9.51e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 287, Batch 1000/1000: LR=9.51e-05, Loss=3.11e-02 BER=1.26e-02 FER=1.18e-01
Epoch 287 Train Time 38.254968881607056s

Training epoch 288, Batch 500/1000: LR=9.51e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 288, Batch 1000/1000: LR=9.51e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 288 Train Time 38.229453802108765s

Training epoch 289, Batch 500/1000: LR=9.50e-05, Loss=3.10e-02 BER=1.25e-02 FER=1.18e-01
Training epoch 289, Batch 1000/1000: LR=9.50e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Epoch 289 Train Time 38.21575903892517s

Training epoch 290, Batch 500/1000: LR=9.50e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 290, Batch 1000/1000: LR=9.50e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.16e-01
Epoch 290 Train Time 38.32331347465515s

Training epoch 291, Batch 500/1000: LR=9.50e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 291, Batch 1000/1000: LR=9.50e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 291 Train Time 38.26168084144592s

Training epoch 292, Batch 500/1000: LR=9.49e-05, Loss=3.13e-02 BER=1.27e-02 FER=1.19e-01
Training epoch 292, Batch 1000/1000: LR=9.49e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.18e-01
Epoch 292 Train Time 206.74327278137207s

Training epoch 293, Batch 500/1000: LR=9.49e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 293, Batch 1000/1000: LR=9.49e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 293 Train Time 39.03465557098389s

Training epoch 294, Batch 500/1000: LR=9.48e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 294, Batch 1000/1000: LR=9.48e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 294 Train Time 38.7758469581604s

Training epoch 295, Batch 500/1000: LR=9.48e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 295, Batch 1000/1000: LR=9.48e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Epoch 295 Train Time 38.678459882736206s

Training epoch 296, Batch 500/1000: LR=9.48e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 296, Batch 1000/1000: LR=9.48e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 296 Train Time 38.66982078552246s

Training epoch 297, Batch 500/1000: LR=9.47e-05, Loss=3.08e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 297, Batch 1000/1000: LR=9.47e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 297 Train Time 38.69285225868225s

Training epoch 298, Batch 500/1000: LR=9.47e-05, Loss=3.11e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 298, Batch 1000/1000: LR=9.47e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 298 Train Time 38.6216721534729s

Training epoch 299, Batch 500/1000: LR=9.47e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 299, Batch 1000/1000: LR=9.47e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 299 Train Time 38.62886834144592s

Training epoch 300, Batch 500/1000: LR=9.46e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Training epoch 300, Batch 1000/1000: LR=9.46e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 300 Train Time 38.668325662612915s


Test Loss 4: 9.57e-03 5: 1.07e-03 6: 4.86e-05
Test FER 4: 4.32e-02 5: 4.82e-03 6: 2.38e-04
Test BER 4: 3.46e-03 5: 3.38e-04 6: 1.16e-05
Test -ln(BER) 4: 5.67e+00 5: 7.99e+00 6: 1.14e+01
# of testing samples: [100352.0, 100352.0, 423936.0]
 Test Time 117.42814564704895 s

Training epoch 301, Batch 500/1000: LR=9.46e-05, Loss=3.09e-02 BER=1.24e-02 FER=1.17e-01
Training epoch 301, Batch 1000/1000: LR=9.46e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 301 Train Time 38.665212869644165s

Training epoch 302, Batch 500/1000: LR=9.46e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 302, Batch 1000/1000: LR=9.46e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Epoch 302 Train Time 38.64124274253845s

Training epoch 303, Batch 500/1000: LR=9.45e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 303, Batch 1000/1000: LR=9.45e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 303 Train Time 39.06834554672241s

Training epoch 304, Batch 500/1000: LR=9.45e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 304, Batch 1000/1000: LR=9.45e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 304 Train Time 38.83466410636902s

Training epoch 305, Batch 500/1000: LR=9.45e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 305, Batch 1000/1000: LR=9.45e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 305 Train Time 38.708667278289795s

Training epoch 306, Batch 500/1000: LR=9.44e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 306, Batch 1000/1000: LR=9.44e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 306 Train Time 38.67635369300842s

Training epoch 307, Batch 500/1000: LR=9.44e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 307, Batch 1000/1000: LR=9.44e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 307 Train Time 38.70201659202576s

Training epoch 308, Batch 500/1000: LR=9.44e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 308, Batch 1000/1000: LR=9.44e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Epoch 308 Train Time 38.679481744766235s

Training epoch 309, Batch 500/1000: LR=9.43e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 309, Batch 1000/1000: LR=9.43e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 309 Train Time 38.67164158821106s

Training epoch 310, Batch 500/1000: LR=9.43e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 310, Batch 1000/1000: LR=9.43e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.17e-01
Epoch 310 Train Time 39.15481758117676s

Training epoch 311, Batch 500/1000: LR=9.42e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 311, Batch 1000/1000: LR=9.42e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 311 Train Time 38.883890867233276s

Training epoch 312, Batch 500/1000: LR=9.42e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 312, Batch 1000/1000: LR=9.42e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.16e-01
Epoch 312 Train Time 38.67090916633606s

Training epoch 313, Batch 500/1000: LR=9.42e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 313, Batch 1000/1000: LR=9.42e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 313 Train Time 38.676852226257324s

Training epoch 314, Batch 500/1000: LR=9.41e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 314, Batch 1000/1000: LR=9.41e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 314 Train Time 38.645660400390625s

Training epoch 315, Batch 500/1000: LR=9.41e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 315, Batch 1000/1000: LR=9.41e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Epoch 315 Train Time 38.69488263130188s

Training epoch 316, Batch 500/1000: LR=9.41e-05, Loss=3.08e-02 BER=1.23e-02 FER=1.16e-01
Training epoch 316, Batch 1000/1000: LR=9.41e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.16e-01
Epoch 316 Train Time 38.6535918712616s

Training epoch 317, Batch 500/1000: LR=9.40e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 317, Batch 1000/1000: LR=9.40e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 317 Train Time 38.6611647605896s

Training epoch 318, Batch 500/1000: LR=9.40e-05, Loss=3.07e-02 BER=1.23e-02 FER=1.17e-01
Training epoch 318, Batch 1000/1000: LR=9.40e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.16e-01
Epoch 318 Train Time 38.717997312545776s

Training epoch 319, Batch 500/1000: LR=9.40e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 319, Batch 1000/1000: LR=9.40e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Epoch 319 Train Time 38.69955587387085s

Training epoch 320, Batch 500/1000: LR=9.39e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.15e-01
Training epoch 320, Batch 1000/1000: LR=9.39e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.17e-01
Epoch 320 Train Time 38.78059959411621s

Training epoch 321, Batch 500/1000: LR=9.39e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 321, Batch 1000/1000: LR=9.39e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 321 Train Time 38.703243017196655s

Training epoch 322, Batch 500/1000: LR=9.38e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 322, Batch 1000/1000: LR=9.38e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.15e-01
Epoch 322 Train Time 38.656049728393555s

Training epoch 323, Batch 500/1000: LR=9.38e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 323, Batch 1000/1000: LR=9.38e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.15e-01
Epoch 323 Train Time 38.65731167793274s

Training epoch 324, Batch 500/1000: LR=9.38e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.17e-01
Training epoch 324, Batch 1000/1000: LR=9.38e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Epoch 324 Train Time 38.70421552658081s

Training epoch 325, Batch 500/1000: LR=9.37e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 325, Batch 1000/1000: LR=9.37e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 325 Train Time 38.67500638961792s

Training epoch 326, Batch 500/1000: LR=9.37e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 326, Batch 1000/1000: LR=9.37e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 326 Train Time 38.68173265457153s

Training epoch 327, Batch 500/1000: LR=9.37e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 327, Batch 1000/1000: LR=9.37e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Epoch 327 Train Time 38.40818548202515s

Training epoch 328, Batch 500/1000: LR=9.36e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 328, Batch 1000/1000: LR=9.36e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 328 Train Time 38.30021929740906s

Training epoch 329, Batch 500/1000: LR=9.36e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 329, Batch 1000/1000: LR=9.36e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 329 Train Time 38.32284951210022s

Training epoch 330, Batch 500/1000: LR=9.35e-05, Loss=3.09e-02 BER=1.25e-02 FER=1.16e-01
Training epoch 330, Batch 1000/1000: LR=9.35e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 330 Train Time 38.38395380973816s

Training epoch 331, Batch 500/1000: LR=9.35e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 331, Batch 1000/1000: LR=9.35e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 331 Train Time 38.3143424987793s

Training epoch 332, Batch 500/1000: LR=9.35e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 332, Batch 1000/1000: LR=9.35e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 332 Train Time 38.282207012176514s

Training epoch 333, Batch 500/1000: LR=9.34e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 333, Batch 1000/1000: LR=9.34e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 333 Train Time 38.28667712211609s

Training epoch 334, Batch 500/1000: LR=9.34e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 334, Batch 1000/1000: LR=9.34e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 334 Train Time 38.295109272003174s

Training epoch 335, Batch 500/1000: LR=9.33e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 335, Batch 1000/1000: LR=9.33e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Epoch 335 Train Time 38.289695024490356s

Training epoch 336, Batch 500/1000: LR=9.33e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.16e-01
Training epoch 336, Batch 1000/1000: LR=9.33e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.16e-01
Epoch 336 Train Time 84.08698177337646s

Training epoch 337, Batch 500/1000: LR=9.33e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 337, Batch 1000/1000: LR=9.33e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 337 Train Time 39.36440849304199s

Training epoch 338, Batch 500/1000: LR=9.32e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 338, Batch 1000/1000: LR=9.32e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Epoch 338 Train Time 38.80986547470093s

Training epoch 339, Batch 500/1000: LR=9.32e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 339, Batch 1000/1000: LR=9.32e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 339 Train Time 38.74818468093872s

Training epoch 340, Batch 500/1000: LR=9.31e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 340, Batch 1000/1000: LR=9.31e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 340 Train Time 39.28563117980957s

Training epoch 341, Batch 500/1000: LR=9.31e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 341, Batch 1000/1000: LR=9.31e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 341 Train Time 38.714959144592285s

Training epoch 342, Batch 500/1000: LR=9.31e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 342, Batch 1000/1000: LR=9.31e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 342 Train Time 38.64086318016052s

Training epoch 343, Batch 500/1000: LR=9.30e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 343, Batch 1000/1000: LR=9.30e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 343 Train Time 38.65106534957886s

Training epoch 344, Batch 500/1000: LR=9.30e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 344, Batch 1000/1000: LR=9.30e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 344 Train Time 38.713303565979004s

Training epoch 345, Batch 500/1000: LR=9.29e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 345, Batch 1000/1000: LR=9.29e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 345 Train Time 38.645875453948975s

Training epoch 346, Batch 500/1000: LR=9.29e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 346, Batch 1000/1000: LR=9.29e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 346 Train Time 38.7178635597229s

Training epoch 347, Batch 500/1000: LR=9.29e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 347, Batch 1000/1000: LR=9.29e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 347 Train Time 38.68399119377136s

Training epoch 348, Batch 500/1000: LR=9.28e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 348, Batch 1000/1000: LR=9.28e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 348 Train Time 38.660895347595215s

Training epoch 349, Batch 500/1000: LR=9.28e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 349, Batch 1000/1000: LR=9.28e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 349 Train Time 38.66978192329407s

Training epoch 350, Batch 500/1000: LR=9.27e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 350, Batch 1000/1000: LR=9.27e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 350 Train Time 38.65871548652649s

Training epoch 351, Batch 500/1000: LR=9.27e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 351, Batch 1000/1000: LR=9.27e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 351 Train Time 38.77349376678467s

Training epoch 352, Batch 500/1000: LR=9.27e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 352, Batch 1000/1000: LR=9.27e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 352 Train Time 38.68728590011597s

Training epoch 353, Batch 500/1000: LR=9.26e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 353, Batch 1000/1000: LR=9.26e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Epoch 353 Train Time 38.63408660888672s

Training epoch 354, Batch 500/1000: LR=9.26e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 354, Batch 1000/1000: LR=9.26e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 354 Train Time 38.65829563140869s

Training epoch 355, Batch 500/1000: LR=9.25e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 355, Batch 1000/1000: LR=9.25e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 355 Train Time 38.646159648895264s

Training epoch 356, Batch 500/1000: LR=9.25e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 356, Batch 1000/1000: LR=9.25e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 356 Train Time 38.67286968231201s

Training epoch 357, Batch 500/1000: LR=9.25e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 357, Batch 1000/1000: LR=9.25e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 357 Train Time 38.641270875930786s

Training epoch 358, Batch 500/1000: LR=9.24e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 358, Batch 1000/1000: LR=9.24e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 358 Train Time 38.654876947402954s

Training epoch 359, Batch 500/1000: LR=9.24e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 359, Batch 1000/1000: LR=9.24e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 359 Train Time 38.64233088493347s

Training epoch 360, Batch 500/1000: LR=9.23e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 360, Batch 1000/1000: LR=9.23e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 360 Train Time 38.665974140167236s

Training epoch 361, Batch 500/1000: LR=9.23e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 361, Batch 1000/1000: LR=9.23e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 361 Train Time 38.63118767738342s

Training epoch 362, Batch 500/1000: LR=9.23e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 362, Batch 1000/1000: LR=9.23e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 362 Train Time 38.620922803878784s

Training epoch 363, Batch 500/1000: LR=9.22e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 363, Batch 1000/1000: LR=9.22e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 363 Train Time 38.63398575782776s

Training epoch 364, Batch 500/1000: LR=9.22e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 364, Batch 1000/1000: LR=9.22e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 364 Train Time 38.66466784477234s

Training epoch 365, Batch 500/1000: LR=9.21e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 365, Batch 1000/1000: LR=9.21e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 365 Train Time 38.7889187335968s

Training epoch 366, Batch 500/1000: LR=9.21e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 366, Batch 1000/1000: LR=9.21e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 366 Train Time 38.62340521812439s

Training epoch 367, Batch 500/1000: LR=9.20e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 367, Batch 1000/1000: LR=9.20e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 367 Train Time 38.7548553943634s

Training epoch 368, Batch 500/1000: LR=9.20e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 368, Batch 1000/1000: LR=9.20e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Epoch 368 Train Time 38.656405210494995s

Training epoch 369, Batch 500/1000: LR=9.20e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 369, Batch 1000/1000: LR=9.20e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 369 Train Time 38.65783095359802s

Training epoch 370, Batch 500/1000: LR=9.19e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 370, Batch 1000/1000: LR=9.19e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 370 Train Time 38.636165142059326s

Training epoch 371, Batch 500/1000: LR=9.19e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 371, Batch 1000/1000: LR=9.19e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 371 Train Time 38.64167904853821s

Training epoch 372, Batch 500/1000: LR=9.18e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 372, Batch 1000/1000: LR=9.18e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 372 Train Time 38.691486835479736s

Training epoch 373, Batch 500/1000: LR=9.18e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 373, Batch 1000/1000: LR=9.18e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 373 Train Time 38.716058015823364s

Training epoch 374, Batch 500/1000: LR=9.17e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 374, Batch 1000/1000: LR=9.17e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 374 Train Time 38.38901686668396s

Training epoch 375, Batch 500/1000: LR=9.17e-05, Loss=3.00e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 375, Batch 1000/1000: LR=9.17e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.14e-01
Epoch 375 Train Time 38.25524663925171s

Training epoch 376, Batch 500/1000: LR=9.17e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 376, Batch 1000/1000: LR=9.17e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Epoch 376 Train Time 38.2620325088501s

Training epoch 377, Batch 500/1000: LR=9.16e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 377, Batch 1000/1000: LR=9.16e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 377 Train Time 38.26308274269104s

Training epoch 378, Batch 500/1000: LR=9.16e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 378, Batch 1000/1000: LR=9.16e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 378 Train Time 38.29175543785095s

Training epoch 379, Batch 500/1000: LR=9.15e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 379, Batch 1000/1000: LR=9.15e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 379 Train Time 38.23634195327759s

Training epoch 380, Batch 500/1000: LR=9.15e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 380, Batch 1000/1000: LR=9.15e-05, Loss=3.05e-02 BER=1.23e-02 FER=1.15e-01
Epoch 380 Train Time 38.267945766448975s

Training epoch 381, Batch 500/1000: LR=9.14e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 381, Batch 1000/1000: LR=9.14e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Epoch 381 Train Time 38.2784526348114s

Training epoch 382, Batch 500/1000: LR=9.14e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 382, Batch 1000/1000: LR=9.14e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Epoch 382 Train Time 38.37036657333374s

Training epoch 383, Batch 500/1000: LR=9.14e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 383, Batch 1000/1000: LR=9.14e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Epoch 383 Train Time 38.249040842056274s

Training epoch 384, Batch 500/1000: LR=9.13e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 384, Batch 1000/1000: LR=9.13e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 384 Train Time 56.41937828063965s

Training epoch 385, Batch 500/1000: LR=9.13e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 385, Batch 1000/1000: LR=9.13e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 385 Train Time 38.891263484954834s

Training epoch 386, Batch 500/1000: LR=9.12e-05, Loss=3.05e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 386, Batch 1000/1000: LR=9.12e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Epoch 386 Train Time 38.832284688949585s

Training epoch 387, Batch 500/1000: LR=9.12e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 387, Batch 1000/1000: LR=9.12e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 387 Train Time 38.458481311798096s

Training epoch 388, Batch 500/1000: LR=9.11e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 388, Batch 1000/1000: LR=9.11e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 388 Train Time 38.276607036590576s

Training epoch 389, Batch 500/1000: LR=9.11e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 389, Batch 1000/1000: LR=9.11e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 389 Train Time 38.27342748641968s

Training epoch 390, Batch 500/1000: LR=9.10e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 390, Batch 1000/1000: LR=9.10e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 390 Train Time 38.321253538131714s

Training epoch 391, Batch 500/1000: LR=9.10e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 391, Batch 1000/1000: LR=9.10e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Epoch 391 Train Time 38.34173893928528s

Training epoch 392, Batch 500/1000: LR=9.10e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 392, Batch 1000/1000: LR=9.10e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 392 Train Time 38.29318642616272s

Training epoch 393, Batch 500/1000: LR=9.09e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.11e-01
Training epoch 393, Batch 1000/1000: LR=9.09e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 393 Train Time 38.301363706588745s

Training epoch 394, Batch 500/1000: LR=9.09e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.14e-01
Training epoch 394, Batch 1000/1000: LR=9.09e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.14e-01
Epoch 394 Train Time 38.33728766441345s

Training epoch 395, Batch 500/1000: LR=9.08e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 395, Batch 1000/1000: LR=9.08e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.13e-01
Epoch 395 Train Time 38.787208795547485s

Training epoch 396, Batch 500/1000: LR=9.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 396, Batch 1000/1000: LR=9.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 396 Train Time 38.456676721572876s

Training epoch 397, Batch 500/1000: LR=9.07e-05, Loss=3.07e-02 BER=1.24e-02 FER=1.16e-01
Training epoch 397, Batch 1000/1000: LR=9.07e-05, Loss=3.05e-02 BER=1.24e-02 FER=1.15e-01
Epoch 397 Train Time 38.32566690444946s

Training epoch 398, Batch 500/1000: LR=9.07e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 398, Batch 1000/1000: LR=9.07e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Epoch 398 Train Time 38.311116218566895s

Training epoch 399, Batch 500/1000: LR=9.06e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 399, Batch 1000/1000: LR=9.06e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 399 Train Time 38.29631996154785s

Training epoch 400, Batch 500/1000: LR=9.06e-05, Loss=3.02e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 400, Batch 1000/1000: LR=9.06e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 400 Train Time 38.30065727233887s

Training epoch 401, Batch 500/1000: LR=9.05e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 401, Batch 1000/1000: LR=9.05e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Epoch 401 Train Time 38.288562536239624s

Training epoch 402, Batch 500/1000: LR=9.05e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 402, Batch 1000/1000: LR=9.05e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 402 Train Time 38.274630069732666s

Training epoch 403, Batch 500/1000: LR=9.05e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 403, Batch 1000/1000: LR=9.05e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 403 Train Time 38.272016763687134s

Training epoch 404, Batch 500/1000: LR=9.04e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 404, Batch 1000/1000: LR=9.04e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 404 Train Time 38.32010078430176s

Training epoch 405, Batch 500/1000: LR=9.04e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 405, Batch 1000/1000: LR=9.04e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 405 Train Time 38.39490365982056s

Training epoch 406, Batch 500/1000: LR=9.03e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 406, Batch 1000/1000: LR=9.03e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 406 Train Time 38.296406745910645s

Training epoch 407, Batch 500/1000: LR=9.03e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 407, Batch 1000/1000: LR=9.03e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 407 Train Time 38.29624009132385s

Training epoch 408, Batch 500/1000: LR=9.02e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 408, Batch 1000/1000: LR=9.02e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 408 Train Time 38.30713438987732s

Training epoch 409, Batch 500/1000: LR=9.02e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 409, Batch 1000/1000: LR=9.02e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 409 Train Time 38.30091309547424s

Training epoch 410, Batch 500/1000: LR=9.01e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 410, Batch 1000/1000: LR=9.01e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.13e-01
Epoch 410 Train Time 38.295243978500366s

Training epoch 411, Batch 500/1000: LR=9.01e-05, Loss=3.00e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 411, Batch 1000/1000: LR=9.01e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Epoch 411 Train Time 38.29901599884033s

Training epoch 412, Batch 500/1000: LR=9.00e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 412, Batch 1000/1000: LR=9.00e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 412 Train Time 38.29977631568909s

Training epoch 413, Batch 500/1000: LR=9.00e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 413, Batch 1000/1000: LR=9.00e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 413 Train Time 38.34624361991882s

Training epoch 414, Batch 500/1000: LR=8.99e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 414, Batch 1000/1000: LR=8.99e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 414 Train Time 38.42626929283142s

Training epoch 415, Batch 500/1000: LR=8.99e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 415, Batch 1000/1000: LR=8.99e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 415 Train Time 38.27060842514038s

Training epoch 416, Batch 500/1000: LR=8.98e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 416, Batch 1000/1000: LR=8.98e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 416 Train Time 38.282848596572876s

Training epoch 417, Batch 500/1000: LR=8.98e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 417, Batch 1000/1000: LR=8.98e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 417 Train Time 38.25603652000427s

Training epoch 418, Batch 500/1000: LR=8.98e-05, Loss=3.06e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 418, Batch 1000/1000: LR=8.98e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Epoch 418 Train Time 38.258753061294556s

Training epoch 419, Batch 500/1000: LR=8.97e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 419, Batch 1000/1000: LR=8.97e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 419 Train Time 38.27229332923889s

Training epoch 420, Batch 500/1000: LR=8.97e-05, Loss=2.90e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 420, Batch 1000/1000: LR=8.97e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 420 Train Time 38.26498198509216s

Training epoch 421, Batch 500/1000: LR=8.96e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 421, Batch 1000/1000: LR=8.96e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 421 Train Time 38.28162169456482s

Training epoch 422, Batch 500/1000: LR=8.96e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Training epoch 422, Batch 1000/1000: LR=8.96e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 422 Train Time 38.2693247795105s

Training epoch 423, Batch 500/1000: LR=8.95e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 423, Batch 1000/1000: LR=8.95e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 423 Train Time 38.39331603050232s

Training epoch 424, Batch 500/1000: LR=8.95e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 424, Batch 1000/1000: LR=8.95e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 424 Train Time 38.28749322891235s

Training epoch 425, Batch 500/1000: LR=8.94e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 425, Batch 1000/1000: LR=8.94e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 425 Train Time 38.29334568977356s

Training epoch 426, Batch 500/1000: LR=8.94e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 426, Batch 1000/1000: LR=8.94e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 426 Train Time 38.26059865951538s

Training epoch 427, Batch 500/1000: LR=8.93e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 427, Batch 1000/1000: LR=8.93e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 427 Train Time 38.283594608306885s

Training epoch 428, Batch 500/1000: LR=8.93e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 428, Batch 1000/1000: LR=8.93e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 428 Train Time 38.270790338516235s

Training epoch 429, Batch 500/1000: LR=8.92e-05, Loss=3.04e-02 BER=1.22e-02 FER=1.15e-01
Training epoch 429, Batch 1000/1000: LR=8.92e-05, Loss=3.03e-02 BER=1.22e-02 FER=1.14e-01
Epoch 429 Train Time 38.25778937339783s

Training epoch 430, Batch 500/1000: LR=8.92e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 430, Batch 1000/1000: LR=8.92e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 430 Train Time 38.24837374687195s

Training epoch 431, Batch 500/1000: LR=8.91e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 431, Batch 1000/1000: LR=8.91e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 431 Train Time 54.84321212768555s

Training epoch 432, Batch 500/1000: LR=8.91e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 432, Batch 1000/1000: LR=8.91e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 432 Train Time 39.324455976486206s

Training epoch 433, Batch 500/1000: LR=8.90e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 433, Batch 1000/1000: LR=8.90e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 433 Train Time 38.79639673233032s

Training epoch 434, Batch 500/1000: LR=8.90e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 434, Batch 1000/1000: LR=8.90e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Epoch 434 Train Time 38.6852822303772s

Training epoch 435, Batch 500/1000: LR=8.89e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 435, Batch 1000/1000: LR=8.89e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Epoch 435 Train Time 38.64797759056091s

Training epoch 436, Batch 500/1000: LR=8.89e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 436, Batch 1000/1000: LR=8.89e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 436 Train Time 38.67407202720642s

Training epoch 437, Batch 500/1000: LR=8.88e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 437, Batch 1000/1000: LR=8.88e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 437 Train Time 38.67306184768677s

Training epoch 438, Batch 500/1000: LR=8.88e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 438, Batch 1000/1000: LR=8.88e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 438 Train Time 38.70563793182373s

Training epoch 439, Batch 500/1000: LR=8.87e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 439, Batch 1000/1000: LR=8.87e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 439 Train Time 38.67514991760254s

Training epoch 440, Batch 500/1000: LR=8.87e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 440, Batch 1000/1000: LR=8.87e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 440 Train Time 38.69056224822998s

Training epoch 441, Batch 500/1000: LR=8.86e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 441, Batch 1000/1000: LR=8.86e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 441 Train Time 39.37316536903381s

Training epoch 442, Batch 500/1000: LR=8.86e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 442, Batch 1000/1000: LR=8.86e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.14e-01
Epoch 442 Train Time 38.870399951934814s

Training epoch 443, Batch 500/1000: LR=8.85e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 443, Batch 1000/1000: LR=8.85e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 443 Train Time 38.65796256065369s

Training epoch 444, Batch 500/1000: LR=8.85e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 444, Batch 1000/1000: LR=8.85e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 444 Train Time 38.69118404388428s

Training epoch 445, Batch 500/1000: LR=8.84e-05, Loss=3.08e-02 BER=1.25e-02 FER=1.15e-01
Training epoch 445, Batch 1000/1000: LR=8.84e-05, Loss=3.03e-02 BER=1.23e-02 FER=1.14e-01
Epoch 445 Train Time 38.667932987213135s

Training epoch 446, Batch 500/1000: LR=8.84e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 446, Batch 1000/1000: LR=8.84e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Epoch 446 Train Time 38.63868427276611s

Training epoch 447, Batch 500/1000: LR=8.83e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 447, Batch 1000/1000: LR=8.83e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 447 Train Time 38.700201988220215s

Training epoch 448, Batch 500/1000: LR=8.83e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 448, Batch 1000/1000: LR=8.83e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 448 Train Time 39.10018754005432s

Training epoch 449, Batch 500/1000: LR=8.82e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 449, Batch 1000/1000: LR=8.82e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 449 Train Time 38.82714581489563s

Training epoch 450, Batch 500/1000: LR=8.82e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 450, Batch 1000/1000: LR=8.82e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 450 Train Time 39.003663301467896s

Training epoch 451, Batch 500/1000: LR=8.81e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 451, Batch 1000/1000: LR=8.81e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 451 Train Time 38.90593504905701s

Training epoch 452, Batch 500/1000: LR=8.81e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 452, Batch 1000/1000: LR=8.81e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 452 Train Time 38.69276833534241s

Training epoch 453, Batch 500/1000: LR=8.80e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 453, Batch 1000/1000: LR=8.80e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 453 Train Time 38.66379761695862s

Training epoch 454, Batch 500/1000: LR=8.80e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 454, Batch 1000/1000: LR=8.80e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 454 Train Time 38.64074158668518s

Training epoch 455, Batch 500/1000: LR=8.79e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 455, Batch 1000/1000: LR=8.79e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 455 Train Time 38.705636978149414s

Training epoch 456, Batch 500/1000: LR=8.79e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 456, Batch 1000/1000: LR=8.79e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 456 Train Time 38.671303510665894s

Training epoch 457, Batch 500/1000: LR=8.78e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 457, Batch 1000/1000: LR=8.78e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 457 Train Time 38.66401171684265s

Training epoch 458, Batch 500/1000: LR=8.78e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 458, Batch 1000/1000: LR=8.78e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 458 Train Time 38.687880754470825s

Training epoch 459, Batch 500/1000: LR=8.77e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 459, Batch 1000/1000: LR=8.77e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 459 Train Time 38.67571234703064s

Training epoch 460, Batch 500/1000: LR=8.77e-05, Loss=3.04e-02 BER=1.23e-02 FER=1.15e-01
Training epoch 460, Batch 1000/1000: LR=8.77e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Epoch 460 Train Time 38.67160367965698s

Training epoch 461, Batch 500/1000: LR=8.76e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 461, Batch 1000/1000: LR=8.76e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Epoch 461 Train Time 38.52897787094116s

Training epoch 462, Batch 500/1000: LR=8.76e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 462, Batch 1000/1000: LR=8.76e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 462 Train Time 38.29975080490112s

Training epoch 463, Batch 500/1000: LR=8.75e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Training epoch 463, Batch 1000/1000: LR=8.75e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.14e-01
Epoch 463 Train Time 38.33251643180847s

Training epoch 464, Batch 500/1000: LR=8.75e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 464, Batch 1000/1000: LR=8.75e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 464 Train Time 38.2796676158905s

Training epoch 465, Batch 500/1000: LR=8.74e-05, Loss=3.01e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 465, Batch 1000/1000: LR=8.74e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 465 Train Time 38.31019568443298s

Training epoch 466, Batch 500/1000: LR=8.74e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 466, Batch 1000/1000: LR=8.74e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 466 Train Time 38.257967948913574s

Training epoch 467, Batch 500/1000: LR=8.73e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 467, Batch 1000/1000: LR=8.73e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 467 Train Time 38.37091016769409s

Training epoch 468, Batch 500/1000: LR=8.73e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 468, Batch 1000/1000: LR=8.73e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 468 Train Time 38.267963886260986s

Training epoch 469, Batch 500/1000: LR=8.72e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 469, Batch 1000/1000: LR=8.72e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Epoch 469 Train Time 38.26922678947449s

Training epoch 470, Batch 500/1000: LR=8.72e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 470, Batch 1000/1000: LR=8.72e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 470 Train Time 38.30425691604614s

Training epoch 471, Batch 500/1000: LR=8.71e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 471, Batch 1000/1000: LR=8.71e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 471 Train Time 38.286182165145874s

Training epoch 472, Batch 500/1000: LR=8.71e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 472, Batch 1000/1000: LR=8.71e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Epoch 472 Train Time 38.265589475631714s

Training epoch 473, Batch 500/1000: LR=8.70e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 473, Batch 1000/1000: LR=8.70e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 473 Train Time 38.25596880912781s

Training epoch 474, Batch 500/1000: LR=8.70e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 474, Batch 1000/1000: LR=8.70e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 474 Train Time 38.381773233413696s

Training epoch 475, Batch 500/1000: LR=8.69e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 475, Batch 1000/1000: LR=8.69e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 475 Train Time 38.92538070678711s

Training epoch 476, Batch 500/1000: LR=8.68e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 476, Batch 1000/1000: LR=8.68e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 476 Train Time 38.47388029098511s

Training epoch 477, Batch 500/1000: LR=8.68e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 477, Batch 1000/1000: LR=8.68e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 477 Train Time 38.313119888305664s

Training epoch 478, Batch 500/1000: LR=8.67e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 478, Batch 1000/1000: LR=8.67e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 478 Train Time 38.763643980026245s

Training epoch 479, Batch 500/1000: LR=8.67e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 479, Batch 1000/1000: LR=8.67e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 479 Train Time 38.287856101989746s

Training epoch 480, Batch 500/1000: LR=8.66e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 480, Batch 1000/1000: LR=8.66e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Epoch 480 Train Time 38.29840135574341s

Training epoch 481, Batch 500/1000: LR=8.66e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 481, Batch 1000/1000: LR=8.66e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 481 Train Time 38.30422019958496s

Training epoch 482, Batch 500/1000: LR=8.65e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 482, Batch 1000/1000: LR=8.65e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 482 Train Time 81.25793313980103s

Training epoch 483, Batch 500/1000: LR=8.65e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 483, Batch 1000/1000: LR=8.65e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 483 Train Time 39.51735973358154s

Training epoch 484, Batch 500/1000: LR=8.64e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 484, Batch 1000/1000: LR=8.64e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 484 Train Time 38.788639068603516s

Training epoch 485, Batch 500/1000: LR=8.64e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 485, Batch 1000/1000: LR=8.64e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 485 Train Time 38.69870972633362s

Training epoch 486, Batch 500/1000: LR=8.63e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 486, Batch 1000/1000: LR=8.63e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 486 Train Time 38.688427209854126s

Training epoch 487, Batch 500/1000: LR=8.63e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 487, Batch 1000/1000: LR=8.63e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 487 Train Time 38.674805641174316s

Training epoch 488, Batch 500/1000: LR=8.62e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 488, Batch 1000/1000: LR=8.62e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Epoch 488 Train Time 38.66820812225342s

Training epoch 489, Batch 500/1000: LR=8.62e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 489, Batch 1000/1000: LR=8.62e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.13e-01
Epoch 489 Train Time 38.68563771247864s

Training epoch 490, Batch 500/1000: LR=8.61e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 490, Batch 1000/1000: LR=8.61e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 490 Train Time 38.671321630477905s

Training epoch 491, Batch 500/1000: LR=8.60e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 491, Batch 1000/1000: LR=8.60e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 491 Train Time 38.6767041683197s

Training epoch 492, Batch 500/1000: LR=8.60e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.14e-01
Training epoch 492, Batch 1000/1000: LR=8.60e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Epoch 492 Train Time 38.670273542404175s

Training epoch 493, Batch 500/1000: LR=8.59e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 493, Batch 1000/1000: LR=8.59e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.11e-01
Epoch 493 Train Time 38.79267907142639s

Training epoch 494, Batch 500/1000: LR=8.59e-05, Loss=2.96e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 494, Batch 1000/1000: LR=8.59e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 494 Train Time 38.66888117790222s

Training epoch 495, Batch 500/1000: LR=8.58e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 495, Batch 1000/1000: LR=8.58e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 495 Train Time 38.654356241226196s

Training epoch 496, Batch 500/1000: LR=8.58e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 496, Batch 1000/1000: LR=8.58e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 496 Train Time 38.662487506866455s

Training epoch 497, Batch 500/1000: LR=8.57e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 497, Batch 1000/1000: LR=8.57e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 497 Train Time 38.67404627799988s

Training epoch 498, Batch 500/1000: LR=8.57e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 498, Batch 1000/1000: LR=8.57e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 498 Train Time 38.658737897872925s

Training epoch 499, Batch 500/1000: LR=8.56e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 499, Batch 1000/1000: LR=8.56e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Epoch 499 Train Time 38.697962045669556s

Training epoch 500, Batch 500/1000: LR=8.56e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 500, Batch 1000/1000: LR=8.56e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Epoch 500 Train Time 38.64150810241699s

Training epoch 501, Batch 500/1000: LR=8.55e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 501, Batch 1000/1000: LR=8.55e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 501 Train Time 38.64538288116455s

Training epoch 502, Batch 500/1000: LR=8.54e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 502, Batch 1000/1000: LR=8.54e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 502 Train Time 38.64792847633362s

Training epoch 503, Batch 500/1000: LR=8.54e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 503, Batch 1000/1000: LR=8.54e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 503 Train Time 38.64406228065491s

Training epoch 504, Batch 500/1000: LR=8.53e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 504, Batch 1000/1000: LR=8.53e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Epoch 504 Train Time 39.28060865402222s

Training epoch 505, Batch 500/1000: LR=8.53e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 505, Batch 1000/1000: LR=8.53e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 505 Train Time 38.831976652145386s

Training epoch 506, Batch 500/1000: LR=8.52e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 506, Batch 1000/1000: LR=8.52e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 506 Train Time 38.686466217041016s

Training epoch 507, Batch 500/1000: LR=8.52e-05, Loss=3.06e-02 BER=1.24e-02 FER=1.14e-01
Training epoch 507, Batch 1000/1000: LR=8.52e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 507 Train Time 38.664036989212036s

Training epoch 508, Batch 500/1000: LR=8.51e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 508, Batch 1000/1000: LR=8.51e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.13e-01
Epoch 508 Train Time 38.62206506729126s

Training epoch 509, Batch 500/1000: LR=8.51e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 509, Batch 1000/1000: LR=8.51e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 509 Train Time 38.246617794036865s

Training epoch 510, Batch 500/1000: LR=8.50e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 510, Batch 1000/1000: LR=8.50e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 510 Train Time 38.26088619232178s

Training epoch 511, Batch 500/1000: LR=8.49e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 511, Batch 1000/1000: LR=8.49e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 511 Train Time 38.26456952095032s

Training epoch 512, Batch 500/1000: LR=8.49e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 512, Batch 1000/1000: LR=8.49e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 512 Train Time 38.27584719657898s

Training epoch 513, Batch 500/1000: LR=8.48e-05, Loss=3.02e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 513, Batch 1000/1000: LR=8.48e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 513 Train Time 38.258405447006226s

Training epoch 514, Batch 500/1000: LR=8.48e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 514, Batch 1000/1000: LR=8.48e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 514 Train Time 38.35893440246582s

Training epoch 515, Batch 500/1000: LR=8.47e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 515, Batch 1000/1000: LR=8.47e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 515 Train Time 38.288185596466064s

Training epoch 516, Batch 500/1000: LR=8.47e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 516, Batch 1000/1000: LR=8.47e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 516 Train Time 38.26118230819702s

Training epoch 517, Batch 500/1000: LR=8.46e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 517, Batch 1000/1000: LR=8.46e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 517 Train Time 38.28126287460327s

Training epoch 518, Batch 500/1000: LR=8.46e-05, Loss=2.95e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 518, Batch 1000/1000: LR=8.46e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 518 Train Time 38.26557111740112s

Training epoch 519, Batch 500/1000: LR=8.45e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 519, Batch 1000/1000: LR=8.45e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 519 Train Time 38.263538122177124s

Training epoch 520, Batch 500/1000: LR=8.44e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 520, Batch 1000/1000: LR=8.44e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 520 Train Time 38.24379348754883s

Training epoch 521, Batch 500/1000: LR=8.44e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 521, Batch 1000/1000: LR=8.44e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 521 Train Time 38.27005338668823s

Training epoch 522, Batch 500/1000: LR=8.43e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 522, Batch 1000/1000: LR=8.43e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 522 Train Time 38.30039644241333s

Training epoch 523, Batch 500/1000: LR=8.43e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 523, Batch 1000/1000: LR=8.43e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 523 Train Time 38.27519989013672s

Training epoch 524, Batch 500/1000: LR=8.42e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 524, Batch 1000/1000: LR=8.42e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 524 Train Time 38.2613844871521s

Training epoch 525, Batch 500/1000: LR=8.42e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 525, Batch 1000/1000: LR=8.42e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 525 Train Time 38.32272219657898s

Training epoch 526, Batch 500/1000: LR=8.41e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 526, Batch 1000/1000: LR=8.41e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Epoch 526 Train Time 38.30630373954773s

Training epoch 527, Batch 500/1000: LR=8.40e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 527, Batch 1000/1000: LR=8.40e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 527 Train Time 38.259886264801025s

Training epoch 528, Batch 500/1000: LR=8.40e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 528, Batch 1000/1000: LR=8.40e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 528 Train Time 38.263593435287476s

Training epoch 529, Batch 500/1000: LR=8.39e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 529, Batch 1000/1000: LR=8.39e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 529 Train Time 38.265012979507446s

Training epoch 530, Batch 500/1000: LR=8.39e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 530, Batch 1000/1000: LR=8.39e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 530 Train Time 56.36478567123413s

Training epoch 531, Batch 500/1000: LR=8.38e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 531, Batch 1000/1000: LR=8.38e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.12e-01
Epoch 531 Train Time 38.90098595619202s

Training epoch 532, Batch 500/1000: LR=8.38e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 532, Batch 1000/1000: LR=8.38e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 532 Train Time 38.5005738735199s

Training epoch 533, Batch 500/1000: LR=8.37e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 533, Batch 1000/1000: LR=8.37e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 533 Train Time 38.299773931503296s

Training epoch 534, Batch 500/1000: LR=8.36e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 534, Batch 1000/1000: LR=8.36e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 534 Train Time 38.41555714607239s

Training epoch 535, Batch 500/1000: LR=8.36e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 535, Batch 1000/1000: LR=8.36e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 535 Train Time 38.291101932525635s

Training epoch 536, Batch 500/1000: LR=8.35e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 536, Batch 1000/1000: LR=8.35e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 536 Train Time 38.24853587150574s

Training epoch 537, Batch 500/1000: LR=8.35e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 537, Batch 1000/1000: LR=8.35e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 537 Train Time 38.26362490653992s

Training epoch 538, Batch 500/1000: LR=8.34e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 538, Batch 1000/1000: LR=8.34e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 538 Train Time 38.28602457046509s

Training epoch 539, Batch 500/1000: LR=8.34e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 539, Batch 1000/1000: LR=8.34e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 539 Train Time 38.26567506790161s

Training epoch 540, Batch 500/1000: LR=8.33e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 540, Batch 1000/1000: LR=8.33e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 540 Train Time 38.25325846672058s

Training epoch 541, Batch 500/1000: LR=8.32e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 541, Batch 1000/1000: LR=8.32e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 541 Train Time 38.326826095581055s

Training epoch 542, Batch 500/1000: LR=8.32e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 542, Batch 1000/1000: LR=8.32e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 542 Train Time 38.24979853630066s

Training epoch 543, Batch 500/1000: LR=8.31e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 543, Batch 1000/1000: LR=8.31e-05, Loss=3.02e-02 BER=1.23e-02 FER=1.14e-01
Epoch 543 Train Time 38.29717493057251s

Training epoch 544, Batch 500/1000: LR=8.31e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 544, Batch 1000/1000: LR=8.31e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 544 Train Time 38.40310549736023s

Training epoch 545, Batch 500/1000: LR=8.30e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 545, Batch 1000/1000: LR=8.30e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 545 Train Time 38.359814167022705s

Training epoch 546, Batch 500/1000: LR=8.29e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 546, Batch 1000/1000: LR=8.29e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 546 Train Time 38.75597882270813s

Training epoch 547, Batch 500/1000: LR=8.29e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 547, Batch 1000/1000: LR=8.29e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 547 Train Time 38.26725220680237s

Training epoch 548, Batch 500/1000: LR=8.28e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 548, Batch 1000/1000: LR=8.28e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Epoch 548 Train Time 38.84603571891785s

Training epoch 549, Batch 500/1000: LR=8.28e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 549, Batch 1000/1000: LR=8.28e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 549 Train Time 39.06405282020569s

Training epoch 550, Batch 500/1000: LR=8.27e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 550, Batch 1000/1000: LR=8.27e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 550 Train Time 38.521270751953125s

Training epoch 551, Batch 500/1000: LR=8.26e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 551, Batch 1000/1000: LR=8.26e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 551 Train Time 38.29413914680481s

Training epoch 552, Batch 500/1000: LR=8.26e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 552, Batch 1000/1000: LR=8.26e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 552 Train Time 38.27641272544861s

Training epoch 553, Batch 500/1000: LR=8.25e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 553, Batch 1000/1000: LR=8.25e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 553 Train Time 38.2885365486145s

Training epoch 554, Batch 500/1000: LR=8.25e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 554, Batch 1000/1000: LR=8.25e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 554 Train Time 38.258288860321045s

Training epoch 555, Batch 500/1000: LR=8.24e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 555, Batch 1000/1000: LR=8.24e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Epoch 555 Train Time 38.41239595413208s

Training epoch 556, Batch 500/1000: LR=8.24e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 556, Batch 1000/1000: LR=8.24e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 556 Train Time 38.27584934234619s

Training epoch 557, Batch 500/1000: LR=8.23e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 557, Batch 1000/1000: LR=8.23e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 557 Train Time 38.26055860519409s

Training epoch 558, Batch 500/1000: LR=8.22e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 558, Batch 1000/1000: LR=8.22e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 558 Train Time 38.27497887611389s

Training epoch 559, Batch 500/1000: LR=8.22e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.13e-01
Training epoch 559, Batch 1000/1000: LR=8.22e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 559 Train Time 38.353845834732056s

Training epoch 560, Batch 500/1000: LR=8.21e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 560, Batch 1000/1000: LR=8.21e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 560 Train Time 38.26254940032959s

Training epoch 561, Batch 500/1000: LR=8.21e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 561, Batch 1000/1000: LR=8.21e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 561 Train Time 38.60717558860779s

Training epoch 562, Batch 500/1000: LR=8.20e-05, Loss=2.97e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 562, Batch 1000/1000: LR=8.20e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Epoch 562 Train Time 38.2466459274292s

Training epoch 563, Batch 500/1000: LR=8.19e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 563, Batch 1000/1000: LR=8.19e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 563 Train Time 38.27017045021057s

Training epoch 564, Batch 500/1000: LR=8.19e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 564, Batch 1000/1000: LR=8.19e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 564 Train Time 38.364585638046265s

Training epoch 565, Batch 500/1000: LR=8.18e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 565, Batch 1000/1000: LR=8.18e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 565 Train Time 38.29409408569336s

Training epoch 566, Batch 500/1000: LR=8.18e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 566, Batch 1000/1000: LR=8.18e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 566 Train Time 38.25603461265564s

Training epoch 567, Batch 500/1000: LR=8.17e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 567, Batch 1000/1000: LR=8.17e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 567 Train Time 38.27981781959534s

Training epoch 568, Batch 500/1000: LR=8.16e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 568, Batch 1000/1000: LR=8.16e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 568 Train Time 38.26679587364197s

Training epoch 569, Batch 500/1000: LR=8.16e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 569, Batch 1000/1000: LR=8.16e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 569 Train Time 38.77505159378052s

Training epoch 570, Batch 500/1000: LR=8.15e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 570, Batch 1000/1000: LR=8.15e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 570 Train Time 38.55997586250305s

Training epoch 571, Batch 500/1000: LR=8.14e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 571, Batch 1000/1000: LR=8.14e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.11e-01
Epoch 571 Train Time 38.272841691970825s

Training epoch 572, Batch 500/1000: LR=8.14e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 572, Batch 1000/1000: LR=8.14e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 572 Train Time 38.30969023704529s

Training epoch 573, Batch 500/1000: LR=8.13e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 573, Batch 1000/1000: LR=8.13e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 573 Train Time 38.27815127372742s

Training epoch 574, Batch 500/1000: LR=8.13e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 574, Batch 1000/1000: LR=8.13e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 574 Train Time 38.366875886917114s

Training epoch 575, Batch 500/1000: LR=8.12e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 575, Batch 1000/1000: LR=8.12e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 575 Train Time 38.29223418235779s

Training epoch 576, Batch 500/1000: LR=8.11e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 576, Batch 1000/1000: LR=8.11e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 576 Train Time 38.242759466171265s

Training epoch 577, Batch 500/1000: LR=8.11e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 577, Batch 1000/1000: LR=8.11e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 577 Train Time 102.34967803955078s

Training epoch 578, Batch 500/1000: LR=8.10e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 578, Batch 1000/1000: LR=8.10e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 578 Train Time 39.64758348464966s

Training epoch 579, Batch 500/1000: LR=8.10e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 579, Batch 1000/1000: LR=8.10e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 579 Train Time 38.811885595321655s

Training epoch 580, Batch 500/1000: LR=8.09e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 580, Batch 1000/1000: LR=8.09e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 580 Train Time 38.68734908103943s

Training epoch 581, Batch 500/1000: LR=8.08e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 581, Batch 1000/1000: LR=8.08e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 581 Train Time 38.797181844711304s

Training epoch 582, Batch 500/1000: LR=8.08e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 582, Batch 1000/1000: LR=8.08e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 582 Train Time 38.69610357284546s

Training epoch 583, Batch 500/1000: LR=8.07e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 583, Batch 1000/1000: LR=8.07e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 583 Train Time 38.648998975753784s

Training epoch 584, Batch 500/1000: LR=8.07e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 584, Batch 1000/1000: LR=8.07e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 584 Train Time 38.662214279174805s

Training epoch 585, Batch 500/1000: LR=8.06e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 585, Batch 1000/1000: LR=8.06e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Epoch 585 Train Time 38.669703245162964s

Training epoch 586, Batch 500/1000: LR=8.05e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 586, Batch 1000/1000: LR=8.05e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 586 Train Time 38.66657209396362s

Training epoch 587, Batch 500/1000: LR=8.05e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Training epoch 587, Batch 1000/1000: LR=8.05e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 587 Train Time 38.66960787773132s

Training epoch 588, Batch 500/1000: LR=8.04e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 588, Batch 1000/1000: LR=8.04e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 588 Train Time 38.66431665420532s

Training epoch 589, Batch 500/1000: LR=8.03e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 589, Batch 1000/1000: LR=8.03e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 589 Train Time 38.6869113445282s

Training epoch 590, Batch 500/1000: LR=8.03e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 590, Batch 1000/1000: LR=8.03e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Epoch 590 Train Time 38.70442771911621s

Training epoch 591, Batch 500/1000: LR=8.02e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 591, Batch 1000/1000: LR=8.02e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 591 Train Time 38.792888879776s

Training epoch 592, Batch 500/1000: LR=8.02e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.13e-01
Training epoch 592, Batch 1000/1000: LR=8.02e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.12e-01
Epoch 592 Train Time 38.65556597709656s

Training epoch 593, Batch 500/1000: LR=8.01e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 593, Batch 1000/1000: LR=8.01e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 593 Train Time 38.676469802856445s

Training epoch 594, Batch 500/1000: LR=8.00e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 594, Batch 1000/1000: LR=8.00e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 594 Train Time 41.02493190765381s

Training epoch 595, Batch 500/1000: LR=8.00e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 595, Batch 1000/1000: LR=8.00e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 595 Train Time 39.5484516620636s

Training epoch 596, Batch 500/1000: LR=7.99e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 596, Batch 1000/1000: LR=7.99e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 596 Train Time 38.66271758079529s

Training epoch 597, Batch 500/1000: LR=7.98e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 597, Batch 1000/1000: LR=7.98e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 597 Train Time 38.638946771621704s

Training epoch 598, Batch 500/1000: LR=7.98e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 598, Batch 1000/1000: LR=7.98e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 598 Train Time 38.69222903251648s

Training epoch 599, Batch 500/1000: LR=7.97e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 599, Batch 1000/1000: LR=7.97e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 599 Train Time 38.79715156555176s

Training epoch 600, Batch 500/1000: LR=7.97e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 600, Batch 1000/1000: LR=7.97e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 600 Train Time 38.762309551239014s


Test Loss 4: 8.98e-03 5: 9.46e-04 6: 4.69e-05
Test FER 4: 4.00e-02 5: 4.41e-03 6: 2.61e-04
Test BER 4: 3.31e-03 5: 2.98e-04 6: 1.35e-05
Test -ln(BER) 4: 5.71e+00 5: 8.12e+00 6: 1.12e+01
# of testing samples: [100352.0, 100352.0, 387072.0]
 Test Time 110.1067283153534 s

Training epoch 601, Batch 500/1000: LR=7.96e-05, Loss=3.00e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 601, Batch 1000/1000: LR=7.96e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Epoch 601 Train Time 38.6326847076416s

Training epoch 602, Batch 500/1000: LR=7.95e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 602, Batch 1000/1000: LR=7.95e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 602 Train Time 38.615854024887085s

Training epoch 603, Batch 500/1000: LR=7.95e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 603, Batch 1000/1000: LR=7.95e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 603 Train Time 38.635186195373535s

Training epoch 604, Batch 500/1000: LR=7.94e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 604, Batch 1000/1000: LR=7.94e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 604 Train Time 38.616621255874634s

Training epoch 605, Batch 500/1000: LR=7.93e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 605, Batch 1000/1000: LR=7.93e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 605 Train Time 38.6853232383728s

Training epoch 606, Batch 500/1000: LR=7.93e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 606, Batch 1000/1000: LR=7.93e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Epoch 606 Train Time 38.80187273025513s

Training epoch 607, Batch 500/1000: LR=7.92e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 607, Batch 1000/1000: LR=7.92e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 607 Train Time 38.35240650177002s

Training epoch 608, Batch 500/1000: LR=7.92e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 608, Batch 1000/1000: LR=7.92e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 608 Train Time 39.65651488304138s

Training epoch 609, Batch 500/1000: LR=7.91e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 609, Batch 1000/1000: LR=7.91e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 609 Train Time 41.33113718032837s

Training epoch 610, Batch 500/1000: LR=7.90e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 610, Batch 1000/1000: LR=7.90e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 610 Train Time 39.7485032081604s

Training epoch 611, Batch 500/1000: LR=7.90e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 611, Batch 1000/1000: LR=7.90e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 611 Train Time 38.95964860916138s

Training epoch 612, Batch 500/1000: LR=7.89e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 612, Batch 1000/1000: LR=7.89e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 612 Train Time 40.41529893875122s

Training epoch 613, Batch 500/1000: LR=7.88e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 613, Batch 1000/1000: LR=7.88e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.11e-01
Epoch 613 Train Time 39.77688145637512s

Training epoch 614, Batch 500/1000: LR=7.88e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 614, Batch 1000/1000: LR=7.88e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 614 Train Time 42.31690311431885s

Training epoch 615, Batch 500/1000: LR=7.87e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 615, Batch 1000/1000: LR=7.87e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 615 Train Time 42.095396518707275s

Training epoch 616, Batch 500/1000: LR=7.86e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 616, Batch 1000/1000: LR=7.86e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 616 Train Time 39.47345781326294s

Training epoch 617, Batch 500/1000: LR=7.86e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 617, Batch 1000/1000: LR=7.86e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 617 Train Time 38.58759927749634s

Training epoch 618, Batch 500/1000: LR=7.85e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 618, Batch 1000/1000: LR=7.85e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 618 Train Time 38.68263244628906s

Training epoch 619, Batch 500/1000: LR=7.85e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 619, Batch 1000/1000: LR=7.85e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 619 Train Time 38.85608792304993s

Training epoch 620, Batch 500/1000: LR=7.84e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 620, Batch 1000/1000: LR=7.84e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 620 Train Time 39.207706928253174s

Training epoch 621, Batch 500/1000: LR=7.83e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 621, Batch 1000/1000: LR=7.83e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 621 Train Time 38.66594743728638s

Training epoch 622, Batch 500/1000: LR=7.83e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 622, Batch 1000/1000: LR=7.83e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 622 Train Time 38.28940010070801s

Training epoch 623, Batch 500/1000: LR=7.82e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 623, Batch 1000/1000: LR=7.82e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 623 Train Time 38.30519890785217s

Training epoch 624, Batch 500/1000: LR=7.81e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 624, Batch 1000/1000: LR=7.81e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 624 Train Time 38.32825040817261s

Training epoch 625, Batch 500/1000: LR=7.81e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 625, Batch 1000/1000: LR=7.81e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 625 Train Time 38.264180183410645s

Training epoch 626, Batch 500/1000: LR=7.80e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 626, Batch 1000/1000: LR=7.80e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 626 Train Time 38.342469930648804s

Training epoch 627, Batch 500/1000: LR=7.79e-05, Loss=2.99e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 627, Batch 1000/1000: LR=7.79e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.09e-01
Epoch 627 Train Time 38.486610651016235s

Training epoch 628, Batch 500/1000: LR=7.79e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 628, Batch 1000/1000: LR=7.79e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 628 Train Time 38.41109776496887s

Training epoch 629, Batch 500/1000: LR=7.78e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 629, Batch 1000/1000: LR=7.78e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 629 Train Time 38.3139762878418s

Training epoch 630, Batch 500/1000: LR=7.77e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 630, Batch 1000/1000: LR=7.77e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 630 Train Time 38.294788122177124s

Training epoch 631, Batch 500/1000: LR=7.77e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 631, Batch 1000/1000: LR=7.77e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 631 Train Time 38.33153820037842s

Training epoch 632, Batch 500/1000: LR=7.76e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 632, Batch 1000/1000: LR=7.76e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.11e-01
Epoch 632 Train Time 38.29563522338867s

Training epoch 633, Batch 500/1000: LR=7.75e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 633, Batch 1000/1000: LR=7.75e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 633 Train Time 38.28262686729431s

Training epoch 634, Batch 500/1000: LR=7.75e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 634, Batch 1000/1000: LR=7.75e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 634 Train Time 38.287926197052s

Training epoch 635, Batch 500/1000: LR=7.74e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 635, Batch 1000/1000: LR=7.74e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 635 Train Time 38.28367352485657s

Training epoch 636, Batch 500/1000: LR=7.74e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 636, Batch 1000/1000: LR=7.74e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 636 Train Time 38.405940771102905s

Training epoch 637, Batch 500/1000: LR=7.73e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.10e-01
Training epoch 637, Batch 1000/1000: LR=7.73e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 637 Train Time 38.404670000076294s

Training epoch 638, Batch 500/1000: LR=7.72e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 638, Batch 1000/1000: LR=7.72e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 638 Train Time 38.290393114089966s

Training epoch 639, Batch 500/1000: LR=7.72e-05, Loss=2.98e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 639, Batch 1000/1000: LR=7.72e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 639 Train Time 38.2645149230957s

Training epoch 640, Batch 500/1000: LR=7.71e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 640, Batch 1000/1000: LR=7.71e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 640 Train Time 38.229740142822266s

Training epoch 641, Batch 500/1000: LR=7.70e-05, Loss=3.01e-02 BER=1.23e-02 FER=1.13e-01
Training epoch 641, Batch 1000/1000: LR=7.70e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.12e-01
Epoch 641 Train Time 38.28714895248413s

Training epoch 642, Batch 500/1000: LR=7.70e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 642, Batch 1000/1000: LR=7.70e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 642 Train Time 38.24675703048706s

Training epoch 643, Batch 500/1000: LR=7.69e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 643, Batch 1000/1000: LR=7.69e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 643 Train Time 38.29018998146057s

Training epoch 644, Batch 500/1000: LR=7.68e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 644, Batch 1000/1000: LR=7.68e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.10e-01
Epoch 644 Train Time 38.258028745651245s

Training epoch 645, Batch 500/1000: LR=7.68e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 645, Batch 1000/1000: LR=7.68e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 645 Train Time 38.271483182907104s

Training epoch 646, Batch 500/1000: LR=7.67e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 646, Batch 1000/1000: LR=7.67e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 646 Train Time 38.38300132751465s

Training epoch 647, Batch 500/1000: LR=7.66e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 647, Batch 1000/1000: LR=7.66e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 647 Train Time 38.409470081329346s

Training epoch 648, Batch 500/1000: LR=7.66e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 648, Batch 1000/1000: LR=7.66e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 648 Train Time 38.292975425720215s

Training epoch 649, Batch 500/1000: LR=7.65e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 649, Batch 1000/1000: LR=7.65e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 649 Train Time 38.27049374580383s

Training epoch 650, Batch 500/1000: LR=7.64e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 650, Batch 1000/1000: LR=7.64e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 650 Train Time 38.25367188453674s

Training epoch 651, Batch 500/1000: LR=7.64e-05, Loss=2.95e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 651, Batch 1000/1000: LR=7.64e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 651 Train Time 38.29637432098389s

Training epoch 652, Batch 500/1000: LR=7.63e-05, Loss=2.92e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 652, Batch 1000/1000: LR=7.63e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 652 Train Time 38.276254177093506s

Training epoch 653, Batch 500/1000: LR=7.62e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 653, Batch 1000/1000: LR=7.62e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 653 Train Time 38.26783013343811s

Training epoch 654, Batch 500/1000: LR=7.62e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 654, Batch 1000/1000: LR=7.62e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 654 Train Time 38.26123070716858s

Training epoch 655, Batch 500/1000: LR=7.61e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 655, Batch 1000/1000: LR=7.61e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Epoch 655 Train Time 38.27587580680847s

Training epoch 656, Batch 500/1000: LR=7.60e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 656, Batch 1000/1000: LR=7.60e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 656 Train Time 38.38133144378662s

Training epoch 657, Batch 500/1000: LR=7.60e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 657, Batch 1000/1000: LR=7.60e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 657 Train Time 38.27333664894104s

Training epoch 658, Batch 500/1000: LR=7.59e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 658, Batch 1000/1000: LR=7.59e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 658 Train Time 38.27499032020569s

Training epoch 659, Batch 500/1000: LR=7.58e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 659, Batch 1000/1000: LR=7.58e-05, Loss=2.87e-02 BER=1.15e-02 FER=1.08e-01
Epoch 659 Train Time 38.271098136901855s

Training epoch 660, Batch 500/1000: LR=7.58e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 660, Batch 1000/1000: LR=7.58e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 660 Train Time 38.27251720428467s

Training epoch 661, Batch 500/1000: LR=7.57e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 661, Batch 1000/1000: LR=7.57e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 661 Train Time 38.27130460739136s

Training epoch 662, Batch 500/1000: LR=7.56e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 662, Batch 1000/1000: LR=7.56e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 662 Train Time 38.249934911727905s

Training epoch 663, Batch 500/1000: LR=7.56e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 663, Batch 1000/1000: LR=7.56e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.12e-01
Epoch 663 Train Time 38.241055727005005s

Training epoch 664, Batch 500/1000: LR=7.55e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 664, Batch 1000/1000: LR=7.55e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 664 Train Time 38.26449966430664s

Training epoch 665, Batch 500/1000: LR=7.54e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 665, Batch 1000/1000: LR=7.54e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 665 Train Time 38.399619579315186s

Training epoch 666, Batch 500/1000: LR=7.54e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 666, Batch 1000/1000: LR=7.54e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 666 Train Time 38.2739360332489s

Training epoch 667, Batch 500/1000: LR=7.53e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 667, Batch 1000/1000: LR=7.53e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 667 Train Time 38.218403339385986s

Training epoch 668, Batch 500/1000: LR=7.52e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 668, Batch 1000/1000: LR=7.52e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 668 Train Time 72.08005928993225s

Training epoch 669, Batch 500/1000: LR=7.52e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 669, Batch 1000/1000: LR=7.52e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Epoch 669 Train Time 39.250975131988525s

Training epoch 670, Batch 500/1000: LR=7.51e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.11e-01
Training epoch 670, Batch 1000/1000: LR=7.51e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 670 Train Time 38.479159355163574s

Training epoch 671, Batch 500/1000: LR=7.50e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 671, Batch 1000/1000: LR=7.50e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 671 Train Time 38.253572940826416s

Training epoch 672, Batch 500/1000: LR=7.50e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 672, Batch 1000/1000: LR=7.50e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 672 Train Time 38.2787721157074s

Training epoch 673, Batch 500/1000: LR=7.49e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 673, Batch 1000/1000: LR=7.49e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.10e-01
Epoch 673 Train Time 38.80849599838257s

Training epoch 674, Batch 500/1000: LR=7.48e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 674, Batch 1000/1000: LR=7.48e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 674 Train Time 38.39287877082825s

Training epoch 675, Batch 500/1000: LR=7.48e-05, Loss=2.96e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 675, Batch 1000/1000: LR=7.48e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 675 Train Time 38.29164457321167s

Training epoch 676, Batch 500/1000: LR=7.47e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 676, Batch 1000/1000: LR=7.47e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 676 Train Time 38.27152943611145s

Training epoch 677, Batch 500/1000: LR=7.46e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 677, Batch 1000/1000: LR=7.46e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Epoch 677 Train Time 38.28434896469116s

Training epoch 678, Batch 500/1000: LR=7.46e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 678, Batch 1000/1000: LR=7.46e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 678 Train Time 38.27267932891846s

Training epoch 679, Batch 500/1000: LR=7.45e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 679, Batch 1000/1000: LR=7.45e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 679 Train Time 38.243969678878784s

Training epoch 680, Batch 500/1000: LR=7.44e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 680, Batch 1000/1000: LR=7.44e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 680 Train Time 38.25865077972412s

Training epoch 681, Batch 500/1000: LR=7.43e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 681, Batch 1000/1000: LR=7.43e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 681 Train Time 38.29421043395996s

Training epoch 682, Batch 500/1000: LR=7.43e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 682, Batch 1000/1000: LR=7.43e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 682 Train Time 38.315104722976685s

Training epoch 683, Batch 500/1000: LR=7.42e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 683, Batch 1000/1000: LR=7.42e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 683 Train Time 38.394020795822144s

Training epoch 684, Batch 500/1000: LR=7.41e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 684, Batch 1000/1000: LR=7.41e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 684 Train Time 38.26093339920044s

Training epoch 685, Batch 500/1000: LR=7.41e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 685, Batch 1000/1000: LR=7.41e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 685 Train Time 38.379372119903564s

Training epoch 686, Batch 500/1000: LR=7.40e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 686, Batch 1000/1000: LR=7.40e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Epoch 686 Train Time 38.387839555740356s

Training epoch 687, Batch 500/1000: LR=7.39e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 687, Batch 1000/1000: LR=7.39e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 687 Train Time 38.259663105010986s

Training epoch 688, Batch 500/1000: LR=7.39e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 688, Batch 1000/1000: LR=7.39e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 688 Train Time 38.28394055366516s

Training epoch 689, Batch 500/1000: LR=7.38e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 689, Batch 1000/1000: LR=7.38e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 689 Train Time 38.257302045822144s

Training epoch 690, Batch 500/1000: LR=7.37e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 690, Batch 1000/1000: LR=7.37e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 690 Train Time 38.255165576934814s

Training epoch 691, Batch 500/1000: LR=7.37e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 691, Batch 1000/1000: LR=7.37e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 691 Train Time 38.25236630439758s

Training epoch 692, Batch 500/1000: LR=7.36e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 692, Batch 1000/1000: LR=7.36e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 692 Train Time 38.2857563495636s

Training epoch 693, Batch 500/1000: LR=7.35e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 693, Batch 1000/1000: LR=7.35e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 693 Train Time 38.346476793289185s

Training epoch 694, Batch 500/1000: LR=7.35e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 694, Batch 1000/1000: LR=7.35e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 694 Train Time 38.24467206001282s

Training epoch 695, Batch 500/1000: LR=7.34e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 695, Batch 1000/1000: LR=7.34e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 695 Train Time 38.27164626121521s

Training epoch 696, Batch 500/1000: LR=7.33e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 696, Batch 1000/1000: LR=7.33e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 696 Train Time 38.283777475357056s

Training epoch 697, Batch 500/1000: LR=7.32e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 697, Batch 1000/1000: LR=7.32e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Epoch 697 Train Time 38.28095722198486s

Training epoch 698, Batch 500/1000: LR=7.32e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 698, Batch 1000/1000: LR=7.32e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.11e-01
Epoch 698 Train Time 38.246992111206055s

Training epoch 699, Batch 500/1000: LR=7.31e-05, Loss=2.99e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 699, Batch 1000/1000: LR=7.31e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 699 Train Time 38.266019344329834s

Training epoch 700, Batch 500/1000: LR=7.30e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 700, Batch 1000/1000: LR=7.30e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 700 Train Time 38.69893288612366s

Training epoch 701, Batch 500/1000: LR=7.30e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 701, Batch 1000/1000: LR=7.30e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 701 Train Time 38.4184889793396s

Training epoch 702, Batch 500/1000: LR=7.29e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 702, Batch 1000/1000: LR=7.29e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Epoch 702 Train Time 38.27459001541138s

Training epoch 703, Batch 500/1000: LR=7.28e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 703, Batch 1000/1000: LR=7.28e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 703 Train Time 38.26150846481323s

Training epoch 704, Batch 500/1000: LR=7.28e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 704, Batch 1000/1000: LR=7.28e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 704 Train Time 38.28962826728821s

Training epoch 705, Batch 500/1000: LR=7.27e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 705, Batch 1000/1000: LR=7.27e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 705 Train Time 38.74334216117859s

Training epoch 706, Batch 500/1000: LR=7.26e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 706, Batch 1000/1000: LR=7.26e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 706 Train Time 38.3419930934906s

Training epoch 707, Batch 500/1000: LR=7.26e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 707, Batch 1000/1000: LR=7.26e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 707 Train Time 38.295143842697144s

Training epoch 708, Batch 500/1000: LR=7.25e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 708, Batch 1000/1000: LR=7.25e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 708 Train Time 38.431591510772705s

Training epoch 709, Batch 500/1000: LR=7.24e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 709, Batch 1000/1000: LR=7.24e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 709 Train Time 38.69700503349304s

Training epoch 710, Batch 500/1000: LR=7.23e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 710, Batch 1000/1000: LR=7.23e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 710 Train Time 38.31125354766846s

Training epoch 711, Batch 500/1000: LR=7.23e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 711, Batch 1000/1000: LR=7.23e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 711 Train Time 38.303415060043335s

Training epoch 712, Batch 500/1000: LR=7.22e-05, Loss=2.81e-02 BER=1.13e-02 FER=1.06e-01
Training epoch 712, Batch 1000/1000: LR=7.22e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 712 Train Time 38.423885345458984s

Training epoch 713, Batch 500/1000: LR=7.21e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 713, Batch 1000/1000: LR=7.21e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 713 Train Time 38.29477071762085s

Training epoch 714, Batch 500/1000: LR=7.21e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 714, Batch 1000/1000: LR=7.21e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 714 Train Time 38.28912925720215s

Training epoch 715, Batch 500/1000: LR=7.20e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 715, Batch 1000/1000: LR=7.20e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 715 Train Time 38.29880213737488s

Training epoch 716, Batch 500/1000: LR=7.19e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 716, Batch 1000/1000: LR=7.19e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 716 Train Time 63.88980150222778s

Training epoch 717, Batch 500/1000: LR=7.19e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 717, Batch 1000/1000: LR=7.19e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 717 Train Time 38.971585273742676s

Training epoch 718, Batch 500/1000: LR=7.18e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 718, Batch 1000/1000: LR=7.18e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 718 Train Time 38.693222999572754s

Training epoch 719, Batch 500/1000: LR=7.17e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.12e-01
Training epoch 719, Batch 1000/1000: LR=7.17e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Epoch 719 Train Time 38.68605446815491s

Training epoch 720, Batch 500/1000: LR=7.16e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 720, Batch 1000/1000: LR=7.16e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 720 Train Time 38.674670457839966s

Training epoch 721, Batch 500/1000: LR=7.16e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 721, Batch 1000/1000: LR=7.16e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 721 Train Time 38.71955728530884s

Training epoch 722, Batch 500/1000: LR=7.15e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 722, Batch 1000/1000: LR=7.15e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 722 Train Time 38.72157287597656s

Training epoch 723, Batch 500/1000: LR=7.14e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 723, Batch 1000/1000: LR=7.14e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Epoch 723 Train Time 38.669979095458984s

Training epoch 724, Batch 500/1000: LR=7.14e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 724, Batch 1000/1000: LR=7.14e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 724 Train Time 38.67297983169556s

Training epoch 725, Batch 500/1000: LR=7.13e-05, Loss=3.00e-02 BER=1.22e-02 FER=1.13e-01
Training epoch 725, Batch 1000/1000: LR=7.13e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Epoch 725 Train Time 38.66696500778198s

Training epoch 726, Batch 500/1000: LR=7.12e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 726, Batch 1000/1000: LR=7.12e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 726 Train Time 38.6650276184082s

Training epoch 727, Batch 500/1000: LR=7.12e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.12e-01
Training epoch 727, Batch 1000/1000: LR=7.12e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Epoch 727 Train Time 38.685981035232544s

Training epoch 728, Batch 500/1000: LR=7.11e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 728, Batch 1000/1000: LR=7.11e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 728 Train Time 38.68216514587402s

Training epoch 729, Batch 500/1000: LR=7.10e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 729, Batch 1000/1000: LR=7.10e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 729 Train Time 38.663058042526245s

Training epoch 730, Batch 500/1000: LR=7.09e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 730, Batch 1000/1000: LR=7.09e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 730 Train Time 38.67779564857483s

Training epoch 731, Batch 500/1000: LR=7.09e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 731, Batch 1000/1000: LR=7.09e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 731 Train Time 38.673234939575195s

Training epoch 732, Batch 500/1000: LR=7.08e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 732, Batch 1000/1000: LR=7.08e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 732 Train Time 38.7890465259552s

Training epoch 733, Batch 500/1000: LR=7.07e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 733, Batch 1000/1000: LR=7.07e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 733 Train Time 38.68607997894287s

Training epoch 734, Batch 500/1000: LR=7.07e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 734, Batch 1000/1000: LR=7.07e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 734 Train Time 38.71991205215454s

Training epoch 735, Batch 500/1000: LR=7.06e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 735, Batch 1000/1000: LR=7.06e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 735 Train Time 38.82853865623474s

Training epoch 736, Batch 500/1000: LR=7.05e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 736, Batch 1000/1000: LR=7.05e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 736 Train Time 38.68124747276306s

Training epoch 737, Batch 500/1000: LR=7.04e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 737, Batch 1000/1000: LR=7.04e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 737 Train Time 38.675748109817505s

Training epoch 738, Batch 500/1000: LR=7.04e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 738, Batch 1000/1000: LR=7.04e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 738 Train Time 38.67520809173584s

Training epoch 739, Batch 500/1000: LR=7.03e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 739, Batch 1000/1000: LR=7.03e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 739 Train Time 39.0093150138855s

Training epoch 740, Batch 500/1000: LR=7.02e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 740, Batch 1000/1000: LR=7.02e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 740 Train Time 38.673107385635376s

Training epoch 741, Batch 500/1000: LR=7.02e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 741, Batch 1000/1000: LR=7.02e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 741 Train Time 38.688185691833496s

Training epoch 742, Batch 500/1000: LR=7.01e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 742, Batch 1000/1000: LR=7.01e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 742 Train Time 39.21192955970764s

Training epoch 743, Batch 500/1000: LR=7.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 743, Batch 1000/1000: LR=7.00e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 743 Train Time 38.717318296432495s

Training epoch 744, Batch 500/1000: LR=6.99e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 744, Batch 1000/1000: LR=6.99e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.10e-01
Epoch 744 Train Time 38.83729934692383s

Training epoch 745, Batch 500/1000: LR=6.99e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 745, Batch 1000/1000: LR=6.99e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 745 Train Time 38.676008462905884s

Training epoch 746, Batch 500/1000: LR=6.98e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 746, Batch 1000/1000: LR=6.98e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 746 Train Time 38.69819092750549s

Training epoch 747, Batch 500/1000: LR=6.97e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 747, Batch 1000/1000: LR=6.97e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 747 Train Time 38.75208282470703s

Training epoch 748, Batch 500/1000: LR=6.97e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 748, Batch 1000/1000: LR=6.97e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 748 Train Time 38.667080879211426s

Training epoch 749, Batch 500/1000: LR=6.96e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 749, Batch 1000/1000: LR=6.96e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 749 Train Time 38.72146439552307s

Training epoch 750, Batch 500/1000: LR=6.95e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 750, Batch 1000/1000: LR=6.95e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 750 Train Time 38.69371485710144s

Training epoch 751, Batch 500/1000: LR=6.94e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 751, Batch 1000/1000: LR=6.94e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 751 Train Time 38.65963125228882s

Training epoch 752, Batch 500/1000: LR=6.94e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 752, Batch 1000/1000: LR=6.94e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 752 Train Time 38.663379430770874s

Training epoch 753, Batch 500/1000: LR=6.93e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 753, Batch 1000/1000: LR=6.93e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 753 Train Time 38.80265665054321s

Training epoch 754, Batch 500/1000: LR=6.92e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 754, Batch 1000/1000: LR=6.92e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 754 Train Time 38.39267587661743s

Training epoch 755, Batch 500/1000: LR=6.92e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 755, Batch 1000/1000: LR=6.92e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 755 Train Time 38.27621531486511s

Training epoch 756, Batch 500/1000: LR=6.91e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 756, Batch 1000/1000: LR=6.91e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 756 Train Time 38.248863697052s

Training epoch 757, Batch 500/1000: LR=6.90e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 757, Batch 1000/1000: LR=6.90e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 757 Train Time 38.27705764770508s

Training epoch 758, Batch 500/1000: LR=6.89e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 758, Batch 1000/1000: LR=6.89e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 758 Train Time 38.24210715293884s

Training epoch 759, Batch 500/1000: LR=6.89e-05, Loss=2.94e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 759, Batch 1000/1000: LR=6.89e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 759 Train Time 38.23347091674805s

Training epoch 760, Batch 500/1000: LR=6.88e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 760, Batch 1000/1000: LR=6.88e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 760 Train Time 38.26716709136963s

Training epoch 761, Batch 500/1000: LR=6.87e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 761, Batch 1000/1000: LR=6.87e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 761 Train Time 38.25168538093567s

Training epoch 762, Batch 500/1000: LR=6.86e-05, Loss=3.01e-02 BER=1.22e-02 FER=1.12e-01
Training epoch 762, Batch 1000/1000: LR=6.86e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.10e-01
Epoch 762 Train Time 38.25998306274414s

Training epoch 763, Batch 500/1000: LR=6.86e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 763, Batch 1000/1000: LR=6.86e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 763 Train Time 79.69679617881775s

Training epoch 764, Batch 500/1000: LR=6.85e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 764, Batch 1000/1000: LR=6.85e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 764 Train Time 39.03860926628113s

Training epoch 765, Batch 500/1000: LR=6.84e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 765, Batch 1000/1000: LR=6.84e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 765 Train Time 38.707271337509155s

Training epoch 766, Batch 500/1000: LR=6.84e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 766, Batch 1000/1000: LR=6.84e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 766 Train Time 38.66950869560242s

Training epoch 767, Batch 500/1000: LR=6.83e-05, Loss=2.98e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 767, Batch 1000/1000: LR=6.83e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Epoch 767 Train Time 38.72504281997681s

Training epoch 768, Batch 500/1000: LR=6.82e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 768, Batch 1000/1000: LR=6.82e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 768 Train Time 38.670172691345215s

Training epoch 769, Batch 500/1000: LR=6.81e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 769, Batch 1000/1000: LR=6.81e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 769 Train Time 38.6602303981781s

Training epoch 770, Batch 500/1000: LR=6.81e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 770, Batch 1000/1000: LR=6.81e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 770 Train Time 38.704771757125854s

Training epoch 771, Batch 500/1000: LR=6.80e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 771, Batch 1000/1000: LR=6.80e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Epoch 771 Train Time 38.67231464385986s

Training epoch 772, Batch 500/1000: LR=6.79e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 772, Batch 1000/1000: LR=6.79e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 772 Train Time 38.693933963775635s

Training epoch 773, Batch 500/1000: LR=6.79e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 773, Batch 1000/1000: LR=6.79e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 773 Train Time 38.684744358062744s

Training epoch 774, Batch 500/1000: LR=6.78e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 774, Batch 1000/1000: LR=6.78e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.09e-01
Epoch 774 Train Time 38.667340993881226s

Training epoch 775, Batch 500/1000: LR=6.77e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.11e-01
Training epoch 775, Batch 1000/1000: LR=6.77e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 775 Train Time 38.68767809867859s

Training epoch 776, Batch 500/1000: LR=6.76e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 776, Batch 1000/1000: LR=6.76e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 776 Train Time 38.68518900871277s

Training epoch 777, Batch 500/1000: LR=6.76e-05, Loss=2.87e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 777, Batch 1000/1000: LR=6.76e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 777 Train Time 38.686912059783936s

Training epoch 778, Batch 500/1000: LR=6.75e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 778, Batch 1000/1000: LR=6.75e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 778 Train Time 38.64698338508606s

Training epoch 779, Batch 500/1000: LR=6.74e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 779, Batch 1000/1000: LR=6.74e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 779 Train Time 38.73551940917969s

Training epoch 780, Batch 500/1000: LR=6.73e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 780, Batch 1000/1000: LR=6.73e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 780 Train Time 38.688525915145874s

Training epoch 781, Batch 500/1000: LR=6.73e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 781, Batch 1000/1000: LR=6.73e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 781 Train Time 38.69134998321533s

Training epoch 782, Batch 500/1000: LR=6.72e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 782, Batch 1000/1000: LR=6.72e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 782 Train Time 38.812756061553955s

Training epoch 783, Batch 500/1000: LR=6.71e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 783, Batch 1000/1000: LR=6.71e-05, Loss=2.93e-02 BER=1.20e-02 FER=1.10e-01
Epoch 783 Train Time 38.6654531955719s

Training epoch 784, Batch 500/1000: LR=6.70e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 784, Batch 1000/1000: LR=6.70e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 784 Train Time 38.66533327102661s

Training epoch 785, Batch 500/1000: LR=6.70e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 785, Batch 1000/1000: LR=6.70e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 785 Train Time 38.67462730407715s

Training epoch 786, Batch 500/1000: LR=6.69e-05, Loss=2.90e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 786, Batch 1000/1000: LR=6.69e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 786 Train Time 38.66943001747131s

Training epoch 787, Batch 500/1000: LR=6.68e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 787, Batch 1000/1000: LR=6.68e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 787 Train Time 38.67206311225891s

Training epoch 788, Batch 500/1000: LR=6.68e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 788, Batch 1000/1000: LR=6.68e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Epoch 788 Train Time 38.6812801361084s

Training epoch 789, Batch 500/1000: LR=6.67e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 789, Batch 1000/1000: LR=6.67e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 789 Train Time 38.698288917541504s

Training epoch 790, Batch 500/1000: LR=6.66e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 790, Batch 1000/1000: LR=6.66e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 790 Train Time 38.68546462059021s

Training epoch 791, Batch 500/1000: LR=6.65e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 791, Batch 1000/1000: LR=6.65e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 791 Train Time 38.772082805633545s

Training epoch 792, Batch 500/1000: LR=6.65e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 792, Batch 1000/1000: LR=6.65e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 792 Train Time 38.66101837158203s

Training epoch 793, Batch 500/1000: LR=6.64e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 793, Batch 1000/1000: LR=6.64e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 793 Train Time 38.67295861244202s

Training epoch 794, Batch 500/1000: LR=6.63e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 794, Batch 1000/1000: LR=6.63e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 794 Train Time 38.681068658828735s

Training epoch 795, Batch 500/1000: LR=6.62e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 795, Batch 1000/1000: LR=6.62e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 795 Train Time 38.656543254852295s

Training epoch 796, Batch 500/1000: LR=6.62e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 796, Batch 1000/1000: LR=6.62e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 796 Train Time 38.697328329086304s

Training epoch 797, Batch 500/1000: LR=6.61e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 797, Batch 1000/1000: LR=6.61e-05, Loss=2.93e-02 BER=1.18e-02 FER=1.09e-01
Epoch 797 Train Time 38.68013048171997s

Training epoch 798, Batch 500/1000: LR=6.60e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 798, Batch 1000/1000: LR=6.60e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Epoch 798 Train Time 38.65035843849182s

Training epoch 799, Batch 500/1000: LR=6.59e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 799, Batch 1000/1000: LR=6.59e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 799 Train Time 38.78458786010742s

Training epoch 800, Batch 500/1000: LR=6.59e-05, Loss=2.97e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 800, Batch 1000/1000: LR=6.59e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 800 Train Time 38.592780351638794s

Training epoch 801, Batch 500/1000: LR=6.58e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 801, Batch 1000/1000: LR=6.58e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 801 Train Time 38.242647886276245s

Training epoch 802, Batch 500/1000: LR=6.57e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 802, Batch 1000/1000: LR=6.57e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 802 Train Time 38.362847566604614s

Training epoch 803, Batch 500/1000: LR=6.56e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 803, Batch 1000/1000: LR=6.56e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 803 Train Time 38.27317190170288s

Training epoch 804, Batch 500/1000: LR=6.56e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Training epoch 804, Batch 1000/1000: LR=6.56e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Epoch 804 Train Time 38.26872158050537s

Training epoch 805, Batch 500/1000: LR=6.55e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 805, Batch 1000/1000: LR=6.55e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 805 Train Time 38.25854134559631s

Training epoch 806, Batch 500/1000: LR=6.54e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 806, Batch 1000/1000: LR=6.54e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 806 Train Time 38.261688470840454s

Training epoch 807, Batch 500/1000: LR=6.54e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 807, Batch 1000/1000: LR=6.54e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 807 Train Time 38.24538207054138s

Training epoch 808, Batch 500/1000: LR=6.53e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 808, Batch 1000/1000: LR=6.53e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 808 Train Time 38.42722201347351s

Training epoch 809, Batch 500/1000: LR=6.52e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 809, Batch 1000/1000: LR=6.52e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.10e-01
Epoch 809 Train Time 38.33243012428284s

Training epoch 810, Batch 500/1000: LR=6.51e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 810, Batch 1000/1000: LR=6.51e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 810 Train Time 57.16243553161621s

Training epoch 811, Batch 500/1000: LR=6.51e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 811, Batch 1000/1000: LR=6.51e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 811 Train Time 38.81598377227783s

Training epoch 812, Batch 500/1000: LR=6.50e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 812, Batch 1000/1000: LR=6.50e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 812 Train Time 38.403626680374146s

Training epoch 813, Batch 500/1000: LR=6.49e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 813, Batch 1000/1000: LR=6.49e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 813 Train Time 38.32165789604187s

Training epoch 814, Batch 500/1000: LR=6.48e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 814, Batch 1000/1000: LR=6.48e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 814 Train Time 38.316864013671875s

Training epoch 815, Batch 500/1000: LR=6.48e-05, Loss=2.97e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 815, Batch 1000/1000: LR=6.48e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 815 Train Time 38.29054880142212s

Training epoch 816, Batch 500/1000: LR=6.47e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 816, Batch 1000/1000: LR=6.47e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 816 Train Time 38.29401469230652s

Training epoch 817, Batch 500/1000: LR=6.46e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 817, Batch 1000/1000: LR=6.46e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 817 Train Time 38.436792850494385s

Training epoch 818, Batch 500/1000: LR=6.45e-05, Loss=2.90e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 818, Batch 1000/1000: LR=6.45e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.10e-01
Epoch 818 Train Time 38.25700855255127s

Training epoch 819, Batch 500/1000: LR=6.45e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 819, Batch 1000/1000: LR=6.45e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 819 Train Time 38.28738451004028s

Training epoch 820, Batch 500/1000: LR=6.44e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 820, Batch 1000/1000: LR=6.44e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 820 Train Time 38.27485394477844s

Training epoch 821, Batch 500/1000: LR=6.43e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 821, Batch 1000/1000: LR=6.43e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 821 Train Time 38.25113534927368s

Training epoch 822, Batch 500/1000: LR=6.42e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 822, Batch 1000/1000: LR=6.42e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Epoch 822 Train Time 38.30071663856506s

Training epoch 823, Batch 500/1000: LR=6.42e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 823, Batch 1000/1000: LR=6.42e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 823 Train Time 38.2769718170166s

Training epoch 824, Batch 500/1000: LR=6.41e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 824, Batch 1000/1000: LR=6.41e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 824 Train Time 38.261470794677734s

Training epoch 825, Batch 500/1000: LR=6.40e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 825, Batch 1000/1000: LR=6.40e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 825 Train Time 38.285775661468506s

Training epoch 826, Batch 500/1000: LR=6.39e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 826, Batch 1000/1000: LR=6.39e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 826 Train Time 38.268338680267334s

Training epoch 827, Batch 500/1000: LR=6.39e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 827, Batch 1000/1000: LR=6.39e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 827 Train Time 38.31108617782593s

Training epoch 828, Batch 500/1000: LR=6.38e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 828, Batch 1000/1000: LR=6.38e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 828 Train Time 38.306828022003174s

Training epoch 829, Batch 500/1000: LR=6.37e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 829, Batch 1000/1000: LR=6.37e-05, Loss=2.91e-02 BER=1.17e-02 FER=1.08e-01
Epoch 829 Train Time 38.28998780250549s

Training epoch 830, Batch 500/1000: LR=6.36e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 830, Batch 1000/1000: LR=6.36e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Epoch 830 Train Time 38.267311573028564s

Training epoch 831, Batch 500/1000: LR=6.36e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 831, Batch 1000/1000: LR=6.36e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 831 Train Time 38.582595109939575s

Training epoch 832, Batch 500/1000: LR=6.35e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 832, Batch 1000/1000: LR=6.35e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 832 Train Time 38.303584814071655s

Training epoch 833, Batch 500/1000: LR=6.34e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 833, Batch 1000/1000: LR=6.34e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 833 Train Time 38.669087648391724s

Training epoch 834, Batch 500/1000: LR=6.33e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 834, Batch 1000/1000: LR=6.33e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 834 Train Time 38.35044479370117s

Training epoch 835, Batch 500/1000: LR=6.33e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 835, Batch 1000/1000: LR=6.33e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 835 Train Time 38.431138038635254s

Training epoch 836, Batch 500/1000: LR=6.32e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 836, Batch 1000/1000: LR=6.32e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 836 Train Time 38.27672505378723s

Training epoch 837, Batch 500/1000: LR=6.31e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 837, Batch 1000/1000: LR=6.31e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 837 Train Time 38.294888734817505s

Training epoch 838, Batch 500/1000: LR=6.30e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 838, Batch 1000/1000: LR=6.30e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 838 Train Time 38.25989127159119s

Training epoch 839, Batch 500/1000: LR=6.30e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 839, Batch 1000/1000: LR=6.30e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 839 Train Time 38.30581092834473s

Training epoch 840, Batch 500/1000: LR=6.29e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 840, Batch 1000/1000: LR=6.29e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 840 Train Time 38.27401947975159s

Training epoch 841, Batch 500/1000: LR=6.28e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 841, Batch 1000/1000: LR=6.28e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 841 Train Time 38.29092001914978s

Training epoch 842, Batch 500/1000: LR=6.27e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 842, Batch 1000/1000: LR=6.27e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 842 Train Time 38.29060244560242s

Training epoch 843, Batch 500/1000: LR=6.27e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 843, Batch 1000/1000: LR=6.27e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 843 Train Time 38.373404026031494s

Training epoch 844, Batch 500/1000: LR=6.26e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 844, Batch 1000/1000: LR=6.26e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 844 Train Time 38.27146911621094s

Training epoch 845, Batch 500/1000: LR=6.25e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 845, Batch 1000/1000: LR=6.25e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 845 Train Time 38.24421048164368s

Training epoch 846, Batch 500/1000: LR=6.24e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 846, Batch 1000/1000: LR=6.24e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 846 Train Time 38.238259077072144s

Training epoch 847, Batch 500/1000: LR=6.24e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 847, Batch 1000/1000: LR=6.24e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 847 Train Time 38.26372218132019s

Training epoch 848, Batch 500/1000: LR=6.23e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 848, Batch 1000/1000: LR=6.23e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 848 Train Time 38.251015424728394s

Training epoch 849, Batch 500/1000: LR=6.22e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 849, Batch 1000/1000: LR=6.22e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 849 Train Time 38.28576350212097s

Training epoch 850, Batch 500/1000: LR=6.21e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 850, Batch 1000/1000: LR=6.21e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 850 Train Time 38.24300789833069s

Training epoch 851, Batch 500/1000: LR=6.21e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 851, Batch 1000/1000: LR=6.21e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 851 Train Time 38.289597511291504s

Training epoch 852, Batch 500/1000: LR=6.20e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 852, Batch 1000/1000: LR=6.20e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 852 Train Time 38.38922166824341s

Training epoch 853, Batch 500/1000: LR=6.19e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 853, Batch 1000/1000: LR=6.19e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 853 Train Time 38.264641523361206s

Training epoch 854, Batch 500/1000: LR=6.18e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 854, Batch 1000/1000: LR=6.18e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 854 Train Time 38.239556550979614s

Training epoch 855, Batch 500/1000: LR=6.18e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 855, Batch 1000/1000: LR=6.18e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 855 Train Time 38.293524742126465s

Training epoch 856, Batch 500/1000: LR=6.17e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 856, Batch 1000/1000: LR=6.17e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 856 Train Time 38.26796579360962s

Training epoch 857, Batch 500/1000: LR=6.16e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 857, Batch 1000/1000: LR=6.16e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 857 Train Time 38.28144907951355s

Training epoch 858, Batch 500/1000: LR=6.15e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 858, Batch 1000/1000: LR=6.15e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 858 Train Time 87.71814131736755s

Training epoch 859, Batch 500/1000: LR=6.14e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 859, Batch 1000/1000: LR=6.14e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 859 Train Time 39.05162811279297s

Training epoch 860, Batch 500/1000: LR=6.14e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.11e-01
Training epoch 860, Batch 1000/1000: LR=6.14e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.10e-01
Epoch 860 Train Time 38.734034061431885s

Training epoch 861, Batch 500/1000: LR=6.13e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 861, Batch 1000/1000: LR=6.13e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 861 Train Time 38.700289726257324s

Training epoch 862, Batch 500/1000: LR=6.12e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 862, Batch 1000/1000: LR=6.12e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 862 Train Time 38.63695430755615s

Training epoch 863, Batch 500/1000: LR=6.11e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 863, Batch 1000/1000: LR=6.11e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 863 Train Time 38.665576457977295s

Training epoch 864, Batch 500/1000: LR=6.11e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 864, Batch 1000/1000: LR=6.11e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Epoch 864 Train Time 38.67599582672119s

Training epoch 865, Batch 500/1000: LR=6.10e-05, Loss=2.84e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 865, Batch 1000/1000: LR=6.10e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 865 Train Time 38.65577006340027s

Training epoch 866, Batch 500/1000: LR=6.09e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 866, Batch 1000/1000: LR=6.09e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 866 Train Time 38.67389702796936s

Training epoch 867, Batch 500/1000: LR=6.08e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 867, Batch 1000/1000: LR=6.08e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 867 Train Time 38.64466619491577s

Training epoch 868, Batch 500/1000: LR=6.08e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 868, Batch 1000/1000: LR=6.08e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 868 Train Time 38.66457438468933s

Training epoch 869, Batch 500/1000: LR=6.07e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 869, Batch 1000/1000: LR=6.07e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 869 Train Time 38.67223405838013s

Training epoch 870, Batch 500/1000: LR=6.06e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 870, Batch 1000/1000: LR=6.06e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 870 Train Time 38.64157962799072s

Training epoch 871, Batch 500/1000: LR=6.05e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 871, Batch 1000/1000: LR=6.05e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 871 Train Time 38.67634963989258s

Training epoch 872, Batch 500/1000: LR=6.05e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 872, Batch 1000/1000: LR=6.05e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 872 Train Time 38.70093083381653s

Training epoch 873, Batch 500/1000: LR=6.04e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 873, Batch 1000/1000: LR=6.04e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 873 Train Time 38.77303433418274s

Training epoch 874, Batch 500/1000: LR=6.03e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 874, Batch 1000/1000: LR=6.03e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 874 Train Time 38.6947922706604s

Training epoch 875, Batch 500/1000: LR=6.02e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 875, Batch 1000/1000: LR=6.02e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 875 Train Time 38.675527572631836s

Training epoch 876, Batch 500/1000: LR=6.02e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 876, Batch 1000/1000: LR=6.02e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 876 Train Time 38.65294170379639s

Training epoch 877, Batch 500/1000: LR=6.01e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 877, Batch 1000/1000: LR=6.01e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 877 Train Time 38.66943573951721s

Training epoch 878, Batch 500/1000: LR=6.00e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 878, Batch 1000/1000: LR=6.00e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.09e-01
Epoch 878 Train Time 38.63917112350464s

Training epoch 879, Batch 500/1000: LR=5.99e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 879, Batch 1000/1000: LR=5.99e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 879 Train Time 38.6998085975647s

Training epoch 880, Batch 500/1000: LR=5.99e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 880, Batch 1000/1000: LR=5.99e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 880 Train Time 38.64798021316528s

Training epoch 881, Batch 500/1000: LR=5.98e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 881, Batch 1000/1000: LR=5.98e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 881 Train Time 38.641451835632324s

Training epoch 882, Batch 500/1000: LR=5.97e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 882, Batch 1000/1000: LR=5.97e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 882 Train Time 38.68924808502197s

Training epoch 883, Batch 500/1000: LR=5.96e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 883, Batch 1000/1000: LR=5.96e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 883 Train Time 38.791794300079346s

Training epoch 884, Batch 500/1000: LR=5.95e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 884, Batch 1000/1000: LR=5.95e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 884 Train Time 38.68858790397644s

Training epoch 885, Batch 500/1000: LR=5.95e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 885, Batch 1000/1000: LR=5.95e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 885 Train Time 38.666242837905884s

Training epoch 886, Batch 500/1000: LR=5.94e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 886, Batch 1000/1000: LR=5.94e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 886 Train Time 38.67087507247925s

Training epoch 887, Batch 500/1000: LR=5.93e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 887, Batch 1000/1000: LR=5.93e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 887 Train Time 38.512439489364624s

Training epoch 888, Batch 500/1000: LR=5.92e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 888, Batch 1000/1000: LR=5.92e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 888 Train Time 38.23978805541992s

Training epoch 889, Batch 500/1000: LR=5.92e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 889, Batch 1000/1000: LR=5.92e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 889 Train Time 38.29511213302612s

Training epoch 890, Batch 500/1000: LR=5.91e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.08e-01
Training epoch 890, Batch 1000/1000: LR=5.91e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.08e-01
Epoch 890 Train Time 38.32090497016907s

Training epoch 891, Batch 500/1000: LR=5.90e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 891, Batch 1000/1000: LR=5.90e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 891 Train Time 38.300928592681885s

Training epoch 892, Batch 500/1000: LR=5.89e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 892, Batch 1000/1000: LR=5.89e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 892 Train Time 38.219239711761475s

Training epoch 893, Batch 500/1000: LR=5.89e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 893, Batch 1000/1000: LR=5.89e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 893 Train Time 38.24878644943237s

Training epoch 894, Batch 500/1000: LR=5.88e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 894, Batch 1000/1000: LR=5.88e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 894 Train Time 38.270249366760254s

Training epoch 895, Batch 500/1000: LR=5.87e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 895, Batch 1000/1000: LR=5.87e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 895 Train Time 38.26412868499756s

Training epoch 896, Batch 500/1000: LR=5.86e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 896, Batch 1000/1000: LR=5.86e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 896 Train Time 38.21809792518616s

Training epoch 897, Batch 500/1000: LR=5.86e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 897, Batch 1000/1000: LR=5.86e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 897 Train Time 38.30305814743042s

Training epoch 898, Batch 500/1000: LR=5.85e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 898, Batch 1000/1000: LR=5.85e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 898 Train Time 38.24957084655762s

Training epoch 899, Batch 500/1000: LR=5.84e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 899, Batch 1000/1000: LR=5.84e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 899 Train Time 38.213651180267334s

Training epoch 900, Batch 500/1000: LR=5.83e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 900, Batch 1000/1000: LR=5.83e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 900 Train Time 38.24731755256653s


Test Loss 4: 8.98e-03 5: 9.80e-04 6: 4.56e-05
Test FER 4: 4.00e-02 5: 4.49e-03 6: 1.92e-04
Test BER 4: 3.20e-03 5: 3.05e-04 6: 1.26e-05
Test -ln(BER) 4: 5.74e+00 5: 8.10e+00 6: 1.13e+01
# of testing samples: [100352.0, 100352.0, 526336.0]
 Test Time 134.93138027191162 s

Training epoch 901, Batch 500/1000: LR=5.82e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 901, Batch 1000/1000: LR=5.82e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 901 Train Time 38.274170875549316s

Training epoch 902, Batch 500/1000: LR=5.82e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 902, Batch 1000/1000: LR=5.82e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 902 Train Time 56.89787316322327s

Training epoch 903, Batch 500/1000: LR=5.81e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 903, Batch 1000/1000: LR=5.81e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 903 Train Time 38.968966245651245s

Training epoch 904, Batch 500/1000: LR=5.80e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 904, Batch 1000/1000: LR=5.80e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 904 Train Time 38.78585433959961s

Training epoch 905, Batch 500/1000: LR=5.79e-05, Loss=2.81e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 905, Batch 1000/1000: LR=5.79e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 905 Train Time 38.72986960411072s

Training epoch 906, Batch 500/1000: LR=5.79e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 906, Batch 1000/1000: LR=5.79e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 906 Train Time 38.726298093795776s

Training epoch 907, Batch 500/1000: LR=5.78e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 907, Batch 1000/1000: LR=5.78e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 907 Train Time 38.723565101623535s

Training epoch 908, Batch 500/1000: LR=5.77e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 908, Batch 1000/1000: LR=5.77e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Epoch 908 Train Time 38.7638041973114s

Training epoch 909, Batch 500/1000: LR=5.76e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 909, Batch 1000/1000: LR=5.76e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 909 Train Time 38.72795128822327s

Training epoch 910, Batch 500/1000: LR=5.76e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 910, Batch 1000/1000: LR=5.76e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 910 Train Time 38.729531049728394s

Training epoch 911, Batch 500/1000: LR=5.75e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 911, Batch 1000/1000: LR=5.75e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 911 Train Time 38.715147495269775s

Training epoch 912, Batch 500/1000: LR=5.74e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 912, Batch 1000/1000: LR=5.74e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 912 Train Time 38.69967842102051s

Training epoch 913, Batch 500/1000: LR=5.73e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 913, Batch 1000/1000: LR=5.73e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 913 Train Time 38.709062814712524s

Training epoch 914, Batch 500/1000: LR=5.72e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 914, Batch 1000/1000: LR=5.72e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 914 Train Time 38.88828420639038s

Training epoch 915, Batch 500/1000: LR=5.72e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 915, Batch 1000/1000: LR=5.72e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 915 Train Time 39.18368315696716s

Training epoch 916, Batch 500/1000: LR=5.71e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 916, Batch 1000/1000: LR=5.71e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 916 Train Time 54.154364585876465s

Training epoch 917, Batch 500/1000: LR=5.70e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 917, Batch 1000/1000: LR=5.70e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 917 Train Time 39.757792472839355s

Training epoch 918, Batch 500/1000: LR=5.69e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 918, Batch 1000/1000: LR=5.69e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 918 Train Time 39.43069577217102s

Training epoch 919, Batch 500/1000: LR=5.69e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 919, Batch 1000/1000: LR=5.69e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 919 Train Time 40.45625019073486s

Training epoch 920, Batch 500/1000: LR=5.68e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 920, Batch 1000/1000: LR=5.68e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 920 Train Time 39.76439714431763s

Training epoch 921, Batch 500/1000: LR=5.67e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 921, Batch 1000/1000: LR=5.67e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 921 Train Time 39.13515758514404s

Training epoch 922, Batch 500/1000: LR=5.66e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 922, Batch 1000/1000: LR=5.66e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 922 Train Time 39.44251036643982s

Training epoch 923, Batch 500/1000: LR=5.65e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 923, Batch 1000/1000: LR=5.65e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 923 Train Time 39.891714334487915s

Training epoch 924, Batch 500/1000: LR=5.65e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 924, Batch 1000/1000: LR=5.65e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 924 Train Time 39.752206325531006s

Training epoch 925, Batch 500/1000: LR=5.64e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 925, Batch 1000/1000: LR=5.64e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 925 Train Time 39.0896782875061s

Training epoch 926, Batch 500/1000: LR=5.63e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 926, Batch 1000/1000: LR=5.63e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 926 Train Time 38.999752044677734s

Training epoch 927, Batch 500/1000: LR=5.62e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 927, Batch 1000/1000: LR=5.62e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 927 Train Time 38.767014026641846s

Training epoch 928, Batch 500/1000: LR=5.62e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 928, Batch 1000/1000: LR=5.62e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 928 Train Time 38.72506666183472s

Training epoch 929, Batch 500/1000: LR=5.61e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 929, Batch 1000/1000: LR=5.61e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 929 Train Time 38.78655219078064s

Training epoch 930, Batch 500/1000: LR=5.60e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 930, Batch 1000/1000: LR=5.60e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 930 Train Time 38.8387336730957s

Training epoch 931, Batch 500/1000: LR=5.59e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 931, Batch 1000/1000: LR=5.59e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 931 Train Time 38.71721625328064s

Training epoch 932, Batch 500/1000: LR=5.59e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 932, Batch 1000/1000: LR=5.59e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 932 Train Time 38.81076240539551s

Training epoch 933, Batch 500/1000: LR=5.58e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 933, Batch 1000/1000: LR=5.58e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Epoch 933 Train Time 38.59987783432007s

Training epoch 934, Batch 500/1000: LR=5.57e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 934, Batch 1000/1000: LR=5.57e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 934 Train Time 38.33975434303284s

Training epoch 935, Batch 500/1000: LR=5.56e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 935, Batch 1000/1000: LR=5.56e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 935 Train Time 38.32703757286072s

Training epoch 936, Batch 500/1000: LR=5.55e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 936, Batch 1000/1000: LR=5.55e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 936 Train Time 38.29603433609009s

Training epoch 937, Batch 500/1000: LR=5.55e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 937, Batch 1000/1000: LR=5.55e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 937 Train Time 38.34304237365723s

Training epoch 938, Batch 500/1000: LR=5.54e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 938, Batch 1000/1000: LR=5.54e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 938 Train Time 38.403239250183105s

Training epoch 939, Batch 500/1000: LR=5.53e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 939, Batch 1000/1000: LR=5.53e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 939 Train Time 38.41571259498596s

Training epoch 940, Batch 500/1000: LR=5.52e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 940, Batch 1000/1000: LR=5.52e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 940 Train Time 38.34489846229553s

Training epoch 941, Batch 500/1000: LR=5.52e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 941, Batch 1000/1000: LR=5.52e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 941 Train Time 38.383317708969116s

Training epoch 942, Batch 500/1000: LR=5.51e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 942, Batch 1000/1000: LR=5.51e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 942 Train Time 38.32628536224365s

Training epoch 943, Batch 500/1000: LR=5.50e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 943, Batch 1000/1000: LR=5.50e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 943 Train Time 38.32357835769653s

Training epoch 944, Batch 500/1000: LR=5.49e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 944, Batch 1000/1000: LR=5.49e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 944 Train Time 38.286842823028564s

Training epoch 945, Batch 500/1000: LR=5.48e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 945, Batch 1000/1000: LR=5.48e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Epoch 945 Train Time 38.30536437034607s

Training epoch 946, Batch 500/1000: LR=5.48e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 946, Batch 1000/1000: LR=5.48e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 946 Train Time 38.319231271743774s

Training epoch 947, Batch 500/1000: LR=5.47e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 947, Batch 1000/1000: LR=5.47e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 947 Train Time 38.3014178276062s

Training epoch 948, Batch 500/1000: LR=5.46e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 948, Batch 1000/1000: LR=5.46e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 948 Train Time 38.43676400184631s

Training epoch 949, Batch 500/1000: LR=5.45e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 949, Batch 1000/1000: LR=5.45e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 949 Train Time 38.30142378807068s

Training epoch 950, Batch 500/1000: LR=5.45e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 950, Batch 1000/1000: LR=5.45e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 950 Train Time 38.30503749847412s

Training epoch 951, Batch 500/1000: LR=5.44e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 951, Batch 1000/1000: LR=5.44e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 951 Train Time 38.29317593574524s

Training epoch 952, Batch 500/1000: LR=5.43e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 952, Batch 1000/1000: LR=5.43e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 952 Train Time 38.326281785964966s

Training epoch 953, Batch 500/1000: LR=5.42e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 953, Batch 1000/1000: LR=5.42e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 953 Train Time 38.2754225730896s

Training epoch 954, Batch 500/1000: LR=5.42e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 954, Batch 1000/1000: LR=5.42e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 954 Train Time 38.27734375s

Training epoch 955, Batch 500/1000: LR=5.41e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 955, Batch 1000/1000: LR=5.41e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 955 Train Time 38.307145833969116s

Training epoch 956, Batch 500/1000: LR=5.40e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 956, Batch 1000/1000: LR=5.40e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 956 Train Time 38.33726668357849s

Training epoch 957, Batch 500/1000: LR=5.39e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 957, Batch 1000/1000: LR=5.39e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 957 Train Time 38.410510301589966s

Training epoch 958, Batch 500/1000: LR=5.38e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 958, Batch 1000/1000: LR=5.38e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 958 Train Time 38.434926986694336s

Training epoch 959, Batch 500/1000: LR=5.38e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 959, Batch 1000/1000: LR=5.38e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 959 Train Time 38.288095474243164s

Training epoch 960, Batch 500/1000: LR=5.37e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 960, Batch 1000/1000: LR=5.37e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 960 Train Time 38.29916477203369s

Training epoch 961, Batch 500/1000: LR=5.36e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 961, Batch 1000/1000: LR=5.36e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 961 Train Time 38.29507327079773s

Training epoch 962, Batch 500/1000: LR=5.35e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 962, Batch 1000/1000: LR=5.35e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 962 Train Time 38.309346437454224s

Training epoch 963, Batch 500/1000: LR=5.35e-05, Loss=2.95e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 963, Batch 1000/1000: LR=5.35e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 963 Train Time 38.268242835998535s

Training epoch 964, Batch 500/1000: LR=5.34e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 964, Batch 1000/1000: LR=5.34e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 964 Train Time 38.30169415473938s

Training epoch 965, Batch 500/1000: LR=5.33e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 965, Batch 1000/1000: LR=5.33e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 965 Train Time 38.28653812408447s

Training epoch 966, Batch 500/1000: LR=5.32e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 966, Batch 1000/1000: LR=5.32e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 966 Train Time 38.321697473526s

Training epoch 967, Batch 500/1000: LR=5.31e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 967, Batch 1000/1000: LR=5.31e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 967 Train Time 38.473915815353394s

Training epoch 968, Batch 500/1000: LR=5.31e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 968, Batch 1000/1000: LR=5.31e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 968 Train Time 38.28014421463013s

Training epoch 969, Batch 500/1000: LR=5.30e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 969, Batch 1000/1000: LR=5.30e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 969 Train Time 38.29337787628174s

Training epoch 970, Batch 500/1000: LR=5.29e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 970, Batch 1000/1000: LR=5.29e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.09e-01
Epoch 970 Train Time 38.2972047328949s

Training epoch 971, Batch 500/1000: LR=5.28e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 971, Batch 1000/1000: LR=5.28e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 971 Train Time 38.288926124572754s

Training epoch 972, Batch 500/1000: LR=5.28e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 972, Batch 1000/1000: LR=5.28e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 972 Train Time 38.280075550079346s

Training epoch 973, Batch 500/1000: LR=5.27e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 973, Batch 1000/1000: LR=5.27e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 973 Train Time 64.56239461898804s

Training epoch 974, Batch 500/1000: LR=5.26e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 974, Batch 1000/1000: LR=5.26e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 974 Train Time 38.785956382751465s

Training epoch 975, Batch 500/1000: LR=5.25e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 975, Batch 1000/1000: LR=5.25e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 975 Train Time 38.331122636795044s

Training epoch 976, Batch 500/1000: LR=5.24e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 976, Batch 1000/1000: LR=5.24e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 976 Train Time 38.31096315383911s

Training epoch 977, Batch 500/1000: LR=5.24e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 977, Batch 1000/1000: LR=5.24e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 977 Train Time 38.3085298538208s

Training epoch 978, Batch 500/1000: LR=5.23e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 978, Batch 1000/1000: LR=5.23e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 978 Train Time 38.285325050354004s

Training epoch 979, Batch 500/1000: LR=5.22e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 979, Batch 1000/1000: LR=5.22e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Epoch 979 Train Time 38.277602672576904s

Training epoch 980, Batch 500/1000: LR=5.21e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 980, Batch 1000/1000: LR=5.21e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Epoch 980 Train Time 38.295560121536255s

Training epoch 981, Batch 500/1000: LR=5.21e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 981, Batch 1000/1000: LR=5.21e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 981 Train Time 38.28923749923706s

Training epoch 982, Batch 500/1000: LR=5.20e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 982, Batch 1000/1000: LR=5.20e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 982 Train Time 38.31377077102661s

Training epoch 983, Batch 500/1000: LR=5.19e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 983, Batch 1000/1000: LR=5.19e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 983 Train Time 38.30010795593262s

Training epoch 984, Batch 500/1000: LR=5.18e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 984, Batch 1000/1000: LR=5.18e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 984 Train Time 38.26067852973938s

Training epoch 985, Batch 500/1000: LR=5.17e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 985, Batch 1000/1000: LR=5.17e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 985 Train Time 38.2650306224823s

Training epoch 986, Batch 500/1000: LR=5.17e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 986, Batch 1000/1000: LR=5.17e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Epoch 986 Train Time 38.28355312347412s

Training epoch 987, Batch 500/1000: LR=5.16e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 987, Batch 1000/1000: LR=5.16e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 987 Train Time 38.29337549209595s

Training epoch 988, Batch 500/1000: LR=5.15e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 988, Batch 1000/1000: LR=5.15e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 988 Train Time 38.94327259063721s

Training epoch 989, Batch 500/1000: LR=5.14e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 989, Batch 1000/1000: LR=5.14e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 989 Train Time 42.96389722824097s

Training epoch 990, Batch 500/1000: LR=5.14e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 990, Batch 1000/1000: LR=5.14e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 990 Train Time 39.03699445724487s

Training epoch 991, Batch 500/1000: LR=5.13e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 991, Batch 1000/1000: LR=5.13e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 991 Train Time 40.82276630401611s

Training epoch 992, Batch 500/1000: LR=5.12e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 992, Batch 1000/1000: LR=5.12e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 992 Train Time 38.71033835411072s

Training epoch 993, Batch 500/1000: LR=5.11e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 993, Batch 1000/1000: LR=5.11e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 993 Train Time 38.812840938568115s

Training epoch 994, Batch 500/1000: LR=5.10e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 994, Batch 1000/1000: LR=5.10e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 994 Train Time 39.13720893859863s

Training epoch 995, Batch 500/1000: LR=5.10e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 995, Batch 1000/1000: LR=5.10e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 995 Train Time 39.95252346992493s

Training epoch 996, Batch 500/1000: LR=5.09e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 996, Batch 1000/1000: LR=5.09e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 996 Train Time 39.736248254776s

Training epoch 997, Batch 500/1000: LR=5.08e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 997, Batch 1000/1000: LR=5.08e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 997 Train Time 42.01370120048523s

Training epoch 998, Batch 500/1000: LR=5.07e-05, Loss=2.95e-02 BER=1.20e-02 FER=1.10e-01
Training epoch 998, Batch 1000/1000: LR=5.07e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 998 Train Time 42.065163135528564s

Training epoch 999, Batch 500/1000: LR=5.07e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 999, Batch 1000/1000: LR=5.07e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 999 Train Time 45.154319286346436s

Training epoch 1000, Batch 500/1000: LR=5.06e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1000, Batch 1000/1000: LR=5.06e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Epoch 1000 Train Time 42.66796517372131s

Training epoch 1001, Batch 500/1000: LR=5.05e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1001, Batch 1000/1000: LR=5.05e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1001 Train Time 39.25403118133545s

Training epoch 1002, Batch 500/1000: LR=5.04e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1002, Batch 1000/1000: LR=5.04e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1002 Train Time 39.170706272125244s

Training epoch 1003, Batch 500/1000: LR=5.03e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1003, Batch 1000/1000: LR=5.03e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1003 Train Time 38.95013451576233s

Training epoch 1004, Batch 500/1000: LR=5.03e-05, Loss=2.84e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1004, Batch 1000/1000: LR=5.03e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1004 Train Time 38.964906454086304s

Training epoch 1005, Batch 500/1000: LR=5.02e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1005, Batch 1000/1000: LR=5.02e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1005 Train Time 40.33698081970215s

Training epoch 1006, Batch 500/1000: LR=5.01e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1006, Batch 1000/1000: LR=5.01e-05, Loss=2.84e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1006 Train Time 39.50808548927307s

Training epoch 1007, Batch 500/1000: LR=5.00e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1007, Batch 1000/1000: LR=5.00e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1007 Train Time 39.04393911361694s

Training epoch 1008, Batch 500/1000: LR=5.00e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.09e-01
Training epoch 1008, Batch 1000/1000: LR=5.00e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1008 Train Time 38.8735933303833s

Training epoch 1009, Batch 500/1000: LR=4.99e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1009, Batch 1000/1000: LR=4.99e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1009 Train Time 39.78124690055847s

Training epoch 1010, Batch 500/1000: LR=4.98e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1010, Batch 1000/1000: LR=4.98e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1010 Train Time 39.31597113609314s

Training epoch 1011, Batch 500/1000: LR=4.97e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1011, Batch 1000/1000: LR=4.97e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1011 Train Time 39.42351770401001s

Training epoch 1012, Batch 500/1000: LR=4.96e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1012, Batch 1000/1000: LR=4.96e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1012 Train Time 39.357996225357056s

Training epoch 1013, Batch 500/1000: LR=4.96e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1013, Batch 1000/1000: LR=4.96e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1013 Train Time 39.11199164390564s

Training epoch 1014, Batch 500/1000: LR=4.95e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1014, Batch 1000/1000: LR=4.95e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1014 Train Time 40.12441301345825s

Training epoch 1015, Batch 500/1000: LR=4.94e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1015, Batch 1000/1000: LR=4.94e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1015 Train Time 39.03441071510315s

Training epoch 1016, Batch 500/1000: LR=4.93e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1016, Batch 1000/1000: LR=4.93e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1016 Train Time 39.3397011756897s

Training epoch 1017, Batch 500/1000: LR=4.93e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 1017, Batch 1000/1000: LR=4.93e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1017 Train Time 39.18562984466553s

Training epoch 1018, Batch 500/1000: LR=4.92e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1018, Batch 1000/1000: LR=4.92e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1018 Train Time 39.00225520133972s

Training epoch 1019, Batch 500/1000: LR=4.91e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1019, Batch 1000/1000: LR=4.91e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1019 Train Time 38.939936876297s

Training epoch 1020, Batch 500/1000: LR=4.90e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1020, Batch 1000/1000: LR=4.90e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1020 Train Time 39.14193391799927s

Training epoch 1021, Batch 500/1000: LR=4.89e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1021, Batch 1000/1000: LR=4.89e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1021 Train Time 39.04091691970825s

Training epoch 1022, Batch 500/1000: LR=4.89e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1022, Batch 1000/1000: LR=4.89e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 1022 Train Time 39.01690912246704s

Training epoch 1023, Batch 500/1000: LR=4.88e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1023, Batch 1000/1000: LR=4.88e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1023 Train Time 38.97481727600098s

Training epoch 1024, Batch 500/1000: LR=4.87e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1024, Batch 1000/1000: LR=4.87e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1024 Train Time 38.93516826629639s

Training epoch 1025, Batch 500/1000: LR=4.86e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1025, Batch 1000/1000: LR=4.86e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1025 Train Time 38.996580839157104s

Training epoch 1026, Batch 500/1000: LR=4.86e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1026, Batch 1000/1000: LR=4.86e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1026 Train Time 39.183518171310425s

Training epoch 1027, Batch 500/1000: LR=4.85e-05, Loss=2.89e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1027, Batch 1000/1000: LR=4.85e-05, Loss=2.87e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1027 Train Time 40.60417819023132s

Training epoch 1028, Batch 500/1000: LR=4.84e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1028, Batch 1000/1000: LR=4.84e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.09e-01
Epoch 1028 Train Time 40.887699365615845s

Training epoch 1029, Batch 500/1000: LR=4.83e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1029, Batch 1000/1000: LR=4.83e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1029 Train Time 40.83216071128845s

Training epoch 1030, Batch 500/1000: LR=4.82e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1030, Batch 1000/1000: LR=4.82e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1030 Train Time 40.27812576293945s

Training epoch 1031, Batch 500/1000: LR=4.82e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1031, Batch 1000/1000: LR=4.82e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1031 Train Time 39.199946641922s

Training epoch 1032, Batch 500/1000: LR=4.81e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1032, Batch 1000/1000: LR=4.81e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1032 Train Time 38.843974590301514s

Training epoch 1033, Batch 500/1000: LR=4.80e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1033, Batch 1000/1000: LR=4.80e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1033 Train Time 38.8120698928833s

Training epoch 1034, Batch 500/1000: LR=4.79e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1034, Batch 1000/1000: LR=4.79e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1034 Train Time 38.80884623527527s

Training epoch 1035, Batch 500/1000: LR=4.79e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1035, Batch 1000/1000: LR=4.79e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1035 Train Time 38.82741403579712s

Training epoch 1036, Batch 500/1000: LR=4.78e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1036, Batch 1000/1000: LR=4.78e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1036 Train Time 38.96360969543457s

Training epoch 1037, Batch 500/1000: LR=4.77e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1037, Batch 1000/1000: LR=4.77e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1037 Train Time 39.03220796585083s

Training epoch 1038, Batch 500/1000: LR=4.76e-05, Loss=2.82e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1038, Batch 1000/1000: LR=4.76e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1038 Train Time 38.78386950492859s

Training epoch 1039, Batch 500/1000: LR=4.75e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 1039, Batch 1000/1000: LR=4.75e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1039 Train Time 38.80680584907532s

Training epoch 1040, Batch 500/1000: LR=4.75e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1040, Batch 1000/1000: LR=4.75e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1040 Train Time 38.792604207992554s

Training epoch 1041, Batch 500/1000: LR=4.74e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1041, Batch 1000/1000: LR=4.74e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1041 Train Time 38.77594351768494s

Training epoch 1042, Batch 500/1000: LR=4.73e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1042, Batch 1000/1000: LR=4.73e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1042 Train Time 38.79822516441345s

Training epoch 1043, Batch 500/1000: LR=4.72e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1043, Batch 1000/1000: LR=4.72e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1043 Train Time 38.810912132263184s

Training epoch 1044, Batch 500/1000: LR=4.72e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1044, Batch 1000/1000: LR=4.72e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1044 Train Time 38.799073696136475s

Training epoch 1045, Batch 500/1000: LR=4.71e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1045, Batch 1000/1000: LR=4.71e-05, Loss=2.84e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1045 Train Time 38.84884452819824s

Training epoch 1046, Batch 500/1000: LR=4.70e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1046, Batch 1000/1000: LR=4.70e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1046 Train Time 38.722273111343384s

Training epoch 1047, Batch 500/1000: LR=4.69e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1047, Batch 1000/1000: LR=4.69e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1047 Train Time 38.90013813972473s

Training epoch 1048, Batch 500/1000: LR=4.68e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1048, Batch 1000/1000: LR=4.68e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1048 Train Time 38.68566131591797s

Training epoch 1049, Batch 500/1000: LR=4.68e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1049, Batch 1000/1000: LR=4.68e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1049 Train Time 38.66967511177063s

Training epoch 1050, Batch 500/1000: LR=4.67e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1050, Batch 1000/1000: LR=4.67e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1050 Train Time 38.72296762466431s

Training epoch 1051, Batch 500/1000: LR=4.66e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1051, Batch 1000/1000: LR=4.66e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1051 Train Time 38.71591854095459s

Training epoch 1052, Batch 500/1000: LR=4.65e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1052, Batch 1000/1000: LR=4.65e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1052 Train Time 38.718724489212036s

Training epoch 1053, Batch 500/1000: LR=4.65e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 1053, Batch 1000/1000: LR=4.65e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 1053 Train Time 38.80504608154297s

Training epoch 1054, Batch 500/1000: LR=4.64e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1054, Batch 1000/1000: LR=4.64e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1054 Train Time 38.79143571853638s

Training epoch 1055, Batch 500/1000: LR=4.63e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 1055, Batch 1000/1000: LR=4.63e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Epoch 1055 Train Time 38.82082986831665s

Training epoch 1056, Batch 500/1000: LR=4.62e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1056, Batch 1000/1000: LR=4.62e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1056 Train Time 38.8183867931366s

Training epoch 1057, Batch 500/1000: LR=4.62e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1057, Batch 1000/1000: LR=4.62e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1057 Train Time 39.03885340690613s

Training epoch 1058, Batch 500/1000: LR=4.61e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1058, Batch 1000/1000: LR=4.61e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1058 Train Time 38.90189599990845s

Training epoch 1059, Batch 500/1000: LR=4.60e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1059, Batch 1000/1000: LR=4.60e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1059 Train Time 38.78742170333862s

Training epoch 1060, Batch 500/1000: LR=4.59e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1060, Batch 1000/1000: LR=4.59e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1060 Train Time 38.97770929336548s

Training epoch 1061, Batch 500/1000: LR=4.58e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1061, Batch 1000/1000: LR=4.58e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1061 Train Time 39.28564238548279s

Training epoch 1062, Batch 500/1000: LR=4.58e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1062, Batch 1000/1000: LR=4.58e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1062 Train Time 39.708794593811035s

Training epoch 1063, Batch 500/1000: LR=4.57e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1063, Batch 1000/1000: LR=4.57e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1063 Train Time 39.15091800689697s

Training epoch 1064, Batch 500/1000: LR=4.56e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1064, Batch 1000/1000: LR=4.56e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1064 Train Time 38.86136484146118s

Training epoch 1065, Batch 500/1000: LR=4.55e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1065, Batch 1000/1000: LR=4.55e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1065 Train Time 38.84236979484558s

Training epoch 1066, Batch 500/1000: LR=4.55e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1066, Batch 1000/1000: LR=4.55e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1066 Train Time 38.79963684082031s

Training epoch 1067, Batch 500/1000: LR=4.54e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1067, Batch 1000/1000: LR=4.54e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1067 Train Time 38.93927574157715s

Training epoch 1068, Batch 500/1000: LR=4.53e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1068, Batch 1000/1000: LR=4.53e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1068 Train Time 38.92000603675842s

Training epoch 1069, Batch 500/1000: LR=4.52e-05, Loss=2.96e-02 BER=1.20e-02 FER=1.11e-01
Training epoch 1069, Batch 1000/1000: LR=4.52e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.09e-01
Epoch 1069 Train Time 38.82455039024353s

Training epoch 1070, Batch 500/1000: LR=4.51e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1070, Batch 1000/1000: LR=4.51e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1070 Train Time 38.95874500274658s

Training epoch 1071, Batch 500/1000: LR=4.51e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1071, Batch 1000/1000: LR=4.51e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1071 Train Time 38.82219171524048s

Training epoch 1072, Batch 500/1000: LR=4.50e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1072, Batch 1000/1000: LR=4.50e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1072 Train Time 38.78909635543823s

Training epoch 1073, Batch 500/1000: LR=4.49e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1073, Batch 1000/1000: LR=4.49e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1073 Train Time 38.838533878326416s

Training epoch 1074, Batch 500/1000: LR=4.48e-05, Loss=2.99e-02 BER=1.22e-02 FER=1.10e-01
Training epoch 1074, Batch 1000/1000: LR=4.48e-05, Loss=2.95e-02 BER=1.21e-02 FER=1.10e-01
Epoch 1074 Train Time 38.80961012840271s

Training epoch 1075, Batch 500/1000: LR=4.48e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1075, Batch 1000/1000: LR=4.48e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1075 Train Time 39.608994245529175s

Training epoch 1076, Batch 500/1000: LR=4.47e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 1076, Batch 1000/1000: LR=4.47e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Epoch 1076 Train Time 38.9640052318573s

Training epoch 1077, Batch 500/1000: LR=4.46e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1077, Batch 1000/1000: LR=4.46e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1077 Train Time 38.996482372283936s

Training epoch 1078, Batch 500/1000: LR=4.45e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1078, Batch 1000/1000: LR=4.45e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1078 Train Time 38.85577368736267s

Training epoch 1079, Batch 500/1000: LR=4.45e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1079, Batch 1000/1000: LR=4.45e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1079 Train Time 38.79172396659851s

Training epoch 1080, Batch 500/1000: LR=4.44e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1080, Batch 1000/1000: LR=4.44e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1080 Train Time 38.820908546447754s

Training epoch 1081, Batch 500/1000: LR=4.43e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1081, Batch 1000/1000: LR=4.43e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1081 Train Time 38.814555644989014s

Training epoch 1082, Batch 500/1000: LR=4.42e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1082, Batch 1000/1000: LR=4.42e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1082 Train Time 39.133137464523315s

Training epoch 1083, Batch 500/1000: LR=4.41e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1083, Batch 1000/1000: LR=4.41e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1083 Train Time 39.005048513412476s

Training epoch 1084, Batch 500/1000: LR=4.41e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1084, Batch 1000/1000: LR=4.41e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1084 Train Time 38.97591304779053s

Training epoch 1085, Batch 500/1000: LR=4.40e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1085, Batch 1000/1000: LR=4.40e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1085 Train Time 38.989794969558716s

Training epoch 1086, Batch 500/1000: LR=4.39e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.09e-01
Training epoch 1086, Batch 1000/1000: LR=4.39e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1086 Train Time 39.12461996078491s

Training epoch 1087, Batch 500/1000: LR=4.38e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1087, Batch 1000/1000: LR=4.38e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1087 Train Time 39.14278793334961s

Training epoch 1088, Batch 500/1000: LR=4.38e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1088, Batch 1000/1000: LR=4.38e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1088 Train Time 38.70456528663635s

Training epoch 1089, Batch 500/1000: LR=4.37e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1089, Batch 1000/1000: LR=4.37e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1089 Train Time 38.696962118148804s

Training epoch 1090, Batch 500/1000: LR=4.36e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1090, Batch 1000/1000: LR=4.36e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1090 Train Time 38.708290576934814s

Training epoch 1091, Batch 500/1000: LR=4.35e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1091, Batch 1000/1000: LR=4.35e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Epoch 1091 Train Time 39.645320415496826s

Training epoch 1092, Batch 500/1000: LR=4.34e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1092, Batch 1000/1000: LR=4.34e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1092 Train Time 39.80915975570679s

Training epoch 1093, Batch 500/1000: LR=4.34e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1093, Batch 1000/1000: LR=4.34e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1093 Train Time 39.965272665023804s

Training epoch 1094, Batch 500/1000: LR=4.33e-05, Loss=2.96e-02 BER=1.21e-02 FER=1.10e-01
Training epoch 1094, Batch 1000/1000: LR=4.33e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1094 Train Time 39.770241498947144s

Training epoch 1095, Batch 500/1000: LR=4.32e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1095, Batch 1000/1000: LR=4.32e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1095 Train Time 39.81989336013794s

Training epoch 1096, Batch 500/1000: LR=4.31e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1096, Batch 1000/1000: LR=4.31e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1096 Train Time 40.277597427368164s

Training epoch 1097, Batch 500/1000: LR=4.31e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1097, Batch 1000/1000: LR=4.31e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1097 Train Time 42.13737154006958s

Training epoch 1098, Batch 500/1000: LR=4.30e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1098, Batch 1000/1000: LR=4.30e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1098 Train Time 41.850582122802734s

Training epoch 1099, Batch 500/1000: LR=4.29e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1099, Batch 1000/1000: LR=4.29e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1099 Train Time 42.38172149658203s

Training epoch 1100, Batch 500/1000: LR=4.28e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1100, Batch 1000/1000: LR=4.28e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1100 Train Time 43.07786798477173s

Training epoch 1101, Batch 500/1000: LR=4.28e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1101, Batch 1000/1000: LR=4.28e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.08e-01
Epoch 1101 Train Time 41.147526264190674s

Training epoch 1102, Batch 500/1000: LR=4.27e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1102, Batch 1000/1000: LR=4.27e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1102 Train Time 41.32610726356506s

Training epoch 1103, Batch 500/1000: LR=4.26e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1103, Batch 1000/1000: LR=4.26e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1103 Train Time 41.10043215751648s

Training epoch 1104, Batch 500/1000: LR=4.25e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1104, Batch 1000/1000: LR=4.25e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1104 Train Time 41.230154037475586s

Training epoch 1105, Batch 500/1000: LR=4.24e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1105, Batch 1000/1000: LR=4.24e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1105 Train Time 41.483798027038574s

Training epoch 1106, Batch 500/1000: LR=4.24e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1106, Batch 1000/1000: LR=4.24e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1106 Train Time 41.13506245613098s

Training epoch 1107, Batch 500/1000: LR=4.23e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1107, Batch 1000/1000: LR=4.23e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1107 Train Time 41.31898832321167s

Training epoch 1108, Batch 500/1000: LR=4.22e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1108, Batch 1000/1000: LR=4.22e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1108 Train Time 41.33191275596619s

Training epoch 1109, Batch 500/1000: LR=4.21e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1109, Batch 1000/1000: LR=4.21e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1109 Train Time 41.18168067932129s

Training epoch 1110, Batch 500/1000: LR=4.21e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1110, Batch 1000/1000: LR=4.21e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1110 Train Time 41.06869459152222s

Training epoch 1111, Batch 500/1000: LR=4.20e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1111, Batch 1000/1000: LR=4.20e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1111 Train Time 41.03636717796326s

Training epoch 1112, Batch 500/1000: LR=4.19e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1112, Batch 1000/1000: LR=4.19e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1112 Train Time 42.622870445251465s

Training epoch 1113, Batch 500/1000: LR=4.18e-05, Loss=2.86e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1113, Batch 1000/1000: LR=4.18e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1113 Train Time 41.50795888900757s

Training epoch 1114, Batch 500/1000: LR=4.18e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1114, Batch 1000/1000: LR=4.18e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1114 Train Time 40.18761897087097s

Training epoch 1115, Batch 500/1000: LR=4.17e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1115, Batch 1000/1000: LR=4.17e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1115 Train Time 41.14702892303467s

Training epoch 1116, Batch 500/1000: LR=4.16e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1116, Batch 1000/1000: LR=4.16e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1116 Train Time 40.94088935852051s

Training epoch 1117, Batch 500/1000: LR=4.15e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1117, Batch 1000/1000: LR=4.15e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.08e-01
Epoch 1117 Train Time 40.437039375305176s

Training epoch 1118, Batch 500/1000: LR=4.15e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1118, Batch 1000/1000: LR=4.15e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1118 Train Time 39.0222704410553s

Training epoch 1119, Batch 500/1000: LR=4.14e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1119, Batch 1000/1000: LR=4.14e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1119 Train Time 39.05597114562988s

Training epoch 1120, Batch 500/1000: LR=4.13e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1120, Batch 1000/1000: LR=4.13e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1120 Train Time 38.84811234474182s

Training epoch 1121, Batch 500/1000: LR=4.12e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1121, Batch 1000/1000: LR=4.12e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1121 Train Time 38.72933912277222s

Training epoch 1122, Batch 500/1000: LR=4.11e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 1122, Batch 1000/1000: LR=4.11e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Epoch 1122 Train Time 38.58215832710266s

Training epoch 1123, Batch 500/1000: LR=4.11e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1123, Batch 1000/1000: LR=4.11e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1123 Train Time 38.52599382400513s

Training epoch 1124, Batch 500/1000: LR=4.10e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1124, Batch 1000/1000: LR=4.10e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1124 Train Time 38.53716731071472s

Training epoch 1125, Batch 500/1000: LR=4.09e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.09e-01
Training epoch 1125, Batch 1000/1000: LR=4.09e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Epoch 1125 Train Time 38.54158020019531s

Training epoch 1126, Batch 500/1000: LR=4.08e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1126, Batch 1000/1000: LR=4.08e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1126 Train Time 38.508816719055176s

Training epoch 1127, Batch 500/1000: LR=4.08e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1127, Batch 1000/1000: LR=4.08e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1127 Train Time 38.71001482009888s

Training epoch 1128, Batch 500/1000: LR=4.07e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1128, Batch 1000/1000: LR=4.07e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1128 Train Time 38.79551649093628s

Training epoch 1129, Batch 500/1000: LR=4.06e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1129, Batch 1000/1000: LR=4.06e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1129 Train Time 38.477951765060425s

Training epoch 1130, Batch 500/1000: LR=4.05e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1130, Batch 1000/1000: LR=4.05e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1130 Train Time 38.32109999656677s

Training epoch 1131, Batch 500/1000: LR=4.05e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1131, Batch 1000/1000: LR=4.05e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1131 Train Time 38.32986521720886s

Training epoch 1132, Batch 500/1000: LR=4.04e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1132, Batch 1000/1000: LR=4.04e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1132 Train Time 38.31521916389465s

Training epoch 1133, Batch 500/1000: LR=4.03e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1133, Batch 1000/1000: LR=4.03e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1133 Train Time 38.33057165145874s

Training epoch 1134, Batch 500/1000: LR=4.02e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1134, Batch 1000/1000: LR=4.02e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1134 Train Time 38.321956634521484s

Training epoch 1135, Batch 500/1000: LR=4.02e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1135, Batch 1000/1000: LR=4.02e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1135 Train Time 38.48539400100708s

Training epoch 1136, Batch 500/1000: LR=4.01e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1136, Batch 1000/1000: LR=4.01e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1136 Train Time 38.54159998893738s

Training epoch 1137, Batch 500/1000: LR=4.00e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1137, Batch 1000/1000: LR=4.00e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1137 Train Time 38.34923696517944s

Training epoch 1138, Batch 500/1000: LR=3.99e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1138, Batch 1000/1000: LR=3.99e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1138 Train Time 38.293179750442505s

Training epoch 1139, Batch 500/1000: LR=3.99e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1139, Batch 1000/1000: LR=3.99e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1139 Train Time 38.30396366119385s

Training epoch 1140, Batch 500/1000: LR=3.98e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1140, Batch 1000/1000: LR=3.98e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1140 Train Time 38.30591130256653s

Training epoch 1141, Batch 500/1000: LR=3.97e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1141, Batch 1000/1000: LR=3.97e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1141 Train Time 38.30322456359863s

Training epoch 1142, Batch 500/1000: LR=3.96e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1142, Batch 1000/1000: LR=3.96e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1142 Train Time 38.30957651138306s

Training epoch 1143, Batch 500/1000: LR=3.96e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1143, Batch 1000/1000: LR=3.96e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1143 Train Time 38.284337759017944s

Training epoch 1144, Batch 500/1000: LR=3.95e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1144, Batch 1000/1000: LR=3.95e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1144 Train Time 38.38723134994507s

Training epoch 1145, Batch 500/1000: LR=3.94e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1145, Batch 1000/1000: LR=3.94e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1145 Train Time 38.25534677505493s

Training epoch 1146, Batch 500/1000: LR=3.93e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1146, Batch 1000/1000: LR=3.93e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1146 Train Time 38.27647876739502s

Training epoch 1147, Batch 500/1000: LR=3.92e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1147, Batch 1000/1000: LR=3.92e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1147 Train Time 38.45160722732544s

Training epoch 1148, Batch 500/1000: LR=3.92e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1148, Batch 1000/1000: LR=3.92e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1148 Train Time 38.30930042266846s

Training epoch 1149, Batch 500/1000: LR=3.91e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1149, Batch 1000/1000: LR=3.91e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1149 Train Time 38.277209758758545s

Training epoch 1150, Batch 500/1000: LR=3.90e-05, Loss=2.90e-02 BER=1.17e-02 FER=1.09e-01
Training epoch 1150, Batch 1000/1000: LR=3.90e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1150 Train Time 38.273361682891846s

Training epoch 1151, Batch 500/1000: LR=3.89e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1151, Batch 1000/1000: LR=3.89e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1151 Train Time 38.27739405632019s

Training epoch 1152, Batch 500/1000: LR=3.89e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1152, Batch 1000/1000: LR=3.89e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1152 Train Time 38.27985668182373s

Training epoch 1153, Batch 500/1000: LR=3.88e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1153, Batch 1000/1000: LR=3.88e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1153 Train Time 38.2802152633667s

Training epoch 1154, Batch 500/1000: LR=3.87e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1154, Batch 1000/1000: LR=3.87e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1154 Train Time 38.28507399559021s

Training epoch 1155, Batch 500/1000: LR=3.86e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1155, Batch 1000/1000: LR=3.86e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1155 Train Time 38.26818108558655s

Training epoch 1156, Batch 500/1000: LR=3.86e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1156, Batch 1000/1000: LR=3.86e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1156 Train Time 38.3222234249115s

Training epoch 1157, Batch 500/1000: LR=3.85e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1157, Batch 1000/1000: LR=3.85e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1157 Train Time 38.64857864379883s

Training epoch 1158, Batch 500/1000: LR=3.84e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1158, Batch 1000/1000: LR=3.84e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1158 Train Time 38.34749984741211s

Training epoch 1159, Batch 500/1000: LR=3.83e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1159, Batch 1000/1000: LR=3.83e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1159 Train Time 38.334657192230225s

Training epoch 1160, Batch 500/1000: LR=3.83e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1160, Batch 1000/1000: LR=3.83e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1160 Train Time 38.224536180496216s

Training epoch 1161, Batch 500/1000: LR=3.82e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1161, Batch 1000/1000: LR=3.82e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1161 Train Time 38.27872157096863s

Training epoch 1162, Batch 500/1000: LR=3.81e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1162, Batch 1000/1000: LR=3.81e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1162 Train Time 38.272374629974365s

Training epoch 1163, Batch 500/1000: LR=3.80e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1163, Batch 1000/1000: LR=3.80e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1163 Train Time 38.2728967666626s

Training epoch 1164, Batch 500/1000: LR=3.80e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1164, Batch 1000/1000: LR=3.80e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1164 Train Time 38.277918100357056s

Training epoch 1165, Batch 500/1000: LR=3.79e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1165, Batch 1000/1000: LR=3.79e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1165 Train Time 38.255300998687744s

Training epoch 1166, Batch 500/1000: LR=3.78e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1166, Batch 1000/1000: LR=3.78e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1166 Train Time 38.30627918243408s

Training epoch 1167, Batch 500/1000: LR=3.77e-05, Loss=2.78e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1167, Batch 1000/1000: LR=3.77e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1167 Train Time 38.47296166419983s

Training epoch 1168, Batch 500/1000: LR=3.77e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1168, Batch 1000/1000: LR=3.77e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1168 Train Time 38.27766442298889s

Training epoch 1169, Batch 500/1000: LR=3.76e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1169, Batch 1000/1000: LR=3.76e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1169 Train Time 38.27347922325134s

Training epoch 1170, Batch 500/1000: LR=3.75e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1170, Batch 1000/1000: LR=3.75e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1170 Train Time 38.24492907524109s

Training epoch 1171, Batch 500/1000: LR=3.74e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1171, Batch 1000/1000: LR=3.74e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1171 Train Time 38.251327991485596s

Training epoch 1172, Batch 500/1000: LR=3.74e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1172, Batch 1000/1000: LR=3.74e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1172 Train Time 38.30591416358948s

Training epoch 1173, Batch 500/1000: LR=3.73e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1173, Batch 1000/1000: LR=3.73e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1173 Train Time 38.258249282836914s

Training epoch 1174, Batch 500/1000: LR=3.72e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1174, Batch 1000/1000: LR=3.72e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1174 Train Time 38.253777742385864s

Training epoch 1175, Batch 500/1000: LR=3.71e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1175, Batch 1000/1000: LR=3.71e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1175 Train Time 38.28251624107361s

Training epoch 1176, Batch 500/1000: LR=3.71e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1176, Batch 1000/1000: LR=3.71e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1176 Train Time 64.30318284034729s

Training epoch 1177, Batch 500/1000: LR=3.70e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1177, Batch 1000/1000: LR=3.70e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1177 Train Time 39.41255021095276s

Training epoch 1178, Batch 500/1000: LR=3.69e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1178, Batch 1000/1000: LR=3.69e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1178 Train Time 38.81175684928894s

Training epoch 1179, Batch 500/1000: LR=3.68e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1179, Batch 1000/1000: LR=3.68e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1179 Train Time 38.68220520019531s

Training epoch 1180, Batch 500/1000: LR=3.68e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.07e-01
Training epoch 1180, Batch 1000/1000: LR=3.68e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1180 Train Time 38.69265031814575s

Training epoch 1181, Batch 500/1000: LR=3.67e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1181, Batch 1000/1000: LR=3.67e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1181 Train Time 38.70954656600952s

Training epoch 1182, Batch 500/1000: LR=3.66e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1182, Batch 1000/1000: LR=3.66e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1182 Train Time 38.44819712638855s

Training epoch 1183, Batch 500/1000: LR=3.65e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1183, Batch 1000/1000: LR=3.65e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1183 Train Time 38.30343580245972s

Training epoch 1184, Batch 500/1000: LR=3.65e-05, Loss=2.94e-02 BER=1.20e-02 FER=1.09e-01
Training epoch 1184, Batch 1000/1000: LR=3.65e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.08e-01
Epoch 1184 Train Time 38.296302318573s

Training epoch 1185, Batch 500/1000: LR=3.64e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1185, Batch 1000/1000: LR=3.64e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1185 Train Time 38.27190041542053s

Training epoch 1186, Batch 500/1000: LR=3.63e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1186, Batch 1000/1000: LR=3.63e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1186 Train Time 38.277644872665405s

Training epoch 1187, Batch 500/1000: LR=3.62e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1187, Batch 1000/1000: LR=3.62e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1187 Train Time 38.26352095603943s

Training epoch 1188, Batch 500/1000: LR=3.62e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1188, Batch 1000/1000: LR=3.62e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1188 Train Time 38.3537700176239s

Training epoch 1189, Batch 500/1000: LR=3.61e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1189, Batch 1000/1000: LR=3.61e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1189 Train Time 38.44781160354614s

Training epoch 1190, Batch 500/1000: LR=3.60e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1190, Batch 1000/1000: LR=3.60e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1190 Train Time 38.26236867904663s

Training epoch 1191, Batch 500/1000: LR=3.59e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1191, Batch 1000/1000: LR=3.59e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1191 Train Time 38.27504563331604s

Training epoch 1192, Batch 500/1000: LR=3.59e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1192, Batch 1000/1000: LR=3.59e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1192 Train Time 38.372387170791626s

Training epoch 1193, Batch 500/1000: LR=3.58e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1193, Batch 1000/1000: LR=3.58e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1193 Train Time 38.265928983688354s

Training epoch 1194, Batch 500/1000: LR=3.57e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1194, Batch 1000/1000: LR=3.57e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1194 Train Time 38.527597188949585s

Training epoch 1195, Batch 500/1000: LR=3.56e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1195, Batch 1000/1000: LR=3.56e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1195 Train Time 38.29358243942261s

Training epoch 1196, Batch 500/1000: LR=3.56e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1196, Batch 1000/1000: LR=3.56e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1196 Train Time 38.304842472076416s

Training epoch 1197, Batch 500/1000: LR=3.55e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1197, Batch 1000/1000: LR=3.55e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1197 Train Time 38.292651891708374s

Training epoch 1198, Batch 500/1000: LR=3.54e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1198, Batch 1000/1000: LR=3.54e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1198 Train Time 38.26114797592163s

Training epoch 1199, Batch 500/1000: LR=3.54e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1199, Batch 1000/1000: LR=3.54e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1199 Train Time 38.288302183151245s

Training epoch 1200, Batch 500/1000: LR=3.53e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 1200, Batch 1000/1000: LR=3.53e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Epoch 1200 Train Time 38.42805242538452s


Test Loss 4: 8.76e-03 5: 9.13e-04 6: 3.57e-05
Test FER 4: 3.82e-02 5: 4.41e-03 6: 1.63e-04
Test BER 4: 3.22e-03 5: 2.98e-04 6: 9.38e-06
Test -ln(BER) 4: 5.74e+00 5: 8.12e+00 6: 1.16e+01
# of testing samples: [100352.0, 100352.0, 624640.0]
 Test Time 153.09483647346497 s

Training epoch 1201, Batch 500/1000: LR=3.52e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1201, Batch 1000/1000: LR=3.52e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1201 Train Time 38.285400390625s

Training epoch 1202, Batch 500/1000: LR=3.51e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1202, Batch 1000/1000: LR=3.51e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1202 Train Time 38.28840494155884s

Training epoch 1203, Batch 500/1000: LR=3.51e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1203, Batch 1000/1000: LR=3.51e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1203 Train Time 38.25707983970642s

Training epoch 1204, Batch 500/1000: LR=3.50e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1204, Batch 1000/1000: LR=3.50e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1204 Train Time 38.27691102027893s

Training epoch 1205, Batch 500/1000: LR=3.49e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1205, Batch 1000/1000: LR=3.49e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1205 Train Time 38.39159393310547s

Training epoch 1206, Batch 500/1000: LR=3.48e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1206, Batch 1000/1000: LR=3.48e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1206 Train Time 38.264530181884766s

Training epoch 1207, Batch 500/1000: LR=3.48e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1207, Batch 1000/1000: LR=3.48e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1207 Train Time 38.36780786514282s

Training epoch 1208, Batch 500/1000: LR=3.47e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1208, Batch 1000/1000: LR=3.47e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1208 Train Time 38.27848148345947s

Training epoch 1209, Batch 500/1000: LR=3.46e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1209, Batch 1000/1000: LR=3.46e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1209 Train Time 38.25863862037659s

Training epoch 1210, Batch 500/1000: LR=3.45e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1210, Batch 1000/1000: LR=3.45e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1210 Train Time 38.27075552940369s

Training epoch 1211, Batch 500/1000: LR=3.45e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1211, Batch 1000/1000: LR=3.45e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1211 Train Time 38.248284578323364s

Training epoch 1212, Batch 500/1000: LR=3.44e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1212, Batch 1000/1000: LR=3.44e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1212 Train Time 38.23661160469055s

Training epoch 1213, Batch 500/1000: LR=3.43e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1213, Batch 1000/1000: LR=3.43e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1213 Train Time 38.2708203792572s

Training epoch 1214, Batch 500/1000: LR=3.42e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1214, Batch 1000/1000: LR=3.42e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1214 Train Time 38.28710722923279s

Training epoch 1215, Batch 500/1000: LR=3.42e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1215, Batch 1000/1000: LR=3.42e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1215 Train Time 38.2806932926178s

Training epoch 1216, Batch 500/1000: LR=3.41e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1216, Batch 1000/1000: LR=3.41e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1216 Train Time 38.27118468284607s

Training epoch 1217, Batch 500/1000: LR=3.40e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1217, Batch 1000/1000: LR=3.40e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1217 Train Time 38.270341873168945s

Training epoch 1218, Batch 500/1000: LR=3.40e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1218, Batch 1000/1000: LR=3.40e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1218 Train Time 38.480273962020874s

Training epoch 1219, Batch 500/1000: LR=3.39e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1219, Batch 1000/1000: LR=3.39e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1219 Train Time 38.31537842750549s

Training epoch 1220, Batch 500/1000: LR=3.38e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1220, Batch 1000/1000: LR=3.38e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1220 Train Time 38.239304542541504s

Training epoch 1221, Batch 500/1000: LR=3.37e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1221, Batch 1000/1000: LR=3.37e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1221 Train Time 56.6945595741272s

Training epoch 1222, Batch 500/1000: LR=3.37e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1222, Batch 1000/1000: LR=3.37e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1222 Train Time 39.26763033866882s

Training epoch 1223, Batch 500/1000: LR=3.36e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1223, Batch 1000/1000: LR=3.36e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1223 Train Time 38.80290627479553s

Training epoch 1224, Batch 500/1000: LR=3.35e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1224, Batch 1000/1000: LR=3.35e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1224 Train Time 38.61150884628296s

Training epoch 1225, Batch 500/1000: LR=3.34e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1225, Batch 1000/1000: LR=3.34e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1225 Train Time 38.37033462524414s

Training epoch 1226, Batch 500/1000: LR=3.34e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1226, Batch 1000/1000: LR=3.34e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1226 Train Time 38.969477891922s

Training epoch 1227, Batch 500/1000: LR=3.33e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1227, Batch 1000/1000: LR=3.33e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1227 Train Time 38.569077253341675s

Training epoch 1228, Batch 500/1000: LR=3.32e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1228, Batch 1000/1000: LR=3.32e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1228 Train Time 38.346580266952515s

Training epoch 1229, Batch 500/1000: LR=3.31e-05, Loss=2.92e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1229, Batch 1000/1000: LR=3.31e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1229 Train Time 38.30192947387695s

Training epoch 1230, Batch 500/1000: LR=3.31e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1230, Batch 1000/1000: LR=3.31e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1230 Train Time 38.2987539768219s

Training epoch 1231, Batch 500/1000: LR=3.30e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 1231, Batch 1000/1000: LR=3.30e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1231 Train Time 38.27514672279358s

Training epoch 1232, Batch 500/1000: LR=3.29e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1232, Batch 1000/1000: LR=3.29e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1232 Train Time 38.31334376335144s

Training epoch 1233, Batch 500/1000: LR=3.29e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1233, Batch 1000/1000: LR=3.29e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1233 Train Time 38.3037474155426s

Training epoch 1234, Batch 500/1000: LR=3.28e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1234, Batch 1000/1000: LR=3.28e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1234 Train Time 38.27889442443848s

Training epoch 1235, Batch 500/1000: LR=3.27e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1235, Batch 1000/1000: LR=3.27e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1235 Train Time 38.28811168670654s

Training epoch 1236, Batch 500/1000: LR=3.26e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1236, Batch 1000/1000: LR=3.26e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1236 Train Time 38.27152395248413s

Training epoch 1237, Batch 500/1000: LR=3.26e-05, Loss=2.92e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1237, Batch 1000/1000: LR=3.26e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1237 Train Time 38.4306538105011s

Training epoch 1238, Batch 500/1000: LR=3.25e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1238, Batch 1000/1000: LR=3.25e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1238 Train Time 38.57134985923767s

Training epoch 1239, Batch 500/1000: LR=3.24e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1239, Batch 1000/1000: LR=3.24e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1239 Train Time 38.27193355560303s

Training epoch 1240, Batch 500/1000: LR=3.24e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1240, Batch 1000/1000: LR=3.24e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1240 Train Time 38.27025389671326s

Training epoch 1241, Batch 500/1000: LR=3.23e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1241, Batch 1000/1000: LR=3.23e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1241 Train Time 38.30910301208496s

Training epoch 1242, Batch 500/1000: LR=3.22e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1242, Batch 1000/1000: LR=3.22e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1242 Train Time 38.27429389953613s

Training epoch 1243, Batch 500/1000: LR=3.21e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1243, Batch 1000/1000: LR=3.21e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1243 Train Time 38.25646686553955s

Training epoch 1244, Batch 500/1000: LR=3.21e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1244, Batch 1000/1000: LR=3.21e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1244 Train Time 38.26676797866821s

Training epoch 1245, Batch 500/1000: LR=3.20e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1245, Batch 1000/1000: LR=3.20e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1245 Train Time 38.280808448791504s

Training epoch 1246, Batch 500/1000: LR=3.19e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1246, Batch 1000/1000: LR=3.19e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1246 Train Time 38.31654977798462s

Training epoch 1247, Batch 500/1000: LR=3.18e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1247, Batch 1000/1000: LR=3.18e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1247 Train Time 38.30038237571716s

Training epoch 1248, Batch 500/1000: LR=3.18e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1248, Batch 1000/1000: LR=3.18e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1248 Train Time 38.29713153839111s

Training epoch 1249, Batch 500/1000: LR=3.17e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1249, Batch 1000/1000: LR=3.17e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1249 Train Time 38.285996437072754s

Training epoch 1250, Batch 500/1000: LR=3.16e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1250, Batch 1000/1000: LR=3.16e-05, Loss=2.81e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1250 Train Time 38.524805545806885s

Training epoch 1251, Batch 500/1000: LR=3.16e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1251, Batch 1000/1000: LR=3.16e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1251 Train Time 38.31243324279785s

Training epoch 1252, Batch 500/1000: LR=3.15e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.05e-01
Training epoch 1252, Batch 1000/1000: LR=3.15e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1252 Train Time 38.29827857017517s

Training epoch 1253, Batch 500/1000: LR=3.14e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1253, Batch 1000/1000: LR=3.14e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1253 Train Time 38.303871154785156s

Training epoch 1254, Batch 500/1000: LR=3.13e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1254, Batch 1000/1000: LR=3.13e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1254 Train Time 38.2783043384552s

Training epoch 1255, Batch 500/1000: LR=3.13e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1255, Batch 1000/1000: LR=3.13e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1255 Train Time 38.28313159942627s

Training epoch 1256, Batch 500/1000: LR=3.12e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1256, Batch 1000/1000: LR=3.12e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1256 Train Time 38.278069496154785s

Training epoch 1257, Batch 500/1000: LR=3.11e-05, Loss=2.90e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1257, Batch 1000/1000: LR=3.11e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1257 Train Time 38.26691174507141s

Training epoch 1258, Batch 500/1000: LR=3.11e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1258, Batch 1000/1000: LR=3.11e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1258 Train Time 38.277103424072266s

Training epoch 1259, Batch 500/1000: LR=3.10e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1259, Batch 1000/1000: LR=3.10e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1259 Train Time 38.279951333999634s

Training epoch 1260, Batch 500/1000: LR=3.09e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1260, Batch 1000/1000: LR=3.09e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1260 Train Time 38.30324983596802s

Training epoch 1261, Batch 500/1000: LR=3.08e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1261, Batch 1000/1000: LR=3.08e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1261 Train Time 38.28757405281067s

Training epoch 1262, Batch 500/1000: LR=3.08e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1262, Batch 1000/1000: LR=3.08e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1262 Train Time 38.257620334625244s

Training epoch 1263, Batch 500/1000: LR=3.07e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1263, Batch 1000/1000: LR=3.07e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1263 Train Time 38.31581377983093s

Training epoch 1264, Batch 500/1000: LR=3.06e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1264, Batch 1000/1000: LR=3.06e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1264 Train Time 38.48969602584839s

Training epoch 1265, Batch 500/1000: LR=3.06e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1265, Batch 1000/1000: LR=3.06e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1265 Train Time 38.29058289527893s

Training epoch 1266, Batch 500/1000: LR=3.05e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1266, Batch 1000/1000: LR=3.05e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1266 Train Time 38.27960920333862s

Training epoch 1267, Batch 500/1000: LR=3.04e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1267, Batch 1000/1000: LR=3.04e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1267 Train Time 38.27476167678833s

Training epoch 1268, Batch 500/1000: LR=3.03e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1268, Batch 1000/1000: LR=3.03e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1268 Train Time 38.282570123672485s

Training epoch 1269, Batch 500/1000: LR=3.03e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1269, Batch 1000/1000: LR=3.03e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1269 Train Time 58.79296803474426s

Training epoch 1270, Batch 500/1000: LR=3.02e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1270, Batch 1000/1000: LR=3.02e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1270 Train Time 38.93058156967163s

Training epoch 1271, Batch 500/1000: LR=3.01e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1271, Batch 1000/1000: LR=3.01e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1271 Train Time 38.70940828323364s

Training epoch 1272, Batch 500/1000: LR=3.01e-05, Loss=2.91e-02 BER=1.19e-02 FER=1.10e-01
Training epoch 1272, Batch 1000/1000: LR=3.01e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1272 Train Time 38.65538549423218s

Training epoch 1273, Batch 500/1000: LR=3.00e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1273, Batch 1000/1000: LR=3.00e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1273 Train Time 38.31507349014282s

Training epoch 1274, Batch 500/1000: LR=2.99e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1274, Batch 1000/1000: LR=2.99e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1274 Train Time 38.32064390182495s

Training epoch 1275, Batch 500/1000: LR=2.98e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1275, Batch 1000/1000: LR=2.98e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1275 Train Time 38.27881741523743s

Training epoch 1276, Batch 500/1000: LR=2.98e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1276, Batch 1000/1000: LR=2.98e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1276 Train Time 38.34604358673096s

Training epoch 1277, Batch 500/1000: LR=2.97e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1277, Batch 1000/1000: LR=2.97e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1277 Train Time 38.53407144546509s

Training epoch 1278, Batch 500/1000: LR=2.96e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1278, Batch 1000/1000: LR=2.96e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1278 Train Time 38.322083711624146s

Training epoch 1279, Batch 500/1000: LR=2.96e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1279, Batch 1000/1000: LR=2.96e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1279 Train Time 38.31787824630737s

Training epoch 1280, Batch 500/1000: LR=2.95e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1280, Batch 1000/1000: LR=2.95e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1280 Train Time 38.30534029006958s

Training epoch 1281, Batch 500/1000: LR=2.94e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1281, Batch 1000/1000: LR=2.94e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1281 Train Time 38.32546520233154s

Training epoch 1282, Batch 500/1000: LR=2.94e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1282, Batch 1000/1000: LR=2.94e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1282 Train Time 38.28619956970215s

Training epoch 1283, Batch 500/1000: LR=2.93e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1283, Batch 1000/1000: LR=2.93e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1283 Train Time 38.61213541030884s

Training epoch 1284, Batch 500/1000: LR=2.92e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1284, Batch 1000/1000: LR=2.92e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1284 Train Time 38.777923822402954s

Training epoch 1285, Batch 500/1000: LR=2.91e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1285, Batch 1000/1000: LR=2.91e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1285 Train Time 38.5388560295105s

Training epoch 1286, Batch 500/1000: LR=2.91e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1286, Batch 1000/1000: LR=2.91e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1286 Train Time 38.34705400466919s

Training epoch 1287, Batch 500/1000: LR=2.90e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1287, Batch 1000/1000: LR=2.90e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1287 Train Time 38.30673551559448s

Training epoch 1288, Batch 500/1000: LR=2.89e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1288, Batch 1000/1000: LR=2.89e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1288 Train Time 38.32964730262756s

Training epoch 1289, Batch 500/1000: LR=2.89e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1289, Batch 1000/1000: LR=2.89e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1289 Train Time 38.70717668533325s

Training epoch 1290, Batch 500/1000: LR=2.88e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1290, Batch 1000/1000: LR=2.88e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1290 Train Time 38.47940397262573s

Training epoch 1291, Batch 500/1000: LR=2.87e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1291, Batch 1000/1000: LR=2.87e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1291 Train Time 38.32711911201477s

Training epoch 1292, Batch 500/1000: LR=2.87e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1292, Batch 1000/1000: LR=2.87e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1292 Train Time 38.34276270866394s

Training epoch 1293, Batch 500/1000: LR=2.86e-05, Loss=2.94e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1293, Batch 1000/1000: LR=2.86e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Epoch 1293 Train Time 38.5184223651886s

Training epoch 1294, Batch 500/1000: LR=2.85e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1294, Batch 1000/1000: LR=2.85e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1294 Train Time 38.35985803604126s

Training epoch 1295, Batch 500/1000: LR=2.84e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1295, Batch 1000/1000: LR=2.84e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1295 Train Time 38.33149552345276s

Training epoch 1296, Batch 500/1000: LR=2.84e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1296, Batch 1000/1000: LR=2.84e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1296 Train Time 38.268375873565674s

Training epoch 1297, Batch 500/1000: LR=2.83e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1297, Batch 1000/1000: LR=2.83e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1297 Train Time 38.288750410079956s

Training epoch 1298, Batch 500/1000: LR=2.82e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1298, Batch 1000/1000: LR=2.82e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1298 Train Time 38.294987201690674s

Training epoch 1299, Batch 500/1000: LR=2.82e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1299, Batch 1000/1000: LR=2.82e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1299 Train Time 38.29916763305664s

Training epoch 1300, Batch 500/1000: LR=2.81e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1300, Batch 1000/1000: LR=2.81e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1300 Train Time 38.31408190727234s

Training epoch 1301, Batch 500/1000: LR=2.80e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1301, Batch 1000/1000: LR=2.80e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1301 Train Time 38.34403371810913s

Training epoch 1302, Batch 500/1000: LR=2.80e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.09e-01
Training epoch 1302, Batch 1000/1000: LR=2.80e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1302 Train Time 38.318291664123535s

Training epoch 1303, Batch 500/1000: LR=2.79e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1303, Batch 1000/1000: LR=2.79e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.06e-01
Epoch 1303 Train Time 38.29853081703186s

Training epoch 1304, Batch 500/1000: LR=2.78e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1304, Batch 1000/1000: LR=2.78e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1304 Train Time 38.297093868255615s

Training epoch 1305, Batch 500/1000: LR=2.78e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1305, Batch 1000/1000: LR=2.78e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1305 Train Time 38.37824106216431s

Training epoch 1306, Batch 500/1000: LR=2.77e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1306, Batch 1000/1000: LR=2.77e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1306 Train Time 38.30669713020325s

Training epoch 1307, Batch 500/1000: LR=2.76e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1307, Batch 1000/1000: LR=2.76e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1307 Train Time 38.56537365913391s

Training epoch 1308, Batch 500/1000: LR=2.75e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1308, Batch 1000/1000: LR=2.75e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1308 Train Time 38.31031680107117s

Training epoch 1309, Batch 500/1000: LR=2.75e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1309, Batch 1000/1000: LR=2.75e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1309 Train Time 38.29524040222168s

Training epoch 1310, Batch 500/1000: LR=2.74e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1310, Batch 1000/1000: LR=2.74e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1310 Train Time 38.2974054813385s

Training epoch 1311, Batch 500/1000: LR=2.73e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1311, Batch 1000/1000: LR=2.73e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1311 Train Time 38.31214189529419s

Training epoch 1312, Batch 500/1000: LR=2.73e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1312, Batch 1000/1000: LR=2.73e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1312 Train Time 38.30734348297119s

Training epoch 1313, Batch 500/1000: LR=2.72e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1313, Batch 1000/1000: LR=2.72e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1313 Train Time 38.302329778671265s

Training epoch 1314, Batch 500/1000: LR=2.71e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1314, Batch 1000/1000: LR=2.71e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1314 Train Time 38.30971074104309s

Training epoch 1315, Batch 500/1000: LR=2.71e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1315, Batch 1000/1000: LR=2.71e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1315 Train Time 38.27850317955017s

Training epoch 1316, Batch 500/1000: LR=2.70e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1316, Batch 1000/1000: LR=2.70e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1316 Train Time 74.82792520523071s

Training epoch 1317, Batch 500/1000: LR=2.69e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1317, Batch 1000/1000: LR=2.69e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1317 Train Time 40.11634373664856s

Training epoch 1318, Batch 500/1000: LR=2.69e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1318, Batch 1000/1000: LR=2.69e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1318 Train Time 38.86217665672302s

Training epoch 1319, Batch 500/1000: LR=2.68e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1319, Batch 1000/1000: LR=2.68e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1319 Train Time 38.730263233184814s

Training epoch 1320, Batch 500/1000: LR=2.67e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1320, Batch 1000/1000: LR=2.67e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1320 Train Time 38.70292282104492s

Training epoch 1321, Batch 500/1000: LR=2.67e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1321, Batch 1000/1000: LR=2.67e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1321 Train Time 38.717400550842285s

Training epoch 1322, Batch 500/1000: LR=2.66e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1322, Batch 1000/1000: LR=2.66e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1322 Train Time 38.71400737762451s

Training epoch 1323, Batch 500/1000: LR=2.65e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1323, Batch 1000/1000: LR=2.65e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1323 Train Time 38.69733262062073s

Training epoch 1324, Batch 500/1000: LR=2.64e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1324, Batch 1000/1000: LR=2.64e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1324 Train Time 38.70924115180969s

Training epoch 1325, Batch 500/1000: LR=2.64e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1325, Batch 1000/1000: LR=2.64e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1325 Train Time 39.335994482040405s

Training epoch 1326, Batch 500/1000: LR=2.63e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1326, Batch 1000/1000: LR=2.63e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1326 Train Time 38.908812046051025s

Training epoch 1327, Batch 500/1000: LR=2.62e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1327, Batch 1000/1000: LR=2.62e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1327 Train Time 38.70723271369934s

Training epoch 1328, Batch 500/1000: LR=2.62e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1328, Batch 1000/1000: LR=2.62e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1328 Train Time 38.719475746154785s

Training epoch 1329, Batch 500/1000: LR=2.61e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1329, Batch 1000/1000: LR=2.61e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1329 Train Time 38.70657825469971s

Training epoch 1330, Batch 500/1000: LR=2.60e-05, Loss=2.72e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1330, Batch 1000/1000: LR=2.60e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1330 Train Time 38.68587779998779s

Training epoch 1331, Batch 500/1000: LR=2.60e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1331, Batch 1000/1000: LR=2.60e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1331 Train Time 38.68665170669556s

Training epoch 1332, Batch 500/1000: LR=2.59e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1332, Batch 1000/1000: LR=2.59e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1332 Train Time 38.69976234436035s

Training epoch 1333, Batch 500/1000: LR=2.58e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1333, Batch 1000/1000: LR=2.58e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1333 Train Time 38.818554162979126s

Training epoch 1334, Batch 500/1000: LR=2.58e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1334, Batch 1000/1000: LR=2.58e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1334 Train Time 38.70311117172241s

Training epoch 1335, Batch 500/1000: LR=2.57e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1335, Batch 1000/1000: LR=2.57e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1335 Train Time 38.739614725112915s

Training epoch 1336, Batch 500/1000: LR=2.56e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1336, Batch 1000/1000: LR=2.56e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1336 Train Time 38.810245513916016s

Training epoch 1337, Batch 500/1000: LR=2.56e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1337, Batch 1000/1000: LR=2.56e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1337 Train Time 38.687158823013306s

Training epoch 1338, Batch 500/1000: LR=2.55e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1338, Batch 1000/1000: LR=2.55e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Epoch 1338 Train Time 38.694415807724s

Training epoch 1339, Batch 500/1000: LR=2.54e-05, Loss=2.79e-02 BER=1.12e-02 FER=1.05e-01
Training epoch 1339, Batch 1000/1000: LR=2.54e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1339 Train Time 38.684659004211426s

Training epoch 1340, Batch 500/1000: LR=2.54e-05, Loss=2.76e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1340, Batch 1000/1000: LR=2.54e-05, Loss=2.76e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1340 Train Time 38.68199825286865s

Training epoch 1341, Batch 500/1000: LR=2.53e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1341, Batch 1000/1000: LR=2.53e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1341 Train Time 38.684526205062866s

Training epoch 1342, Batch 500/1000: LR=2.52e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1342, Batch 1000/1000: LR=2.52e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1342 Train Time 38.715699195861816s

Training epoch 1343, Batch 500/1000: LR=2.52e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1343, Batch 1000/1000: LR=2.52e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1343 Train Time 38.69961166381836s

Training epoch 1344, Batch 500/1000: LR=2.51e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1344, Batch 1000/1000: LR=2.51e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1344 Train Time 38.74405264854431s

Training epoch 1345, Batch 500/1000: LR=2.50e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1345, Batch 1000/1000: LR=2.50e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1345 Train Time 38.81962299346924s

Training epoch 1346, Batch 500/1000: LR=2.50e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1346, Batch 1000/1000: LR=2.50e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1346 Train Time 38.692413091659546s

Training epoch 1347, Batch 500/1000: LR=2.49e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1347, Batch 1000/1000: LR=2.49e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1347 Train Time 38.82528614997864s

Training epoch 1348, Batch 500/1000: LR=2.48e-05, Loss=2.93e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1348, Batch 1000/1000: LR=2.48e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1348 Train Time 39.59315514564514s

Training epoch 1349, Batch 500/1000: LR=2.48e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1349, Batch 1000/1000: LR=2.48e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1349 Train Time 38.701926946640015s

Training epoch 1350, Batch 500/1000: LR=2.47e-05, Loss=2.88e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1350, Batch 1000/1000: LR=2.47e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1350 Train Time 38.70065689086914s

Training epoch 1351, Batch 500/1000: LR=2.46e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1351, Batch 1000/1000: LR=2.46e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1351 Train Time 38.690205812454224s

Training epoch 1352, Batch 500/1000: LR=2.46e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1352, Batch 1000/1000: LR=2.46e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1352 Train Time 38.68414068222046s

Training epoch 1353, Batch 500/1000: LR=2.45e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1353, Batch 1000/1000: LR=2.45e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1353 Train Time 38.69238615036011s

Training epoch 1354, Batch 500/1000: LR=2.44e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1354, Batch 1000/1000: LR=2.44e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1354 Train Time 38.661298751831055s

Training epoch 1355, Batch 500/1000: LR=2.44e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1355, Batch 1000/1000: LR=2.44e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1355 Train Time 38.72587466239929s

Training epoch 1356, Batch 500/1000: LR=2.43e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1356, Batch 1000/1000: LR=2.43e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1356 Train Time 38.703356981277466s

Training epoch 1357, Batch 500/1000: LR=2.42e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1357, Batch 1000/1000: LR=2.42e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1357 Train Time 38.84201741218567s

Training epoch 1358, Batch 500/1000: LR=2.42e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1358, Batch 1000/1000: LR=2.42e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1358 Train Time 38.730233907699585s

Training epoch 1359, Batch 500/1000: LR=2.41e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1359, Batch 1000/1000: LR=2.41e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1359 Train Time 38.563485860824585s

Training epoch 1360, Batch 500/1000: LR=2.40e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1360, Batch 1000/1000: LR=2.40e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1360 Train Time 38.29545259475708s

Training epoch 1361, Batch 500/1000: LR=2.40e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1361, Batch 1000/1000: LR=2.40e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1361 Train Time 38.30075454711914s

Training epoch 1362, Batch 500/1000: LR=2.39e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1362, Batch 1000/1000: LR=2.39e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1362 Train Time 38.29122757911682s

Training epoch 1363, Batch 500/1000: LR=2.38e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1363, Batch 1000/1000: LR=2.38e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1363 Train Time 38.30687689781189s

Training epoch 1364, Batch 500/1000: LR=2.38e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1364, Batch 1000/1000: LR=2.38e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1364 Train Time 72.99851036071777s

Training epoch 1365, Batch 500/1000: LR=2.37e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1365, Batch 1000/1000: LR=2.37e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1365 Train Time 38.853304624557495s

Training epoch 1366, Batch 500/1000: LR=2.36e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1366, Batch 1000/1000: LR=2.36e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1366 Train Time 38.539761543273926s

Training epoch 1367, Batch 500/1000: LR=2.36e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1367, Batch 1000/1000: LR=2.36e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1367 Train Time 38.30781102180481s

Training epoch 1368, Batch 500/1000: LR=2.35e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1368, Batch 1000/1000: LR=2.35e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1368 Train Time 38.326454401016235s

Training epoch 1369, Batch 500/1000: LR=2.35e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1369, Batch 1000/1000: LR=2.35e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1369 Train Time 38.29822134971619s

Training epoch 1370, Batch 500/1000: LR=2.34e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1370, Batch 1000/1000: LR=2.34e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1370 Train Time 38.285619020462036s

Training epoch 1371, Batch 500/1000: LR=2.33e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1371, Batch 1000/1000: LR=2.33e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1371 Train Time 38.283005714416504s

Training epoch 1372, Batch 500/1000: LR=2.33e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1372, Batch 1000/1000: LR=2.33e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1372 Train Time 38.27823066711426s

Training epoch 1373, Batch 500/1000: LR=2.32e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1373, Batch 1000/1000: LR=2.32e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1373 Train Time 38.280056953430176s

Training epoch 1374, Batch 500/1000: LR=2.31e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1374, Batch 1000/1000: LR=2.31e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1374 Train Time 38.31120324134827s

Training epoch 1375, Batch 500/1000: LR=2.31e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1375, Batch 1000/1000: LR=2.31e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1375 Train Time 38.798280000686646s

Training epoch 1376, Batch 500/1000: LR=2.30e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1376, Batch 1000/1000: LR=2.30e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1376 Train Time 38.473398208618164s

Training epoch 1377, Batch 500/1000: LR=2.29e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1377, Batch 1000/1000: LR=2.29e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1377 Train Time 38.541298627853394s

Training epoch 1378, Batch 500/1000: LR=2.29e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1378, Batch 1000/1000: LR=2.29e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1378 Train Time 38.31103706359863s

Training epoch 1379, Batch 500/1000: LR=2.28e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1379, Batch 1000/1000: LR=2.28e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1379 Train Time 38.29679775238037s

Training epoch 1380, Batch 500/1000: LR=2.27e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1380, Batch 1000/1000: LR=2.27e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1380 Train Time 38.383517265319824s

Training epoch 1381, Batch 500/1000: LR=2.27e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1381, Batch 1000/1000: LR=2.27e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1381 Train Time 38.29972553253174s

Training epoch 1382, Batch 500/1000: LR=2.26e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1382, Batch 1000/1000: LR=2.26e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1382 Train Time 38.31764793395996s

Training epoch 1383, Batch 500/1000: LR=2.25e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1383, Batch 1000/1000: LR=2.25e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1383 Train Time 38.292579650878906s

Training epoch 1384, Batch 500/1000: LR=2.25e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1384, Batch 1000/1000: LR=2.25e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1384 Train Time 38.31721067428589s

Training epoch 1385, Batch 500/1000: LR=2.24e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1385, Batch 1000/1000: LR=2.24e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1385 Train Time 38.31698274612427s

Training epoch 1386, Batch 500/1000: LR=2.24e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1386, Batch 1000/1000: LR=2.24e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1386 Train Time 38.35609436035156s

Training epoch 1387, Batch 500/1000: LR=2.23e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1387, Batch 1000/1000: LR=2.23e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1387 Train Time 38.472012758255005s

Training epoch 1388, Batch 500/1000: LR=2.22e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1388, Batch 1000/1000: LR=2.22e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1388 Train Time 38.287400007247925s

Training epoch 1389, Batch 500/1000: LR=2.22e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1389, Batch 1000/1000: LR=2.22e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1389 Train Time 38.29710054397583s

Training epoch 1390, Batch 500/1000: LR=2.21e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1390, Batch 1000/1000: LR=2.21e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1390 Train Time 38.30276942253113s

Training epoch 1391, Batch 500/1000: LR=2.20e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1391, Batch 1000/1000: LR=2.20e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1391 Train Time 38.28807306289673s

Training epoch 1392, Batch 500/1000: LR=2.20e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1392, Batch 1000/1000: LR=2.20e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1392 Train Time 38.285707235336304s

Training epoch 1393, Batch 500/1000: LR=2.19e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1393, Batch 1000/1000: LR=2.19e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1393 Train Time 38.29090690612793s

Training epoch 1394, Batch 500/1000: LR=2.18e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1394, Batch 1000/1000: LR=2.18e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1394 Train Time 38.26347470283508s

Training epoch 1395, Batch 500/1000: LR=2.18e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1395, Batch 1000/1000: LR=2.18e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1395 Train Time 38.30655264854431s

Training epoch 1396, Batch 500/1000: LR=2.17e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1396, Batch 1000/1000: LR=2.17e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1396 Train Time 38.491554975509644s

Training epoch 1397, Batch 500/1000: LR=2.17e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1397, Batch 1000/1000: LR=2.17e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1397 Train Time 38.29452681541443s

Training epoch 1398, Batch 500/1000: LR=2.16e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1398, Batch 1000/1000: LR=2.16e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1398 Train Time 38.29203963279724s

Training epoch 1399, Batch 500/1000: LR=2.15e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1399, Batch 1000/1000: LR=2.15e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1399 Train Time 38.748451232910156s

Training epoch 1400, Batch 500/1000: LR=2.15e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1400, Batch 1000/1000: LR=2.15e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1400 Train Time 38.51326823234558s

Training epoch 1401, Batch 500/1000: LR=2.14e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1401, Batch 1000/1000: LR=2.14e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1401 Train Time 38.31192946434021s

Training epoch 1402, Batch 500/1000: LR=2.13e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1402, Batch 1000/1000: LR=2.13e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1402 Train Time 38.28620362281799s

Training epoch 1403, Batch 500/1000: LR=2.13e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1403, Batch 1000/1000: LR=2.13e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1403 Train Time 38.28588247299194s

Training epoch 1404, Batch 500/1000: LR=2.12e-05, Loss=2.74e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1404, Batch 1000/1000: LR=2.12e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1404 Train Time 38.304356813430786s

Training epoch 1405, Batch 500/1000: LR=2.12e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.09e-01
Training epoch 1405, Batch 1000/1000: LR=2.12e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1405 Train Time 38.27750039100647s

Training epoch 1406, Batch 500/1000: LR=2.11e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1406, Batch 1000/1000: LR=2.11e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1406 Train Time 38.480350494384766s

Training epoch 1407, Batch 500/1000: LR=2.10e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1407, Batch 1000/1000: LR=2.10e-05, Loss=2.91e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1407 Train Time 38.2795786857605s

Training epoch 1408, Batch 500/1000: LR=2.10e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1408, Batch 1000/1000: LR=2.10e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1408 Train Time 38.269946813583374s

Training epoch 1409, Batch 500/1000: LR=2.09e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1409, Batch 1000/1000: LR=2.09e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1409 Train Time 38.32357740402222s

Training epoch 1410, Batch 500/1000: LR=2.08e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1410, Batch 1000/1000: LR=2.08e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1410 Train Time 38.271000623703s

Training epoch 1411, Batch 500/1000: LR=2.08e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1411, Batch 1000/1000: LR=2.08e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1411 Train Time 79.42619609832764s

Training epoch 1412, Batch 500/1000: LR=2.07e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1412, Batch 1000/1000: LR=2.07e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1412 Train Time 39.15497398376465s

Training epoch 1413, Batch 500/1000: LR=2.07e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1413, Batch 1000/1000: LR=2.07e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1413 Train Time 38.79216718673706s

Training epoch 1414, Batch 500/1000: LR=2.06e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1414, Batch 1000/1000: LR=2.06e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1414 Train Time 38.724339962005615s

Training epoch 1415, Batch 500/1000: LR=2.05e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1415, Batch 1000/1000: LR=2.05e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1415 Train Time 38.7933509349823s

Training epoch 1416, Batch 500/1000: LR=2.05e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1416, Batch 1000/1000: LR=2.05e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1416 Train Time 38.62387681007385s

Training epoch 1417, Batch 500/1000: LR=2.04e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1417, Batch 1000/1000: LR=2.04e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1417 Train Time 38.27574634552002s

Training epoch 1418, Batch 500/1000: LR=2.03e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1418, Batch 1000/1000: LR=2.03e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1418 Train Time 38.27218317985535s

Training epoch 1419, Batch 500/1000: LR=2.03e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1419, Batch 1000/1000: LR=2.03e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1419 Train Time 38.27963662147522s

Training epoch 1420, Batch 500/1000: LR=2.02e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1420, Batch 1000/1000: LR=2.02e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1420 Train Time 38.302597761154175s

Training epoch 1421, Batch 500/1000: LR=2.02e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1421, Batch 1000/1000: LR=2.02e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1421 Train Time 38.29865002632141s

Training epoch 1422, Batch 500/1000: LR=2.01e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1422, Batch 1000/1000: LR=2.01e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1422 Train Time 38.30705404281616s

Training epoch 1423, Batch 500/1000: LR=2.00e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1423, Batch 1000/1000: LR=2.00e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1423 Train Time 38.28729748725891s

Training epoch 1424, Batch 500/1000: LR=2.00e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1424, Batch 1000/1000: LR=2.00e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1424 Train Time 38.28294658660889s

Training epoch 1425, Batch 500/1000: LR=1.99e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1425, Batch 1000/1000: LR=1.99e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1425 Train Time 38.4650764465332s

Training epoch 1426, Batch 500/1000: LR=1.99e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1426, Batch 1000/1000: LR=1.99e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1426 Train Time 38.3289852142334s

Training epoch 1427, Batch 500/1000: LR=1.98e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.08e-01
Training epoch 1427, Batch 1000/1000: LR=1.98e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1427 Train Time 38.38734769821167s

Training epoch 1428, Batch 500/1000: LR=1.97e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1428, Batch 1000/1000: LR=1.97e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1428 Train Time 38.308531284332275s

Training epoch 1429, Batch 500/1000: LR=1.97e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1429, Batch 1000/1000: LR=1.97e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1429 Train Time 38.27722930908203s

Training epoch 1430, Batch 500/1000: LR=1.96e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1430, Batch 1000/1000: LR=1.96e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1430 Train Time 38.31268930435181s

Training epoch 1431, Batch 500/1000: LR=1.96e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1431, Batch 1000/1000: LR=1.96e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1431 Train Time 38.27792263031006s

Training epoch 1432, Batch 500/1000: LR=1.95e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1432, Batch 1000/1000: LR=1.95e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1432 Train Time 38.28333568572998s

Training epoch 1433, Batch 500/1000: LR=1.94e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1433, Batch 1000/1000: LR=1.94e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1433 Train Time 38.29301643371582s

Training epoch 1434, Batch 500/1000: LR=1.94e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1434, Batch 1000/1000: LR=1.94e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1434 Train Time 38.5103542804718s

Training epoch 1435, Batch 500/1000: LR=1.93e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1435, Batch 1000/1000: LR=1.93e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1435 Train Time 38.31413269042969s

Training epoch 1436, Batch 500/1000: LR=1.92e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1436, Batch 1000/1000: LR=1.92e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1436 Train Time 38.27509784698486s

Training epoch 1437, Batch 500/1000: LR=1.92e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1437, Batch 1000/1000: LR=1.92e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1437 Train Time 38.30188488960266s

Training epoch 1438, Batch 500/1000: LR=1.91e-05, Loss=2.76e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1438, Batch 1000/1000: LR=1.91e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1438 Train Time 38.253803968429565s

Training epoch 1439, Batch 500/1000: LR=1.91e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1439, Batch 1000/1000: LR=1.91e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1439 Train Time 38.271848917007446s

Training epoch 1440, Batch 500/1000: LR=1.90e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1440, Batch 1000/1000: LR=1.90e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1440 Train Time 38.272828340530396s

Training epoch 1441, Batch 500/1000: LR=1.89e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1441, Batch 1000/1000: LR=1.89e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1441 Train Time 38.2731294631958s

Training epoch 1442, Batch 500/1000: LR=1.89e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1442, Batch 1000/1000: LR=1.89e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1442 Train Time 38.28642702102661s

Training epoch 1443, Batch 500/1000: LR=1.88e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1443, Batch 1000/1000: LR=1.88e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1443 Train Time 38.29480051994324s

Training epoch 1444, Batch 500/1000: LR=1.88e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1444, Batch 1000/1000: LR=1.88e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1444 Train Time 38.42040705680847s

Training epoch 1445, Batch 500/1000: LR=1.87e-05, Loss=2.87e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1445, Batch 1000/1000: LR=1.87e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1445 Train Time 38.2758207321167s

Training epoch 1446, Batch 500/1000: LR=1.86e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1446, Batch 1000/1000: LR=1.86e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1446 Train Time 38.2936327457428s

Training epoch 1447, Batch 500/1000: LR=1.86e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1447, Batch 1000/1000: LR=1.86e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1447 Train Time 38.302053451538086s

Training epoch 1448, Batch 500/1000: LR=1.85e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1448, Batch 1000/1000: LR=1.85e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1448 Train Time 38.275532484054565s

Training epoch 1449, Batch 500/1000: LR=1.85e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1449, Batch 1000/1000: LR=1.85e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1449 Train Time 38.308138370513916s

Training epoch 1450, Batch 500/1000: LR=1.84e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1450, Batch 1000/1000: LR=1.84e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1450 Train Time 38.28361105918884s

Training epoch 1451, Batch 500/1000: LR=1.84e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1451, Batch 1000/1000: LR=1.84e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1451 Train Time 38.30631422996521s

Training epoch 1452, Batch 500/1000: LR=1.83e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1452, Batch 1000/1000: LR=1.83e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1452 Train Time 38.29522895812988s

Training epoch 1453, Batch 500/1000: LR=1.82e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1453, Batch 1000/1000: LR=1.82e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1453 Train Time 38.402584075927734s

Training epoch 1454, Batch 500/1000: LR=1.82e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1454, Batch 1000/1000: LR=1.82e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1454 Train Time 38.28872895240784s

Training epoch 1455, Batch 500/1000: LR=1.81e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1455, Batch 1000/1000: LR=1.81e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1455 Train Time 38.286487340927124s

Training epoch 1456, Batch 500/1000: LR=1.81e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1456, Batch 1000/1000: LR=1.81e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1456 Train Time 38.38023519515991s

Training epoch 1457, Batch 500/1000: LR=1.80e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1457, Batch 1000/1000: LR=1.80e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1457 Train Time 38.28698921203613s

Training epoch 1458, Batch 500/1000: LR=1.79e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1458, Batch 1000/1000: LR=1.79e-05, Loss=2.89e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1458 Train Time 38.284226179122925s

Training epoch 1459, Batch 500/1000: LR=1.79e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1459, Batch 1000/1000: LR=1.79e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1459 Train Time 108.00417423248291s

Training epoch 1460, Batch 500/1000: LR=1.78e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1460, Batch 1000/1000: LR=1.78e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1460 Train Time 38.93206787109375s

Training epoch 1461, Batch 500/1000: LR=1.78e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1461, Batch 1000/1000: LR=1.78e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1461 Train Time 38.74103593826294s

Training epoch 1462, Batch 500/1000: LR=1.77e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1462, Batch 1000/1000: LR=1.77e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1462 Train Time 38.75055551528931s

Training epoch 1463, Batch 500/1000: LR=1.76e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1463, Batch 1000/1000: LR=1.76e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1463 Train Time 38.70518660545349s

Training epoch 1464, Batch 500/1000: LR=1.76e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1464, Batch 1000/1000: LR=1.76e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1464 Train Time 38.49318766593933s

Training epoch 1465, Batch 500/1000: LR=1.75e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1465, Batch 1000/1000: LR=1.75e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1465 Train Time 38.36129450798035s

Training epoch 1466, Batch 500/1000: LR=1.75e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1466, Batch 1000/1000: LR=1.75e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1466 Train Time 38.765113830566406s

Training epoch 1467, Batch 500/1000: LR=1.74e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1467, Batch 1000/1000: LR=1.74e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1467 Train Time 38.541951417922974s

Training epoch 1468, Batch 500/1000: LR=1.74e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1468, Batch 1000/1000: LR=1.74e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1468 Train Time 38.312989950180054s

Training epoch 1469, Batch 500/1000: LR=1.73e-05, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1469, Batch 1000/1000: LR=1.73e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1469 Train Time 38.306195974349976s

Training epoch 1470, Batch 500/1000: LR=1.72e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1470, Batch 1000/1000: LR=1.72e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1470 Train Time 38.31713795661926s

Training epoch 1471, Batch 500/1000: LR=1.72e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1471, Batch 1000/1000: LR=1.72e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1471 Train Time 38.31133031845093s

Training epoch 1472, Batch 500/1000: LR=1.71e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1472, Batch 1000/1000: LR=1.71e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1472 Train Time 38.34347701072693s

Training epoch 1473, Batch 500/1000: LR=1.71e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1473, Batch 1000/1000: LR=1.71e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1473 Train Time 38.31580400466919s

Training epoch 1474, Batch 500/1000: LR=1.70e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1474, Batch 1000/1000: LR=1.70e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1474 Train Time 38.31182837486267s

Training epoch 1475, Batch 500/1000: LR=1.70e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1475, Batch 1000/1000: LR=1.70e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1475 Train Time 38.67205858230591s

Training epoch 1476, Batch 500/1000: LR=1.69e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1476, Batch 1000/1000: LR=1.69e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1476 Train Time 38.320311546325684s

Training epoch 1477, Batch 500/1000: LR=1.68e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1477, Batch 1000/1000: LR=1.68e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1477 Train Time 38.346309661865234s

Training epoch 1478, Batch 500/1000: LR=1.68e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1478, Batch 1000/1000: LR=1.68e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1478 Train Time 38.29496645927429s

Training epoch 1479, Batch 500/1000: LR=1.67e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1479, Batch 1000/1000: LR=1.67e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1479 Train Time 38.33358883857727s

Training epoch 1480, Batch 500/1000: LR=1.67e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1480, Batch 1000/1000: LR=1.67e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.07e-01
Epoch 1480 Train Time 38.313058376312256s

Training epoch 1481, Batch 500/1000: LR=1.66e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1481, Batch 1000/1000: LR=1.66e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1481 Train Time 38.304086446762085s

Training epoch 1482, Batch 500/1000: LR=1.66e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1482, Batch 1000/1000: LR=1.66e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1482 Train Time 38.34098291397095s

Training epoch 1483, Batch 500/1000: LR=1.65e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1483, Batch 1000/1000: LR=1.65e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1483 Train Time 38.31139922142029s

Training epoch 1484, Batch 500/1000: LR=1.64e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1484, Batch 1000/1000: LR=1.64e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1484 Train Time 38.349812507629395s

Training epoch 1485, Batch 500/1000: LR=1.64e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1485, Batch 1000/1000: LR=1.64e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1485 Train Time 38.51673412322998s

Training epoch 1486, Batch 500/1000: LR=1.63e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1486, Batch 1000/1000: LR=1.63e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1486 Train Time 38.34307670593262s

Training epoch 1487, Batch 500/1000: LR=1.63e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1487, Batch 1000/1000: LR=1.63e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1487 Train Time 38.32662343978882s

Training epoch 1488, Batch 500/1000: LR=1.62e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1488, Batch 1000/1000: LR=1.62e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1488 Train Time 38.33336853981018s

Training epoch 1489, Batch 500/1000: LR=1.62e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1489, Batch 1000/1000: LR=1.62e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1489 Train Time 38.29997515678406s

Training epoch 1490, Batch 500/1000: LR=1.61e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1490, Batch 1000/1000: LR=1.61e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1490 Train Time 38.30664682388306s

Training epoch 1491, Batch 500/1000: LR=1.61e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1491, Batch 1000/1000: LR=1.61e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1491 Train Time 38.29871678352356s

Training epoch 1492, Batch 500/1000: LR=1.60e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1492, Batch 1000/1000: LR=1.60e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1492 Train Time 38.30822992324829s

Training epoch 1493, Batch 500/1000: LR=1.59e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1493, Batch 1000/1000: LR=1.59e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1493 Train Time 38.33004879951477s

Training epoch 1494, Batch 500/1000: LR=1.59e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1494, Batch 1000/1000: LR=1.59e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1494 Train Time 38.34931540489197s

Training epoch 1495, Batch 500/1000: LR=1.58e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1495, Batch 1000/1000: LR=1.58e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1495 Train Time 38.511739015579224s

Training epoch 1496, Batch 500/1000: LR=1.58e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1496, Batch 1000/1000: LR=1.58e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1496 Train Time 38.331175565719604s

Training epoch 1497, Batch 500/1000: LR=1.57e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1497, Batch 1000/1000: LR=1.57e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1497 Train Time 38.306230783462524s

Training epoch 1498, Batch 500/1000: LR=1.57e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1498, Batch 1000/1000: LR=1.57e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1498 Train Time 38.34254693984985s

Training epoch 1499, Batch 500/1000: LR=1.56e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1499, Batch 1000/1000: LR=1.56e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1499 Train Time 38.31949305534363s

Training epoch 1500, Batch 500/1000: LR=1.56e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1500, Batch 1000/1000: LR=1.56e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1500 Train Time 38.31290674209595s


Test Loss 4: 8.32e-03 5: 8.69e-04 6: 4.00e-05
Test FER 4: 3.77e-02 5: 4.18e-03 6: 1.88e-04
Test BER 4: 3.05e-03 5: 3.01e-04 6: 1.09e-05
Test -ln(BER) 4: 5.79e+00 5: 8.11e+00 6: 1.14e+01
# of testing samples: [100352.0, 100352.0, 548864.0]
 Test Time 138.42105174064636 s

Training epoch 1501, Batch 500/1000: LR=1.55e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1501, Batch 1000/1000: LR=1.55e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1501 Train Time 38.27803087234497s

Training epoch 1502, Batch 500/1000: LR=1.54e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1502, Batch 1000/1000: LR=1.54e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1502 Train Time 38.470789670944214s

Training epoch 1503, Batch 500/1000: LR=1.54e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1503, Batch 1000/1000: LR=1.54e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1503 Train Time 38.26307511329651s

Training epoch 1504, Batch 500/1000: LR=1.53e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1504, Batch 1000/1000: LR=1.53e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1504 Train Time 38.298813581466675s

Training epoch 1505, Batch 500/1000: LR=1.53e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1505, Batch 1000/1000: LR=1.53e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1505 Train Time 141.66039609909058s

Training epoch 1506, Batch 500/1000: LR=1.52e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1506, Batch 1000/1000: LR=1.52e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1506 Train Time 39.14170956611633s

Training epoch 1507, Batch 500/1000: LR=1.52e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1507, Batch 1000/1000: LR=1.52e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1507 Train Time 38.73753881454468s

Training epoch 1508, Batch 500/1000: LR=1.51e-05, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1508, Batch 1000/1000: LR=1.51e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1508 Train Time 38.69055104255676s

Training epoch 1509, Batch 500/1000: LR=1.51e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1509, Batch 1000/1000: LR=1.51e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1509 Train Time 38.698434591293335s

Training epoch 1510, Batch 500/1000: LR=1.50e-05, Loss=2.81e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1510, Batch 1000/1000: LR=1.50e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1510 Train Time 38.70428800582886s

Training epoch 1511, Batch 500/1000: LR=1.50e-05, Loss=2.77e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1511, Batch 1000/1000: LR=1.50e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1511 Train Time 38.352981090545654s

Training epoch 1512, Batch 500/1000: LR=1.49e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1512, Batch 1000/1000: LR=1.49e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1512 Train Time 38.2954261302948s

Training epoch 1513, Batch 500/1000: LR=1.48e-05, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1513, Batch 1000/1000: LR=1.48e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1513 Train Time 38.3084819316864s

Training epoch 1514, Batch 500/1000: LR=1.48e-05, Loss=2.81e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1514, Batch 1000/1000: LR=1.48e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1514 Train Time 38.30946159362793s

Training epoch 1515, Batch 500/1000: LR=1.47e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1515, Batch 1000/1000: LR=1.47e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1515 Train Time 38.277055740356445s

Training epoch 1516, Batch 500/1000: LR=1.47e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1516, Batch 1000/1000: LR=1.47e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1516 Train Time 38.90272831916809s

Training epoch 1517, Batch 500/1000: LR=1.46e-05, Loss=2.76e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1517, Batch 1000/1000: LR=1.46e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1517 Train Time 38.36801218986511s

Training epoch 1518, Batch 500/1000: LR=1.46e-05, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1518, Batch 1000/1000: LR=1.46e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1518 Train Time 38.27866053581238s

Training epoch 1519, Batch 500/1000: LR=1.45e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1519, Batch 1000/1000: LR=1.45e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1519 Train Time 38.48423957824707s

Training epoch 1520, Batch 500/1000: LR=1.45e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.03e-01
Training epoch 1520, Batch 1000/1000: LR=1.45e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1520 Train Time 38.28580284118652s

Training epoch 1521, Batch 500/1000: LR=1.44e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1521, Batch 1000/1000: LR=1.44e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1521 Train Time 38.7619948387146s

Training epoch 1522, Batch 500/1000: LR=1.44e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1522, Batch 1000/1000: LR=1.44e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1522 Train Time 38.48213863372803s

Training epoch 1523, Batch 500/1000: LR=1.43e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1523, Batch 1000/1000: LR=1.43e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1523 Train Time 38.338846921920776s

Training epoch 1524, Batch 500/1000: LR=1.43e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1524, Batch 1000/1000: LR=1.43e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1524 Train Time 38.344852447509766s

Training epoch 1525, Batch 500/1000: LR=1.42e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1525, Batch 1000/1000: LR=1.42e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1525 Train Time 38.32365965843201s

Training epoch 1526, Batch 500/1000: LR=1.42e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1526, Batch 1000/1000: LR=1.42e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1526 Train Time 38.30413317680359s

Training epoch 1527, Batch 500/1000: LR=1.41e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1527, Batch 1000/1000: LR=1.41e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1527 Train Time 38.331987619400024s

Training epoch 1528, Batch 500/1000: LR=1.40e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1528, Batch 1000/1000: LR=1.40e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1528 Train Time 38.29302906990051s

Training epoch 1529, Batch 500/1000: LR=1.40e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1529, Batch 1000/1000: LR=1.40e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1529 Train Time 38.3033983707428s

Training epoch 1530, Batch 500/1000: LR=1.39e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1530, Batch 1000/1000: LR=1.39e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1530 Train Time 38.29757237434387s

Training epoch 1531, Batch 500/1000: LR=1.39e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1531, Batch 1000/1000: LR=1.39e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1531 Train Time 38.30133366584778s

Training epoch 1532, Batch 500/1000: LR=1.38e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1532, Batch 1000/1000: LR=1.38e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1532 Train Time 38.312705278396606s

Training epoch 1533, Batch 500/1000: LR=1.38e-05, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1533, Batch 1000/1000: LR=1.38e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1533 Train Time 38.41033387184143s

Training epoch 1534, Batch 500/1000: LR=1.37e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1534, Batch 1000/1000: LR=1.37e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1534 Train Time 38.30157685279846s

Training epoch 1535, Batch 500/1000: LR=1.37e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1535, Batch 1000/1000: LR=1.37e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1535 Train Time 38.30628728866577s

Training epoch 1536, Batch 500/1000: LR=1.36e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1536, Batch 1000/1000: LR=1.36e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1536 Train Time 38.297940731048584s

Training epoch 1537, Batch 500/1000: LR=1.36e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1537, Batch 1000/1000: LR=1.36e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1537 Train Time 38.31544494628906s

Training epoch 1538, Batch 500/1000: LR=1.35e-05, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1538, Batch 1000/1000: LR=1.35e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1538 Train Time 38.278048038482666s

Training epoch 1539, Batch 500/1000: LR=1.35e-05, Loss=2.73e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1539, Batch 1000/1000: LR=1.35e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1539 Train Time 38.31453895568848s

Training epoch 1540, Batch 500/1000: LR=1.34e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1540, Batch 1000/1000: LR=1.34e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1540 Train Time 38.29563283920288s

Training epoch 1541, Batch 500/1000: LR=1.34e-05, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1541, Batch 1000/1000: LR=1.34e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1541 Train Time 38.33329892158508s

Training epoch 1542, Batch 500/1000: LR=1.33e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1542, Batch 1000/1000: LR=1.33e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1542 Train Time 38.40611481666565s

Training epoch 1543, Batch 500/1000: LR=1.33e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1543, Batch 1000/1000: LR=1.33e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1543 Train Time 38.31169509887695s

Training epoch 1544, Batch 500/1000: LR=1.32e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1544, Batch 1000/1000: LR=1.32e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1544 Train Time 38.31795525550842s

Training epoch 1545, Batch 500/1000: LR=1.32e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1545, Batch 1000/1000: LR=1.32e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1545 Train Time 38.29405403137207s

Training epoch 1546, Batch 500/1000: LR=1.31e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1546, Batch 1000/1000: LR=1.31e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1546 Train Time 38.302223443984985s

Training epoch 1547, Batch 500/1000: LR=1.31e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1547, Batch 1000/1000: LR=1.31e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1547 Train Time 38.294278621673584s

Training epoch 1548, Batch 500/1000: LR=1.30e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1548, Batch 1000/1000: LR=1.30e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1548 Train Time 38.302693605422974s

Training epoch 1549, Batch 500/1000: LR=1.30e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1549, Batch 1000/1000: LR=1.30e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1549 Train Time 38.318201303482056s

Training epoch 1550, Batch 500/1000: LR=1.29e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1550, Batch 1000/1000: LR=1.29e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1550 Train Time 38.322301387786865s

Training epoch 1551, Batch 500/1000: LR=1.29e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1551, Batch 1000/1000: LR=1.29e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1551 Train Time 38.56882119178772s

Training epoch 1552, Batch 500/1000: LR=1.28e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1552, Batch 1000/1000: LR=1.28e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1552 Train Time 38.32068133354187s

Training epoch 1553, Batch 500/1000: LR=1.28e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1553, Batch 1000/1000: LR=1.28e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1553 Train Time 58.19184589385986s

Training epoch 1554, Batch 500/1000: LR=1.27e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1554, Batch 1000/1000: LR=1.27e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1554 Train Time 38.86430358886719s

Training epoch 1555, Batch 500/1000: LR=1.27e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1555, Batch 1000/1000: LR=1.27e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1555 Train Time 38.687466859817505s

Training epoch 1556, Batch 500/1000: LR=1.26e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1556, Batch 1000/1000: LR=1.26e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1556 Train Time 38.72560453414917s

Training epoch 1557, Batch 500/1000: LR=1.26e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.07e-01
Training epoch 1557, Batch 1000/1000: LR=1.26e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1557 Train Time 38.71591019630432s

Training epoch 1558, Batch 500/1000: LR=1.25e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1558, Batch 1000/1000: LR=1.25e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1558 Train Time 38.698652505874634s

Training epoch 1559, Batch 500/1000: LR=1.25e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1559, Batch 1000/1000: LR=1.25e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1559 Train Time 38.69612097740173s

Training epoch 1560, Batch 500/1000: LR=1.24e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1560, Batch 1000/1000: LR=1.24e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1560 Train Time 38.86522102355957s

Training epoch 1561, Batch 500/1000: LR=1.24e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1561, Batch 1000/1000: LR=1.24e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1561 Train Time 39.14194178581238s

Training epoch 1562, Batch 500/1000: LR=1.23e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1562, Batch 1000/1000: LR=1.23e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1562 Train Time 38.947272062301636s

Training epoch 1563, Batch 500/1000: LR=1.23e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1563, Batch 1000/1000: LR=1.23e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1563 Train Time 38.72321796417236s

Training epoch 1564, Batch 500/1000: LR=1.22e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1564, Batch 1000/1000: LR=1.22e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1564 Train Time 38.69695067405701s

Training epoch 1565, Batch 500/1000: LR=1.22e-05, Loss=2.90e-02 BER=1.18e-02 FER=1.06e-01
Training epoch 1565, Batch 1000/1000: LR=1.22e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1565 Train Time 38.386714935302734s

Training epoch 1566, Batch 500/1000: LR=1.21e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1566, Batch 1000/1000: LR=1.21e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1566 Train Time 38.339502573013306s

Training epoch 1567, Batch 500/1000: LR=1.21e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1567, Batch 1000/1000: LR=1.21e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1567 Train Time 38.297908306121826s

Training epoch 1568, Batch 500/1000: LR=1.20e-05, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1568, Batch 1000/1000: LR=1.20e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1568 Train Time 38.29466009140015s

Training epoch 1569, Batch 500/1000: LR=1.20e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1569, Batch 1000/1000: LR=1.20e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1569 Train Time 38.42373728752136s

Training epoch 1570, Batch 500/1000: LR=1.19e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1570, Batch 1000/1000: LR=1.19e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1570 Train Time 38.419435262680054s

Training epoch 1571, Batch 500/1000: LR=1.19e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1571, Batch 1000/1000: LR=1.19e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1571 Train Time 38.32416772842407s

Training epoch 1572, Batch 500/1000: LR=1.18e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1572, Batch 1000/1000: LR=1.18e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1572 Train Time 38.31484937667847s

Training epoch 1573, Batch 500/1000: LR=1.18e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1573, Batch 1000/1000: LR=1.18e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1573 Train Time 38.371543645858765s

Training epoch 1574, Batch 500/1000: LR=1.17e-05, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1574, Batch 1000/1000: LR=1.17e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1574 Train Time 38.29213261604309s

Training epoch 1575, Batch 500/1000: LR=1.17e-05, Loss=2.78e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1575, Batch 1000/1000: LR=1.17e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1575 Train Time 38.28484129905701s

Training epoch 1576, Batch 500/1000: LR=1.16e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1576, Batch 1000/1000: LR=1.16e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1576 Train Time 38.34810709953308s

Training epoch 1577, Batch 500/1000: LR=1.16e-05, Loss=2.78e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1577, Batch 1000/1000: LR=1.16e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1577 Train Time 38.31466221809387s

Training epoch 1578, Batch 500/1000: LR=1.15e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1578, Batch 1000/1000: LR=1.15e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1578 Train Time 38.277621269226074s

Training epoch 1579, Batch 500/1000: LR=1.15e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1579, Batch 1000/1000: LR=1.15e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1579 Train Time 38.38947772979736s

Training epoch 1580, Batch 500/1000: LR=1.14e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1580, Batch 1000/1000: LR=1.14e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1580 Train Time 38.311736822128296s

Training epoch 1581, Batch 500/1000: LR=1.14e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1581, Batch 1000/1000: LR=1.14e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1581 Train Time 38.28677988052368s

Training epoch 1582, Batch 500/1000: LR=1.13e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1582, Batch 1000/1000: LR=1.13e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1582 Train Time 38.29087734222412s

Training epoch 1583, Batch 500/1000: LR=1.13e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1583, Batch 1000/1000: LR=1.13e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1583 Train Time 38.420045375823975s

Training epoch 1584, Batch 500/1000: LR=1.12e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1584, Batch 1000/1000: LR=1.12e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1584 Train Time 38.279008626937866s

Training epoch 1585, Batch 500/1000: LR=1.12e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1585, Batch 1000/1000: LR=1.12e-05, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1585 Train Time 38.277344703674316s

Training epoch 1586, Batch 500/1000: LR=1.12e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1586, Batch 1000/1000: LR=1.12e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1586 Train Time 38.30061388015747s

Training epoch 1587, Batch 500/1000: LR=1.11e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1587, Batch 1000/1000: LR=1.11e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1587 Train Time 38.283703088760376s

Training epoch 1588, Batch 500/1000: LR=1.11e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1588, Batch 1000/1000: LR=1.11e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1588 Train Time 38.42104983329773s

Training epoch 1589, Batch 500/1000: LR=1.10e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1589, Batch 1000/1000: LR=1.10e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1589 Train Time 38.278008222579956s

Training epoch 1590, Batch 500/1000: LR=1.10e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1590, Batch 1000/1000: LR=1.10e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1590 Train Time 38.27682018280029s

Training epoch 1591, Batch 500/1000: LR=1.09e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1591, Batch 1000/1000: LR=1.09e-05, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1591 Train Time 38.28878402709961s

Training epoch 1592, Batch 500/1000: LR=1.09e-05, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1592, Batch 1000/1000: LR=1.09e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1592 Train Time 38.30498719215393s

Training epoch 1593, Batch 500/1000: LR=1.08e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1593, Batch 1000/1000: LR=1.08e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1593 Train Time 38.27708959579468s

Training epoch 1594, Batch 500/1000: LR=1.08e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1594, Batch 1000/1000: LR=1.08e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1594 Train Time 38.273632526397705s

Training epoch 1595, Batch 500/1000: LR=1.07e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1595, Batch 1000/1000: LR=1.07e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1595 Train Time 38.28891396522522s

Training epoch 1596, Batch 500/1000: LR=1.07e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1596, Batch 1000/1000: LR=1.07e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1596 Train Time 38.39380216598511s

Training epoch 1597, Batch 500/1000: LR=1.06e-05, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1597, Batch 1000/1000: LR=1.06e-05, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1597 Train Time 38.30765223503113s

Training epoch 1598, Batch 500/1000: LR=1.06e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1598, Batch 1000/1000: LR=1.06e-05, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1598 Train Time 38.35105323791504s

Training epoch 1599, Batch 500/1000: LR=1.05e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1599, Batch 1000/1000: LR=1.05e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1599 Train Time 38.306275367736816s

Training epoch 1600, Batch 500/1000: LR=1.05e-05, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1600, Batch 1000/1000: LR=1.05e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1600 Train Time 38.281243562698364s

Training epoch 1601, Batch 500/1000: LR=1.05e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1601, Batch 1000/1000: LR=1.05e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1601 Train Time 81.82638049125671s

Training epoch 1602, Batch 500/1000: LR=1.04e-05, Loss=2.70e-02 BER=1.10e-02 FER=1.02e-01
Training epoch 1602, Batch 1000/1000: LR=1.04e-05, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1602 Train Time 38.937084436416626s

Training epoch 1603, Batch 500/1000: LR=1.04e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1603, Batch 1000/1000: LR=1.04e-05, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1603 Train Time 38.75752258300781s

Training epoch 1604, Batch 500/1000: LR=1.03e-05, Loss=2.87e-02 BER=1.18e-02 FER=1.06e-01
Training epoch 1604, Batch 1000/1000: LR=1.03e-05, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1604 Train Time 38.74753475189209s

Training epoch 1605, Batch 500/1000: LR=1.03e-05, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1605, Batch 1000/1000: LR=1.03e-05, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1605 Train Time 38.712246894836426s

Training epoch 1606, Batch 500/1000: LR=1.02e-05, Loss=2.73e-02 BER=1.11e-02 FER=1.01e-01
Training epoch 1606, Batch 1000/1000: LR=1.02e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1606 Train Time 38.70609760284424s

Training epoch 1607, Batch 500/1000: LR=1.02e-05, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1607, Batch 1000/1000: LR=1.02e-05, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1607 Train Time 38.70397090911865s

Training epoch 1608, Batch 500/1000: LR=1.01e-05, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1608, Batch 1000/1000: LR=1.01e-05, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1608 Train Time 38.715843200683594s

Training epoch 1609, Batch 500/1000: LR=1.01e-05, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1609, Batch 1000/1000: LR=1.01e-05, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1609 Train Time 38.72968363761902s

Training epoch 1610, Batch 500/1000: LR=1.00e-05, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1610, Batch 1000/1000: LR=1.00e-05, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1610 Train Time 38.74053120613098s

Training epoch 1611, Batch 500/1000: LR=1.00e-05, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1611, Batch 1000/1000: LR=1.00e-05, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1611 Train Time 38.72581338882446s

Training epoch 1612, Batch 500/1000: LR=9.96e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1612, Batch 1000/1000: LR=9.96e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1612 Train Time 38.675899267196655s

Training epoch 1613, Batch 500/1000: LR=9.91e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1613, Batch 1000/1000: LR=9.91e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1613 Train Time 38.32156157493591s

Training epoch 1614, Batch 500/1000: LR=9.87e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1614, Batch 1000/1000: LR=9.87e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1614 Train Time 38.31714701652527s

Training epoch 1615, Batch 500/1000: LR=9.82e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1615, Batch 1000/1000: LR=9.82e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1615 Train Time 38.32256770133972s

Training epoch 1616, Batch 500/1000: LR=9.78e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1616, Batch 1000/1000: LR=9.78e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1616 Train Time 38.36753726005554s

Training epoch 1617, Batch 500/1000: LR=9.74e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1617, Batch 1000/1000: LR=9.74e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1617 Train Time 38.56299114227295s

Training epoch 1618, Batch 500/1000: LR=9.69e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1618, Batch 1000/1000: LR=9.69e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1618 Train Time 38.31602907180786s

Training epoch 1619, Batch 500/1000: LR=9.65e-06, Loss=2.84e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1619, Batch 1000/1000: LR=9.65e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1619 Train Time 38.33172607421875s

Training epoch 1620, Batch 500/1000: LR=9.60e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1620, Batch 1000/1000: LR=9.60e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1620 Train Time 38.356751441955566s

Training epoch 1621, Batch 500/1000: LR=9.56e-06, Loss=2.78e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1621, Batch 1000/1000: LR=9.56e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Epoch 1621 Train Time 38.34674906730652s

Training epoch 1622, Batch 500/1000: LR=9.52e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1622, Batch 1000/1000: LR=9.52e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1622 Train Time 38.33159923553467s

Training epoch 1623, Batch 500/1000: LR=9.47e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1623, Batch 1000/1000: LR=9.47e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1623 Train Time 38.32607555389404s

Training epoch 1624, Batch 500/1000: LR=9.43e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1624, Batch 1000/1000: LR=9.43e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1624 Train Time 38.307698011398315s

Training epoch 1625, Batch 500/1000: LR=9.39e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1625, Batch 1000/1000: LR=9.39e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1625 Train Time 38.36587572097778s

Training epoch 1626, Batch 500/1000: LR=9.34e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1626, Batch 1000/1000: LR=9.34e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1626 Train Time 38.427077531814575s

Training epoch 1627, Batch 500/1000: LR=9.30e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1627, Batch 1000/1000: LR=9.30e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1627 Train Time 38.32646179199219s

Training epoch 1628, Batch 500/1000: LR=9.26e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1628, Batch 1000/1000: LR=9.26e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1628 Train Time 38.33410429954529s

Training epoch 1629, Batch 500/1000: LR=9.21e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.02e-01
Training epoch 1629, Batch 1000/1000: LR=9.21e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1629 Train Time 38.31600856781006s

Training epoch 1630, Batch 500/1000: LR=9.17e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1630, Batch 1000/1000: LR=9.17e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1630 Train Time 38.334081411361694s

Training epoch 1631, Batch 500/1000: LR=9.13e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1631, Batch 1000/1000: LR=9.13e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1631 Train Time 38.29889941215515s

Training epoch 1632, Batch 500/1000: LR=9.08e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1632, Batch 1000/1000: LR=9.08e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1632 Train Time 38.31073069572449s

Training epoch 1633, Batch 500/1000: LR=9.04e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1633, Batch 1000/1000: LR=9.04e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1633 Train Time 38.32006478309631s

Training epoch 1634, Batch 500/1000: LR=9.00e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1634, Batch 1000/1000: LR=9.00e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1634 Train Time 38.30667853355408s

Training epoch 1635, Batch 500/1000: LR=8.96e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1635, Batch 1000/1000: LR=8.96e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1635 Train Time 38.31541180610657s

Training epoch 1636, Batch 500/1000: LR=8.92e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1636, Batch 1000/1000: LR=8.92e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1636 Train Time 38.45116400718689s

Training epoch 1637, Batch 500/1000: LR=8.87e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1637, Batch 1000/1000: LR=8.87e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1637 Train Time 38.305761098861694s

Training epoch 1638, Batch 500/1000: LR=8.83e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1638, Batch 1000/1000: LR=8.83e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1638 Train Time 38.30842161178589s

Training epoch 1639, Batch 500/1000: LR=8.79e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1639, Batch 1000/1000: LR=8.79e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1639 Train Time 38.3062858581543s

Training epoch 1640, Batch 500/1000: LR=8.75e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1640, Batch 1000/1000: LR=8.75e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1640 Train Time 38.277201652526855s

Training epoch 1641, Batch 500/1000: LR=8.71e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1641, Batch 1000/1000: LR=8.71e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1641 Train Time 38.30223989486694s

Training epoch 1642, Batch 500/1000: LR=8.66e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1642, Batch 1000/1000: LR=8.66e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1642 Train Time 38.31533694267273s

Training epoch 1643, Batch 500/1000: LR=8.62e-06, Loss=2.92e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1643, Batch 1000/1000: LR=8.62e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1643 Train Time 38.31341552734375s

Training epoch 1644, Batch 500/1000: LR=8.58e-06, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1644, Batch 1000/1000: LR=8.58e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1644 Train Time 38.32162356376648s

Training epoch 1645, Batch 500/1000: LR=8.54e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1645, Batch 1000/1000: LR=8.54e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1645 Train Time 38.50139021873474s

Training epoch 1646, Batch 500/1000: LR=8.50e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1646, Batch 1000/1000: LR=8.50e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1646 Train Time 38.34570598602295s

Training epoch 1647, Batch 500/1000: LR=8.46e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.05e-01
Training epoch 1647, Batch 1000/1000: LR=8.46e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1647 Train Time 38.37127757072449s

Training epoch 1648, Batch 500/1000: LR=8.42e-06, Loss=2.78e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1648, Batch 1000/1000: LR=8.42e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Epoch 1648 Train Time 57.26927185058594s

Training epoch 1649, Batch 500/1000: LR=8.38e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1649, Batch 1000/1000: LR=8.38e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1649 Train Time 39.23059391975403s

Training epoch 1650, Batch 500/1000: LR=8.33e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1650, Batch 1000/1000: LR=8.33e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1650 Train Time 38.84687852859497s

Training epoch 1651, Batch 500/1000: LR=8.29e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1651, Batch 1000/1000: LR=8.29e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1651 Train Time 38.7307870388031s

Training epoch 1652, Batch 500/1000: LR=8.25e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1652, Batch 1000/1000: LR=8.25e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1652 Train Time 38.722118854522705s

Training epoch 1653, Batch 500/1000: LR=8.21e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1653, Batch 1000/1000: LR=8.21e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1653 Train Time 38.734150886535645s

Training epoch 1654, Batch 500/1000: LR=8.17e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1654, Batch 1000/1000: LR=8.17e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1654 Train Time 38.83150863647461s

Training epoch 1655, Batch 500/1000: LR=8.13e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1655, Batch 1000/1000: LR=8.13e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1655 Train Time 39.11860680580139s

Training epoch 1656, Batch 500/1000: LR=8.09e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1656, Batch 1000/1000: LR=8.09e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1656 Train Time 39.11985898017883s

Training epoch 1657, Batch 500/1000: LR=8.05e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1657, Batch 1000/1000: LR=8.05e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1657 Train Time 38.72632074356079s

Training epoch 1658, Batch 500/1000: LR=8.01e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1658, Batch 1000/1000: LR=8.01e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1658 Train Time 38.704408168792725s

Training epoch 1659, Batch 500/1000: LR=7.97e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1659, Batch 1000/1000: LR=7.97e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1659 Train Time 38.752063512802124s

Training epoch 1660, Batch 500/1000: LR=7.93e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1660, Batch 1000/1000: LR=7.93e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1660 Train Time 38.3830304145813s

Training epoch 1661, Batch 500/1000: LR=7.89e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1661, Batch 1000/1000: LR=7.89e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1661 Train Time 38.666512966156006s

Training epoch 1662, Batch 500/1000: LR=7.85e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1662, Batch 1000/1000: LR=7.85e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1662 Train Time 38.55762720108032s

Training epoch 1663, Batch 500/1000: LR=7.81e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1663, Batch 1000/1000: LR=7.81e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1663 Train Time 38.317994117736816s

Training epoch 1664, Batch 500/1000: LR=7.78e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1664, Batch 1000/1000: LR=7.78e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1664 Train Time 38.39622259140015s

Training epoch 1665, Batch 500/1000: LR=7.74e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1665, Batch 1000/1000: LR=7.74e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1665 Train Time 38.51275277137756s

Training epoch 1666, Batch 500/1000: LR=7.70e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1666, Batch 1000/1000: LR=7.70e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1666 Train Time 38.30049729347229s

Training epoch 1667, Batch 500/1000: LR=7.66e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1667, Batch 1000/1000: LR=7.66e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1667 Train Time 38.338666915893555s

Training epoch 1668, Batch 500/1000: LR=7.62e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1668, Batch 1000/1000: LR=7.62e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1668 Train Time 38.32100701332092s

Training epoch 1669, Batch 500/1000: LR=7.58e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1669, Batch 1000/1000: LR=7.58e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1669 Train Time 38.34085988998413s

Training epoch 1670, Batch 500/1000: LR=7.54e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1670, Batch 1000/1000: LR=7.54e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1670 Train Time 38.53740406036377s

Training epoch 1671, Batch 500/1000: LR=7.50e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1671, Batch 1000/1000: LR=7.50e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1671 Train Time 38.99744772911072s

Training epoch 1672, Batch 500/1000: LR=7.46e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1672, Batch 1000/1000: LR=7.46e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1672 Train Time 38.318158864974976s

Training epoch 1673, Batch 500/1000: LR=7.43e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1673, Batch 1000/1000: LR=7.43e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1673 Train Time 38.32670259475708s

Training epoch 1674, Batch 500/1000: LR=7.39e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1674, Batch 1000/1000: LR=7.39e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1674 Train Time 38.38179087638855s

Training epoch 1675, Batch 500/1000: LR=7.35e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1675, Batch 1000/1000: LR=7.35e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1675 Train Time 38.300286531448364s

Training epoch 1676, Batch 500/1000: LR=7.31e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1676, Batch 1000/1000: LR=7.31e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1676 Train Time 38.312660932540894s

Training epoch 1677, Batch 500/1000: LR=7.27e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1677, Batch 1000/1000: LR=7.27e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1677 Train Time 38.30568861961365s

Training epoch 1678, Batch 500/1000: LR=7.24e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1678, Batch 1000/1000: LR=7.24e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1678 Train Time 38.83470010757446s

Training epoch 1679, Batch 500/1000: LR=7.20e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1679, Batch 1000/1000: LR=7.20e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1679 Train Time 39.32201361656189s

Training epoch 1680, Batch 500/1000: LR=7.16e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1680, Batch 1000/1000: LR=7.16e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1680 Train Time 38.71851301193237s

Training epoch 1681, Batch 500/1000: LR=7.12e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1681, Batch 1000/1000: LR=7.12e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1681 Train Time 38.629265785217285s

Training epoch 1682, Batch 500/1000: LR=7.09e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1682, Batch 1000/1000: LR=7.09e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1682 Train Time 38.34791588783264s

Training epoch 1683, Batch 500/1000: LR=7.05e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1683, Batch 1000/1000: LR=7.05e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1683 Train Time 38.401724100112915s

Training epoch 1684, Batch 500/1000: LR=7.01e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1684, Batch 1000/1000: LR=7.01e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1684 Train Time 38.325374126434326s

Training epoch 1685, Batch 500/1000: LR=6.97e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1685, Batch 1000/1000: LR=6.97e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1685 Train Time 38.303447008132935s

Training epoch 1686, Batch 500/1000: LR=6.94e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1686, Batch 1000/1000: LR=6.94e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1686 Train Time 38.34119415283203s

Training epoch 1687, Batch 500/1000: LR=6.90e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1687, Batch 1000/1000: LR=6.90e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1687 Train Time 38.29952669143677s

Training epoch 1688, Batch 500/1000: LR=6.86e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1688, Batch 1000/1000: LR=6.86e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1688 Train Time 38.30380845069885s

Training epoch 1689, Batch 500/1000: LR=6.83e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1689, Batch 1000/1000: LR=6.83e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1689 Train Time 38.296231508255005s

Training epoch 1690, Batch 500/1000: LR=6.79e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1690, Batch 1000/1000: LR=6.79e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1690 Train Time 38.320454359054565s

Training epoch 1691, Batch 500/1000: LR=6.75e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1691, Batch 1000/1000: LR=6.75e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1691 Train Time 38.37846922874451s

Training epoch 1692, Batch 500/1000: LR=6.72e-06, Loss=2.88e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1692, Batch 1000/1000: LR=6.72e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1692 Train Time 38.31759428977966s

Training epoch 1693, Batch 500/1000: LR=6.68e-06, Loss=2.74e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1693, Batch 1000/1000: LR=6.68e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1693 Train Time 38.40451097488403s

Training epoch 1694, Batch 500/1000: LR=6.64e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1694, Batch 1000/1000: LR=6.64e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1694 Train Time 38.30736017227173s

Training epoch 1695, Batch 500/1000: LR=6.61e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1695, Batch 1000/1000: LR=6.61e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1695 Train Time 38.30118012428284s

Training epoch 1696, Batch 500/1000: LR=6.57e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1696, Batch 1000/1000: LR=6.57e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1696 Train Time 57.827096700668335s

Training epoch 1697, Batch 500/1000: LR=6.54e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1697, Batch 1000/1000: LR=6.54e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1697 Train Time 38.537638902664185s

Training epoch 1698, Batch 500/1000: LR=6.50e-06, Loss=2.91e-02 BER=1.20e-02 FER=1.08e-01
Training epoch 1698, Batch 1000/1000: LR=6.50e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1698 Train Time 38.32420063018799s

Training epoch 1699, Batch 500/1000: LR=6.47e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1699, Batch 1000/1000: LR=6.47e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1699 Train Time 38.80861043930054s

Training epoch 1700, Batch 500/1000: LR=6.43e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1700, Batch 1000/1000: LR=6.43e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1700 Train Time 38.406996726989746s

Training epoch 1701, Batch 500/1000: LR=6.40e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.02e-01
Training epoch 1701, Batch 1000/1000: LR=6.40e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1701 Train Time 38.34618592262268s

Training epoch 1702, Batch 500/1000: LR=6.36e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1702, Batch 1000/1000: LR=6.36e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1702 Train Time 38.40944743156433s

Training epoch 1703, Batch 500/1000: LR=6.32e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1703, Batch 1000/1000: LR=6.32e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1703 Train Time 38.32319211959839s

Training epoch 1704, Batch 500/1000: LR=6.29e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1704, Batch 1000/1000: LR=6.29e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1704 Train Time 38.32689690589905s

Training epoch 1705, Batch 500/1000: LR=6.25e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1705, Batch 1000/1000: LR=6.25e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1705 Train Time 38.323994159698486s

Training epoch 1706, Batch 500/1000: LR=6.22e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1706, Batch 1000/1000: LR=6.22e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1706 Train Time 38.281477212905884s

Training epoch 1707, Batch 500/1000: LR=6.19e-06, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Training epoch 1707, Batch 1000/1000: LR=6.19e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1707 Train Time 38.28763556480408s

Training epoch 1708, Batch 500/1000: LR=6.15e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1708, Batch 1000/1000: LR=6.15e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1708 Train Time 38.317092180252075s

Training epoch 1709, Batch 500/1000: LR=6.12e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1709, Batch 1000/1000: LR=6.12e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1709 Train Time 38.4002571105957s

Training epoch 1710, Batch 500/1000: LR=6.08e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1710, Batch 1000/1000: LR=6.08e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1710 Train Time 38.33816409111023s

Training epoch 1711, Batch 500/1000: LR=6.05e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1711, Batch 1000/1000: LR=6.05e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1711 Train Time 38.29504871368408s

Training epoch 1712, Batch 500/1000: LR=6.01e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.03e-01
Training epoch 1712, Batch 1000/1000: LR=6.01e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1712 Train Time 38.42120552062988s

Training epoch 1713, Batch 500/1000: LR=5.98e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1713, Batch 1000/1000: LR=5.98e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1713 Train Time 38.312039852142334s

Training epoch 1714, Batch 500/1000: LR=5.95e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1714, Batch 1000/1000: LR=5.95e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1714 Train Time 38.34475779533386s

Training epoch 1715, Batch 500/1000: LR=5.91e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1715, Batch 1000/1000: LR=5.91e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1715 Train Time 38.33070778846741s

Training epoch 1716, Batch 500/1000: LR=5.88e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.05e-01
Training epoch 1716, Batch 1000/1000: LR=5.88e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1716 Train Time 38.30270195007324s

Training epoch 1717, Batch 500/1000: LR=5.84e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1717, Batch 1000/1000: LR=5.84e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1717 Train Time 38.33587121963501s

Training epoch 1718, Batch 500/1000: LR=5.81e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1718, Batch 1000/1000: LR=5.81e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1718 Train Time 38.341079235076904s

Training epoch 1719, Batch 500/1000: LR=5.78e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1719, Batch 1000/1000: LR=5.78e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1719 Train Time 38.42462730407715s

Training epoch 1720, Batch 500/1000: LR=5.74e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1720, Batch 1000/1000: LR=5.74e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1720 Train Time 38.30716800689697s

Training epoch 1721, Batch 500/1000: LR=5.71e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1721, Batch 1000/1000: LR=5.71e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1721 Train Time 38.298484563827515s

Training epoch 1722, Batch 500/1000: LR=5.68e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1722, Batch 1000/1000: LR=5.68e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1722 Train Time 38.2962281703949s

Training epoch 1723, Batch 500/1000: LR=5.65e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1723, Batch 1000/1000: LR=5.65e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1723 Train Time 38.33423113822937s

Training epoch 1724, Batch 500/1000: LR=5.61e-06, Loss=2.82e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1724, Batch 1000/1000: LR=5.61e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1724 Train Time 38.3062219619751s

Training epoch 1725, Batch 500/1000: LR=5.58e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1725, Batch 1000/1000: LR=5.58e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1725 Train Time 38.307117223739624s

Training epoch 1726, Batch 500/1000: LR=5.55e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1726, Batch 1000/1000: LR=5.55e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1726 Train Time 38.30717992782593s

Training epoch 1727, Batch 500/1000: LR=5.51e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1727, Batch 1000/1000: LR=5.51e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1727 Train Time 38.34827446937561s

Training epoch 1728, Batch 500/1000: LR=5.48e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1728, Batch 1000/1000: LR=5.48e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1728 Train Time 38.43928670883179s

Training epoch 1729, Batch 500/1000: LR=5.45e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1729, Batch 1000/1000: LR=5.45e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1729 Train Time 38.29086446762085s

Training epoch 1730, Batch 500/1000: LR=5.42e-06, Loss=2.89e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1730, Batch 1000/1000: LR=5.42e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1730 Train Time 38.31174302101135s

Training epoch 1731, Batch 500/1000: LR=5.39e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1731, Batch 1000/1000: LR=5.39e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1731 Train Time 38.31118106842041s

Training epoch 1732, Batch 500/1000: LR=5.35e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1732, Batch 1000/1000: LR=5.35e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1732 Train Time 38.30573606491089s

Training epoch 1733, Batch 500/1000: LR=5.32e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1733, Batch 1000/1000: LR=5.32e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1733 Train Time 38.28486394882202s

Training epoch 1734, Batch 500/1000: LR=5.29e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1734, Batch 1000/1000: LR=5.29e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1734 Train Time 38.30372452735901s

Training epoch 1735, Batch 500/1000: LR=5.26e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1735, Batch 1000/1000: LR=5.26e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1735 Train Time 38.29461598396301s

Training epoch 1736, Batch 500/1000: LR=5.23e-06, Loss=2.73e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1736, Batch 1000/1000: LR=5.23e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1736 Train Time 38.39290928840637s

Training epoch 1737, Batch 500/1000: LR=5.20e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1737, Batch 1000/1000: LR=5.20e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1737 Train Time 38.34969687461853s

Training epoch 1738, Batch 500/1000: LR=5.16e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1738, Batch 1000/1000: LR=5.16e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1738 Train Time 38.393662452697754s

Training epoch 1739, Batch 500/1000: LR=5.13e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1739, Batch 1000/1000: LR=5.13e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1739 Train Time 38.335132122039795s

Training epoch 1740, Batch 500/1000: LR=5.10e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1740, Batch 1000/1000: LR=5.10e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1740 Train Time 38.29094576835632s

Training epoch 1741, Batch 500/1000: LR=5.07e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1741, Batch 1000/1000: LR=5.07e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1741 Train Time 38.29622507095337s

Training epoch 1742, Batch 500/1000: LR=5.04e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1742, Batch 1000/1000: LR=5.04e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1742 Train Time 38.266133546829224s

Training epoch 1743, Batch 500/1000: LR=5.01e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1743, Batch 1000/1000: LR=5.01e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1743 Train Time 88.34265732765198s

Training epoch 1744, Batch 500/1000: LR=4.98e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1744, Batch 1000/1000: LR=4.98e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1744 Train Time 39.2698917388916s

Training epoch 1745, Batch 500/1000: LR=4.95e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1745, Batch 1000/1000: LR=4.95e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1745 Train Time 38.93741774559021s

Training epoch 1746, Batch 500/1000: LR=4.92e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1746, Batch 1000/1000: LR=4.92e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1746 Train Time 38.73975729942322s

Training epoch 1747, Batch 500/1000: LR=4.89e-06, Loss=2.82e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1747, Batch 1000/1000: LR=4.89e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1747 Train Time 38.744696378707886s

Training epoch 1748, Batch 500/1000: LR=4.86e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1748, Batch 1000/1000: LR=4.86e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1748 Train Time 38.68799805641174s

Training epoch 1749, Batch 500/1000: LR=4.83e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1749, Batch 1000/1000: LR=4.83e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1749 Train Time 38.72330904006958s

Training epoch 1750, Batch 500/1000: LR=4.80e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1750, Batch 1000/1000: LR=4.80e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1750 Train Time 38.71825289726257s

Training epoch 1751, Batch 500/1000: LR=4.77e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1751, Batch 1000/1000: LR=4.77e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1751 Train Time 38.397093296051025s

Training epoch 1752, Batch 500/1000: LR=4.74e-06, Loss=2.73e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1752, Batch 1000/1000: LR=4.74e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1752 Train Time 38.3094437122345s

Training epoch 1753, Batch 500/1000: LR=4.71e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.02e-01
Training epoch 1753, Batch 1000/1000: LR=4.71e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1753 Train Time 38.293376445770264s

Training epoch 1754, Batch 500/1000: LR=4.68e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1754, Batch 1000/1000: LR=4.68e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1754 Train Time 38.33679437637329s

Training epoch 1755, Batch 500/1000: LR=4.65e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1755, Batch 1000/1000: LR=4.65e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1755 Train Time 38.31206703186035s

Training epoch 1756, Batch 500/1000: LR=4.62e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1756, Batch 1000/1000: LR=4.62e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1756 Train Time 38.291186571121216s

Training epoch 1757, Batch 500/1000: LR=4.59e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1757, Batch 1000/1000: LR=4.59e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1757 Train Time 38.32943868637085s

Training epoch 1758, Batch 500/1000: LR=4.56e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1758, Batch 1000/1000: LR=4.56e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1758 Train Time 38.482226848602295s

Training epoch 1759, Batch 500/1000: LR=4.53e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1759, Batch 1000/1000: LR=4.53e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1759 Train Time 38.333619356155396s

Training epoch 1760, Batch 500/1000: LR=4.50e-06, Loss=2.78e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1760, Batch 1000/1000: LR=4.50e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1760 Train Time 38.459731101989746s

Training epoch 1761, Batch 500/1000: LR=4.48e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1761, Batch 1000/1000: LR=4.48e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1761 Train Time 38.297163248062134s

Training epoch 1762, Batch 500/1000: LR=4.45e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1762, Batch 1000/1000: LR=4.45e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1762 Train Time 38.755276679992676s

Training epoch 1763, Batch 500/1000: LR=4.42e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1763, Batch 1000/1000: LR=4.42e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1763 Train Time 38.48843693733215s

Training epoch 1764, Batch 500/1000: LR=4.39e-06, Loss=2.78e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1764, Batch 1000/1000: LR=4.39e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1764 Train Time 38.33438777923584s

Training epoch 1765, Batch 500/1000: LR=4.36e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1765, Batch 1000/1000: LR=4.36e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1765 Train Time 38.32289481163025s

Training epoch 1766, Batch 500/1000: LR=4.33e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1766, Batch 1000/1000: LR=4.33e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1766 Train Time 38.28139638900757s

Training epoch 1767, Batch 500/1000: LR=4.31e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1767, Batch 1000/1000: LR=4.31e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1767 Train Time 38.286468744277954s

Training epoch 1768, Batch 500/1000: LR=4.28e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1768, Batch 1000/1000: LR=4.28e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1768 Train Time 38.32012462615967s

Training epoch 1769, Batch 500/1000: LR=4.25e-06, Loss=2.76e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1769, Batch 1000/1000: LR=4.25e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1769 Train Time 38.31494498252869s

Training epoch 1770, Batch 500/1000: LR=4.22e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1770, Batch 1000/1000: LR=4.22e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1770 Train Time 38.313939332962036s

Training epoch 1771, Batch 500/1000: LR=4.20e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1771, Batch 1000/1000: LR=4.20e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1771 Train Time 38.352885007858276s

Training epoch 1772, Batch 500/1000: LR=4.17e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1772, Batch 1000/1000: LR=4.17e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1772 Train Time 38.44015955924988s

Training epoch 1773, Batch 500/1000: LR=4.14e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1773, Batch 1000/1000: LR=4.14e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1773 Train Time 38.32415270805359s

Training epoch 1774, Batch 500/1000: LR=4.11e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1774, Batch 1000/1000: LR=4.11e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1774 Train Time 38.30905055999756s

Training epoch 1775, Batch 500/1000: LR=4.09e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1775, Batch 1000/1000: LR=4.09e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1775 Train Time 38.298670530319214s

Training epoch 1776, Batch 500/1000: LR=4.06e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1776, Batch 1000/1000: LR=4.06e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1776 Train Time 38.291080951690674s

Training epoch 1777, Batch 500/1000: LR=4.03e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1777, Batch 1000/1000: LR=4.03e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1777 Train Time 38.31862807273865s

Training epoch 1778, Batch 500/1000: LR=4.01e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1778, Batch 1000/1000: LR=4.01e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1778 Train Time 38.32619571685791s

Training epoch 1779, Batch 500/1000: LR=3.98e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1779, Batch 1000/1000: LR=3.98e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1779 Train Time 38.29984140396118s

Training epoch 1780, Batch 500/1000: LR=3.95e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1780, Batch 1000/1000: LR=3.95e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1780 Train Time 38.331751108169556s

Training epoch 1781, Batch 500/1000: LR=3.93e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1781, Batch 1000/1000: LR=3.93e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1781 Train Time 38.43612003326416s

Training epoch 1782, Batch 500/1000: LR=3.90e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1782, Batch 1000/1000: LR=3.90e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1782 Train Time 38.32542872428894s

Training epoch 1783, Batch 500/1000: LR=3.87e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1783, Batch 1000/1000: LR=3.87e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1783 Train Time 38.325758934020996s

Training epoch 1784, Batch 500/1000: LR=3.85e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1784, Batch 1000/1000: LR=3.85e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1784 Train Time 38.3371307849884s

Training epoch 1785, Batch 500/1000: LR=3.82e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1785, Batch 1000/1000: LR=3.82e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1785 Train Time 38.29102373123169s

Training epoch 1786, Batch 500/1000: LR=3.80e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1786, Batch 1000/1000: LR=3.80e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1786 Train Time 38.297054290771484s

Training epoch 1787, Batch 500/1000: LR=3.77e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1787, Batch 1000/1000: LR=3.77e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1787 Train Time 38.29622983932495s

Training epoch 1788, Batch 500/1000: LR=3.74e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1788, Batch 1000/1000: LR=3.74e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1788 Train Time 38.282132387161255s

Training epoch 1789, Batch 500/1000: LR=3.72e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1789, Batch 1000/1000: LR=3.72e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1789 Train Time 38.32786750793457s

Training epoch 1790, Batch 500/1000: LR=3.69e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1790, Batch 1000/1000: LR=3.69e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1790 Train Time 38.446112871170044s

Training epoch 1791, Batch 500/1000: LR=3.67e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1791, Batch 1000/1000: LR=3.67e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1791 Train Time 57.938209533691406s

Training epoch 1792, Batch 500/1000: LR=3.64e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1792, Batch 1000/1000: LR=3.64e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1792 Train Time 38.91371393203735s

Training epoch 1793, Batch 500/1000: LR=3.62e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1793, Batch 1000/1000: LR=3.62e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1793 Train Time 38.6931893825531s

Training epoch 1794, Batch 500/1000: LR=3.59e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1794, Batch 1000/1000: LR=3.59e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1794 Train Time 38.69112420082092s

Training epoch 1795, Batch 500/1000: LR=3.57e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1795, Batch 1000/1000: LR=3.57e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1795 Train Time 38.69247508049011s

Training epoch 1796, Batch 500/1000: LR=3.54e-06, Loss=2.78e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1796, Batch 1000/1000: LR=3.54e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1796 Train Time 38.70901155471802s

Training epoch 1797, Batch 500/1000: LR=3.52e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1797, Batch 1000/1000: LR=3.52e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1797 Train Time 38.68281817436218s

Training epoch 1798, Batch 500/1000: LR=3.50e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1798, Batch 1000/1000: LR=3.50e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1798 Train Time 38.69122934341431s

Training epoch 1799, Batch 500/1000: LR=3.47e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1799, Batch 1000/1000: LR=3.47e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1799 Train Time 38.80151081085205s

Training epoch 1800, Batch 500/1000: LR=3.45e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1800, Batch 1000/1000: LR=3.45e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1800 Train Time 38.699535846710205s


Test Loss 4: 8.50e-03 5: 8.41e-04 6: 3.32e-05
Test FER 4: 3.74e-02 5: 4.13e-03 6: 1.62e-04
Test BER 4: 3.09e-03 5: 2.74e-04 6: 8.30e-06
Test -ln(BER) 4: 5.78e+00 5: 8.20e+00 6: 1.17e+01
# of testing samples: [100352.0, 100352.0, 624640.0]
 Test Time 153.33420038223267 s

Training epoch 1801, Batch 500/1000: LR=3.42e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1801, Batch 1000/1000: LR=3.42e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1801 Train Time 38.2827787399292s

Training epoch 1802, Batch 500/1000: LR=3.40e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1802, Batch 1000/1000: LR=3.40e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1802 Train Time 38.267733097076416s

Training epoch 1803, Batch 500/1000: LR=3.37e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1803, Batch 1000/1000: LR=3.37e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1803 Train Time 38.35215878486633s

Training epoch 1804, Batch 500/1000: LR=3.35e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1804, Batch 1000/1000: LR=3.35e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1804 Train Time 38.29805564880371s

Training epoch 1805, Batch 500/1000: LR=3.33e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1805, Batch 1000/1000: LR=3.33e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1805 Train Time 38.3939790725708s

Training epoch 1806, Batch 500/1000: LR=3.30e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1806, Batch 1000/1000: LR=3.30e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1806 Train Time 38.276710510253906s

Training epoch 1807, Batch 500/1000: LR=3.28e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.03e-01
Training epoch 1807, Batch 1000/1000: LR=3.28e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1807 Train Time 38.29115533828735s

Training epoch 1808, Batch 500/1000: LR=3.26e-06, Loss=2.74e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1808, Batch 1000/1000: LR=3.26e-06, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1808 Train Time 38.26891613006592s

Training epoch 1809, Batch 500/1000: LR=3.23e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1809, Batch 1000/1000: LR=3.23e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1809 Train Time 38.255672454833984s

Training epoch 1810, Batch 500/1000: LR=3.21e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1810, Batch 1000/1000: LR=3.21e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1810 Train Time 38.267672061920166s

Training epoch 1811, Batch 500/1000: LR=3.19e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.02e-01
Training epoch 1811, Batch 1000/1000: LR=3.19e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1811 Train Time 38.263092041015625s

Training epoch 1812, Batch 500/1000: LR=3.17e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1812, Batch 1000/1000: LR=3.17e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1812 Train Time 38.26322555541992s

Training epoch 1813, Batch 500/1000: LR=3.14e-06, Loss=2.78e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1813, Batch 1000/1000: LR=3.14e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1813 Train Time 38.28635096549988s

Training epoch 1814, Batch 500/1000: LR=3.12e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1814, Batch 1000/1000: LR=3.12e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1814 Train Time 38.39582538604736s

Training epoch 1815, Batch 500/1000: LR=3.10e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1815, Batch 1000/1000: LR=3.10e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1815 Train Time 38.27541708946228s

Training epoch 1816, Batch 500/1000: LR=3.08e-06, Loss=2.76e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1816, Batch 1000/1000: LR=3.08e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1816 Train Time 38.26551795005798s

Training epoch 1817, Batch 500/1000: LR=3.05e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1817, Batch 1000/1000: LR=3.05e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1817 Train Time 38.253172636032104s

Training epoch 1818, Batch 500/1000: LR=3.03e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1818, Batch 1000/1000: LR=3.03e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1818 Train Time 38.259599685668945s

Training epoch 1819, Batch 500/1000: LR=3.01e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1819, Batch 1000/1000: LR=3.01e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1819 Train Time 38.22714924812317s

Training epoch 1820, Batch 500/1000: LR=2.99e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1820, Batch 1000/1000: LR=2.99e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1820 Train Time 38.27115201950073s

Training epoch 1821, Batch 500/1000: LR=2.97e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1821, Batch 1000/1000: LR=2.97e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1821 Train Time 38.262181520462036s

Training epoch 1822, Batch 500/1000: LR=2.94e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1822, Batch 1000/1000: LR=2.94e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1822 Train Time 38.24935483932495s

Training epoch 1823, Batch 500/1000: LR=2.92e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1823, Batch 1000/1000: LR=2.92e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1823 Train Time 38.381720304489136s

Training epoch 1824, Batch 500/1000: LR=2.90e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1824, Batch 1000/1000: LR=2.90e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1824 Train Time 38.27546238899231s

Training epoch 1825, Batch 500/1000: LR=2.88e-06, Loss=2.75e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1825, Batch 1000/1000: LR=2.88e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1825 Train Time 38.230063676834106s

Training epoch 1826, Batch 500/1000: LR=2.86e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1826, Batch 1000/1000: LR=2.86e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1826 Train Time 38.33547568321228s

Training epoch 1827, Batch 500/1000: LR=2.84e-06, Loss=2.76e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1827, Batch 1000/1000: LR=2.84e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1827 Train Time 38.26524305343628s

Training epoch 1828, Batch 500/1000: LR=2.82e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1828, Batch 1000/1000: LR=2.82e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1828 Train Time 38.28581357002258s

Training epoch 1829, Batch 500/1000: LR=2.80e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1829, Batch 1000/1000: LR=2.80e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1829 Train Time 38.27228832244873s

Training epoch 1830, Batch 500/1000: LR=2.77e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1830, Batch 1000/1000: LR=2.77e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1830 Train Time 38.26335382461548s

Training epoch 1831, Batch 500/1000: LR=2.75e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1831, Batch 1000/1000: LR=2.75e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1831 Train Time 38.2309787273407s

Training epoch 1832, Batch 500/1000: LR=2.73e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1832, Batch 1000/1000: LR=2.73e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1832 Train Time 38.32848501205444s

Training epoch 1833, Batch 500/1000: LR=2.71e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1833, Batch 1000/1000: LR=2.71e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1833 Train Time 38.36101174354553s

Training epoch 1834, Batch 500/1000: LR=2.69e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1834, Batch 1000/1000: LR=2.69e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1834 Train Time 74.81475806236267s

Training epoch 1835, Batch 500/1000: LR=2.67e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1835, Batch 1000/1000: LR=2.67e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1835 Train Time 39.14685535430908s

Training epoch 1836, Batch 500/1000: LR=2.65e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1836, Batch 1000/1000: LR=2.65e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1836 Train Time 38.4140887260437s

Training epoch 1837, Batch 500/1000: LR=2.63e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1837, Batch 1000/1000: LR=2.63e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1837 Train Time 38.29720211029053s

Training epoch 1838, Batch 500/1000: LR=2.61e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1838, Batch 1000/1000: LR=2.61e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1838 Train Time 38.304917335510254s

Training epoch 1839, Batch 500/1000: LR=2.59e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1839, Batch 1000/1000: LR=2.59e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1839 Train Time 38.24148678779602s

Training epoch 1840, Batch 500/1000: LR=2.57e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1840, Batch 1000/1000: LR=2.57e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1840 Train Time 38.65687847137451s

Training epoch 1841, Batch 500/1000: LR=2.56e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1841, Batch 1000/1000: LR=2.56e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1841 Train Time 38.555413007736206s

Training epoch 1842, Batch 500/1000: LR=2.54e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1842, Batch 1000/1000: LR=2.54e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1842 Train Time 38.27860426902771s

Training epoch 1843, Batch 500/1000: LR=2.52e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1843, Batch 1000/1000: LR=2.52e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1843 Train Time 38.30398488044739s

Training epoch 1844, Batch 500/1000: LR=2.50e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1844, Batch 1000/1000: LR=2.50e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1844 Train Time 38.328466176986694s

Training epoch 1845, Batch 500/1000: LR=2.48e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1845, Batch 1000/1000: LR=2.48e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1845 Train Time 38.29810452461243s

Training epoch 1846, Batch 500/1000: LR=2.46e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1846, Batch 1000/1000: LR=2.46e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1846 Train Time 38.29420351982117s

Training epoch 1847, Batch 500/1000: LR=2.44e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1847, Batch 1000/1000: LR=2.44e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1847 Train Time 38.29331612586975s

Training epoch 1848, Batch 500/1000: LR=2.42e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1848, Batch 1000/1000: LR=2.42e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1848 Train Time 38.33131980895996s

Training epoch 1849, Batch 500/1000: LR=2.40e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1849, Batch 1000/1000: LR=2.40e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1849 Train Time 38.43609380722046s

Training epoch 1850, Batch 500/1000: LR=2.39e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1850, Batch 1000/1000: LR=2.39e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1850 Train Time 38.32117509841919s

Training epoch 1851, Batch 500/1000: LR=2.37e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1851, Batch 1000/1000: LR=2.37e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1851 Train Time 38.421871185302734s

Training epoch 1852, Batch 500/1000: LR=2.35e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1852, Batch 1000/1000: LR=2.35e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1852 Train Time 38.293437480926514s

Training epoch 1853, Batch 500/1000: LR=2.33e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1853, Batch 1000/1000: LR=2.33e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1853 Train Time 38.31291174888611s

Training epoch 1854, Batch 500/1000: LR=2.31e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1854, Batch 1000/1000: LR=2.31e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1854 Train Time 38.319355487823486s

Training epoch 1855, Batch 500/1000: LR=2.30e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1855, Batch 1000/1000: LR=2.30e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1855 Train Time 38.277568101882935s

Training epoch 1856, Batch 500/1000: LR=2.28e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1856, Batch 1000/1000: LR=2.28e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Epoch 1856 Train Time 38.270859718322754s

Training epoch 1857, Batch 500/1000: LR=2.26e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1857, Batch 1000/1000: LR=2.26e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1857 Train Time 38.30397891998291s

Training epoch 1858, Batch 500/1000: LR=2.24e-06, Loss=2.74e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1858, Batch 1000/1000: LR=2.24e-06, Loss=2.73e-02 BER=1.11e-02 FER=1.02e-01
Epoch 1858 Train Time 38.32820439338684s

Training epoch 1859, Batch 500/1000: LR=2.23e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1859, Batch 1000/1000: LR=2.23e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1859 Train Time 38.42663216590881s

Training epoch 1860, Batch 500/1000: LR=2.21e-06, Loss=2.80e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1860, Batch 1000/1000: LR=2.21e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1860 Train Time 38.29439926147461s

Training epoch 1861, Batch 500/1000: LR=2.19e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1861, Batch 1000/1000: LR=2.19e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1861 Train Time 38.31795573234558s

Training epoch 1862, Batch 500/1000: LR=2.18e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1862, Batch 1000/1000: LR=2.18e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1862 Train Time 38.318488121032715s

Training epoch 1863, Batch 500/1000: LR=2.16e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1863, Batch 1000/1000: LR=2.16e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1863 Train Time 38.282771587371826s

Training epoch 1864, Batch 500/1000: LR=2.14e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1864, Batch 1000/1000: LR=2.14e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1864 Train Time 38.3026397228241s

Training epoch 1865, Batch 500/1000: LR=2.13e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1865, Batch 1000/1000: LR=2.13e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1865 Train Time 38.28251767158508s

Training epoch 1866, Batch 500/1000: LR=2.11e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1866, Batch 1000/1000: LR=2.11e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.06e-01
Epoch 1866 Train Time 38.32543063163757s

Training epoch 1867, Batch 500/1000: LR=2.09e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1867, Batch 1000/1000: LR=2.09e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1867 Train Time 38.287166357040405s

Training epoch 1868, Batch 500/1000: LR=2.08e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1868, Batch 1000/1000: LR=2.08e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1868 Train Time 38.37493658065796s

Training epoch 1869, Batch 500/1000: LR=2.06e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1869, Batch 1000/1000: LR=2.06e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1869 Train Time 38.282095193862915s

Training epoch 1870, Batch 500/1000: LR=2.04e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1870, Batch 1000/1000: LR=2.04e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1870 Train Time 38.25268578529358s

Training epoch 1871, Batch 500/1000: LR=2.03e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1871, Batch 1000/1000: LR=2.03e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1871 Train Time 38.279807329177856s

Training epoch 1872, Batch 500/1000: LR=2.01e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1872, Batch 1000/1000: LR=2.01e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1872 Train Time 38.27867794036865s

Training epoch 1873, Batch 500/1000: LR=2.00e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1873, Batch 1000/1000: LR=2.00e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1873 Train Time 38.26961064338684s

Training epoch 1874, Batch 500/1000: LR=1.98e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.06e-01
Training epoch 1874, Batch 1000/1000: LR=1.98e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1874 Train Time 38.30574679374695s

Training epoch 1875, Batch 500/1000: LR=1.97e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1875, Batch 1000/1000: LR=1.97e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1875 Train Time 38.276432037353516s

Training epoch 1876, Batch 500/1000: LR=1.95e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1876, Batch 1000/1000: LR=1.95e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1876 Train Time 38.298161029815674s

Training epoch 1877, Batch 500/1000: LR=1.94e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1877, Batch 1000/1000: LR=1.94e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1877 Train Time 38.31117606163025s

Training epoch 1878, Batch 500/1000: LR=1.92e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1878, Batch 1000/1000: LR=1.92e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1878 Train Time 38.39472413063049s

Training epoch 1879, Batch 500/1000: LR=1.91e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1879, Batch 1000/1000: LR=1.91e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1879 Train Time 38.27698826789856s

Training epoch 1880, Batch 500/1000: LR=1.89e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1880, Batch 1000/1000: LR=1.89e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1880 Train Time 38.290441036224365s

Training epoch 1881, Batch 500/1000: LR=1.88e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1881, Batch 1000/1000: LR=1.88e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1881 Train Time 38.28952407836914s

Training epoch 1882, Batch 500/1000: LR=1.86e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1882, Batch 1000/1000: LR=1.86e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1882 Train Time 68.93693161010742s

Training epoch 1883, Batch 500/1000: LR=1.85e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1883, Batch 1000/1000: LR=1.85e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1883 Train Time 39.175390005111694s

Training epoch 1884, Batch 500/1000: LR=1.83e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1884, Batch 1000/1000: LR=1.83e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1884 Train Time 38.728989601135254s

Training epoch 1885, Batch 500/1000: LR=1.82e-06, Loss=2.83e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1885, Batch 1000/1000: LR=1.82e-06, Loss=2.85e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1885 Train Time 38.66738700866699s

Training epoch 1886, Batch 500/1000: LR=1.81e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1886, Batch 1000/1000: LR=1.81e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1886 Train Time 38.6772665977478s

Training epoch 1887, Batch 500/1000: LR=1.79e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1887, Batch 1000/1000: LR=1.79e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1887 Train Time 38.680591344833374s

Training epoch 1888, Batch 500/1000: LR=1.78e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1888, Batch 1000/1000: LR=1.78e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1888 Train Time 38.71783208847046s

Training epoch 1889, Batch 500/1000: LR=1.76e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1889, Batch 1000/1000: LR=1.76e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1889 Train Time 38.676663398742676s

Training epoch 1890, Batch 500/1000: LR=1.75e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1890, Batch 1000/1000: LR=1.75e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1890 Train Time 38.674601316452026s

Training epoch 1891, Batch 500/1000: LR=1.74e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1891, Batch 1000/1000: LR=1.74e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1891 Train Time 38.669739723205566s

Training epoch 1892, Batch 500/1000: LR=1.72e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1892, Batch 1000/1000: LR=1.72e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1892 Train Time 38.663203716278076s

Training epoch 1893, Batch 500/1000: LR=1.71e-06, Loss=2.88e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1893, Batch 1000/1000: LR=1.71e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1893 Train Time 38.69667983055115s

Training epoch 1894, Batch 500/1000: LR=1.70e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1894, Batch 1000/1000: LR=1.70e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1894 Train Time 38.8448007106781s

Training epoch 1895, Batch 500/1000: LR=1.68e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1895, Batch 1000/1000: LR=1.68e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1895 Train Time 38.694458961486816s

Training epoch 1896, Batch 500/1000: LR=1.67e-06, Loss=2.74e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1896, Batch 1000/1000: LR=1.67e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1896 Train Time 38.36397910118103s

Training epoch 1897, Batch 500/1000: LR=1.66e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1897, Batch 1000/1000: LR=1.66e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1897 Train Time 38.33801031112671s

Training epoch 1898, Batch 500/1000: LR=1.65e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1898, Batch 1000/1000: LR=1.65e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1898 Train Time 38.35504770278931s

Training epoch 1899, Batch 500/1000: LR=1.63e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1899, Batch 1000/1000: LR=1.63e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1899 Train Time 38.28249502182007s

Training epoch 1900, Batch 500/1000: LR=1.62e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1900, Batch 1000/1000: LR=1.62e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1900 Train Time 38.94408988952637s

Training epoch 1901, Batch 500/1000: LR=1.61e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1901, Batch 1000/1000: LR=1.61e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1901 Train Time 38.32645392417908s

Training epoch 1902, Batch 500/1000: LR=1.60e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1902, Batch 1000/1000: LR=1.60e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1902 Train Time 38.2939088344574s

Training epoch 1903, Batch 500/1000: LR=1.59e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1903, Batch 1000/1000: LR=1.59e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1903 Train Time 38.29503011703491s

Training epoch 1904, Batch 500/1000: LR=1.57e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1904, Batch 1000/1000: LR=1.57e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1904 Train Time 38.27401065826416s

Training epoch 1905, Batch 500/1000: LR=1.56e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1905, Batch 1000/1000: LR=1.56e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1905 Train Time 38.78203773498535s

Training epoch 1906, Batch 500/1000: LR=1.55e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1906, Batch 1000/1000: LR=1.55e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1906 Train Time 38.466522455215454s

Training epoch 1907, Batch 500/1000: LR=1.54e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1907, Batch 1000/1000: LR=1.54e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1907 Train Time 38.26114273071289s

Training epoch 1908, Batch 500/1000: LR=1.53e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1908, Batch 1000/1000: LR=1.53e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1908 Train Time 38.3443021774292s

Training epoch 1909, Batch 500/1000: LR=1.52e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1909, Batch 1000/1000: LR=1.52e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1909 Train Time 38.383647441864014s

Training epoch 1910, Batch 500/1000: LR=1.50e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1910, Batch 1000/1000: LR=1.50e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1910 Train Time 38.302624225616455s

Training epoch 1911, Batch 500/1000: LR=1.49e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1911, Batch 1000/1000: LR=1.49e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1911 Train Time 38.75254845619202s

Training epoch 1912, Batch 500/1000: LR=1.48e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1912, Batch 1000/1000: LR=1.48e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1912 Train Time 38.41490697860718s

Training epoch 1913, Batch 500/1000: LR=1.47e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1913, Batch 1000/1000: LR=1.47e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1913 Train Time 38.2900333404541s

Training epoch 1914, Batch 500/1000: LR=1.46e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1914, Batch 1000/1000: LR=1.46e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1914 Train Time 38.28605651855469s

Training epoch 1915, Batch 500/1000: LR=1.45e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1915, Batch 1000/1000: LR=1.45e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1915 Train Time 38.3049898147583s

Training epoch 1916, Batch 500/1000: LR=1.44e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.05e-01
Training epoch 1916, Batch 1000/1000: LR=1.44e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1916 Train Time 38.246323108673096s

Training epoch 1917, Batch 500/1000: LR=1.43e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1917, Batch 1000/1000: LR=1.43e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1917 Train Time 38.28296613693237s

Training epoch 1918, Batch 500/1000: LR=1.42e-06, Loss=2.89e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1918, Batch 1000/1000: LR=1.42e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1918 Train Time 38.45972657203674s

Training epoch 1919, Batch 500/1000: LR=1.41e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1919, Batch 1000/1000: LR=1.41e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1919 Train Time 38.52875018119812s

Training epoch 1920, Batch 500/1000: LR=1.40e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1920, Batch 1000/1000: LR=1.40e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1920 Train Time 38.68996453285217s

Training epoch 1921, Batch 500/1000: LR=1.39e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1921, Batch 1000/1000: LR=1.39e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1921 Train Time 38.54196524620056s

Training epoch 1922, Batch 500/1000: LR=1.38e-06, Loss=2.87e-02 BER=1.16e-02 FER=1.07e-01
Training epoch 1922, Batch 1000/1000: LR=1.38e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1922 Train Time 38.34166669845581s

Training epoch 1923, Batch 500/1000: LR=1.37e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1923, Batch 1000/1000: LR=1.37e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1923 Train Time 38.28447961807251s

Training epoch 1924, Batch 500/1000: LR=1.36e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1924, Batch 1000/1000: LR=1.36e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1924 Train Time 38.25970149040222s

Training epoch 1925, Batch 500/1000: LR=1.35e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1925, Batch 1000/1000: LR=1.35e-06, Loss=2.80e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1925 Train Time 38.29894709587097s

Training epoch 1926, Batch 500/1000: LR=1.34e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1926, Batch 1000/1000: LR=1.34e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1926 Train Time 38.27840280532837s

Training epoch 1927, Batch 500/1000: LR=1.33e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1927, Batch 1000/1000: LR=1.33e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1927 Train Time 38.32163333892822s

Training epoch 1928, Batch 500/1000: LR=1.33e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1928, Batch 1000/1000: LR=1.33e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1928 Train Time 38.397693157196045s

Training epoch 1929, Batch 500/1000: LR=1.32e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1929, Batch 1000/1000: LR=1.32e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1929 Train Time 38.290913105010986s

Training epoch 1930, Batch 500/1000: LR=1.31e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1930, Batch 1000/1000: LR=1.31e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Epoch 1930 Train Time 118.17180562019348s

Training epoch 1931, Batch 500/1000: LR=1.30e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1931, Batch 1000/1000: LR=1.30e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1931 Train Time 39.8036413192749s

Training epoch 1932, Batch 500/1000: LR=1.29e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1932, Batch 1000/1000: LR=1.29e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1932 Train Time 38.687928438186646s

Training epoch 1933, Batch 500/1000: LR=1.28e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1933, Batch 1000/1000: LR=1.28e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1933 Train Time 38.72189211845398s

Training epoch 1934, Batch 500/1000: LR=1.27e-06, Loss=2.91e-02 BER=1.19e-02 FER=1.08e-01
Training epoch 1934, Batch 1000/1000: LR=1.27e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1934 Train Time 38.7073175907135s

Training epoch 1935, Batch 500/1000: LR=1.27e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1935, Batch 1000/1000: LR=1.27e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1935 Train Time 38.67873287200928s

Training epoch 1936, Batch 500/1000: LR=1.26e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1936, Batch 1000/1000: LR=1.26e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1936 Train Time 38.68626165390015s

Training epoch 1937, Batch 500/1000: LR=1.25e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1937, Batch 1000/1000: LR=1.25e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1937 Train Time 38.673136949539185s

Training epoch 1938, Batch 500/1000: LR=1.24e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1938, Batch 1000/1000: LR=1.24e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1938 Train Time 38.690024852752686s

Training epoch 1939, Batch 500/1000: LR=1.23e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1939, Batch 1000/1000: LR=1.23e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1939 Train Time 38.69530987739563s

Training epoch 1940, Batch 500/1000: LR=1.23e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1940, Batch 1000/1000: LR=1.23e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1940 Train Time 38.651007413864136s

Training epoch 1941, Batch 500/1000: LR=1.22e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1941, Batch 1000/1000: LR=1.22e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1941 Train Time 38.68317103385925s

Training epoch 1942, Batch 500/1000: LR=1.21e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1942, Batch 1000/1000: LR=1.21e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1942 Train Time 38.707622051239014s

Training epoch 1943, Batch 500/1000: LR=1.21e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1943, Batch 1000/1000: LR=1.21e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1943 Train Time 38.66549849510193s

Training epoch 1944, Batch 500/1000: LR=1.20e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1944, Batch 1000/1000: LR=1.20e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1944 Train Time 38.737687826156616s

Training epoch 1945, Batch 500/1000: LR=1.19e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1945, Batch 1000/1000: LR=1.19e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1945 Train Time 38.7693247795105s

Training epoch 1946, Batch 500/1000: LR=1.18e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1946, Batch 1000/1000: LR=1.18e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1946 Train Time 38.46216702461243s

Training epoch 1947, Batch 500/1000: LR=1.18e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1947, Batch 1000/1000: LR=1.18e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1947 Train Time 38.26026797294617s

Training epoch 1948, Batch 500/1000: LR=1.17e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1948, Batch 1000/1000: LR=1.17e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1948 Train Time 38.30384421348572s

Training epoch 1949, Batch 500/1000: LR=1.17e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.06e-01
Training epoch 1949, Batch 1000/1000: LR=1.17e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1949 Train Time 38.282806158065796s

Training epoch 1950, Batch 500/1000: LR=1.16e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1950, Batch 1000/1000: LR=1.16e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.07e-01
Epoch 1950 Train Time 38.288601875305176s

Training epoch 1951, Batch 500/1000: LR=1.15e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.04e-01
Training epoch 1951, Batch 1000/1000: LR=1.15e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1951 Train Time 38.27914214134216s

Training epoch 1952, Batch 500/1000: LR=1.15e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1952, Batch 1000/1000: LR=1.15e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1952 Train Time 38.295591831207275s

Training epoch 1953, Batch 500/1000: LR=1.14e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1953, Batch 1000/1000: LR=1.14e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1953 Train Time 38.31548595428467s

Training epoch 1954, Batch 500/1000: LR=1.13e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1954, Batch 1000/1000: LR=1.13e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1954 Train Time 38.404744386672974s

Training epoch 1955, Batch 500/1000: LR=1.13e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.03e-01
Training epoch 1955, Batch 1000/1000: LR=1.13e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1955 Train Time 38.29811382293701s

Training epoch 1956, Batch 500/1000: LR=1.12e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1956, Batch 1000/1000: LR=1.12e-06, Loss=2.82e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1956 Train Time 38.270087242126465s

Training epoch 1957, Batch 500/1000: LR=1.12e-06, Loss=2.88e-02 BER=1.17e-02 FER=1.08e-01
Training epoch 1957, Batch 1000/1000: LR=1.12e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1957 Train Time 38.25606632232666s

Training epoch 1958, Batch 500/1000: LR=1.11e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1958, Batch 1000/1000: LR=1.11e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1958 Train Time 38.25695466995239s

Training epoch 1959, Batch 500/1000: LR=1.11e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1959, Batch 1000/1000: LR=1.11e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1959 Train Time 38.28466725349426s

Training epoch 1960, Batch 500/1000: LR=1.10e-06, Loss=2.86e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1960, Batch 1000/1000: LR=1.10e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1960 Train Time 38.281001329422s

Training epoch 1961, Batch 500/1000: LR=1.10e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1961, Batch 1000/1000: LR=1.10e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1961 Train Time 38.276043176651s

Training epoch 1962, Batch 500/1000: LR=1.09e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1962, Batch 1000/1000: LR=1.09e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1962 Train Time 38.30138111114502s

Training epoch 1963, Batch 500/1000: LR=1.09e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1963, Batch 1000/1000: LR=1.09e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1963 Train Time 38.37885904312134s

Training epoch 1964, Batch 500/1000: LR=1.08e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1964, Batch 1000/1000: LR=1.08e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1964 Train Time 38.279114961624146s

Training epoch 1965, Batch 500/1000: LR=1.08e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.02e-01
Training epoch 1965, Batch 1000/1000: LR=1.08e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1965 Train Time 38.28593397140503s

Training epoch 1966, Batch 500/1000: LR=1.07e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1966, Batch 1000/1000: LR=1.07e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1966 Train Time 38.25642371177673s

Training epoch 1967, Batch 500/1000: LR=1.07e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1967, Batch 1000/1000: LR=1.07e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1967 Train Time 38.23383069038391s

Training epoch 1968, Batch 500/1000: LR=1.07e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1968, Batch 1000/1000: LR=1.07e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1968 Train Time 38.30349016189575s

Training epoch 1969, Batch 500/1000: LR=1.06e-06, Loss=2.75e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1969, Batch 1000/1000: LR=1.06e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1969 Train Time 38.28379845619202s

Training epoch 1970, Batch 500/1000: LR=1.06e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1970, Batch 1000/1000: LR=1.06e-06, Loss=2.83e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1970 Train Time 38.26829552650452s

Training epoch 1971, Batch 500/1000: LR=1.05e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1971, Batch 1000/1000: LR=1.05e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.04e-01
Epoch 1971 Train Time 38.29344940185547s

Training epoch 1972, Batch 500/1000: LR=1.05e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1972, Batch 1000/1000: LR=1.05e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.03e-01
Epoch 1972 Train Time 38.52116298675537s

Training epoch 1973, Batch 500/1000: LR=1.05e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1973, Batch 1000/1000: LR=1.05e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1973 Train Time 38.6278715133667s

Training epoch 1974, Batch 500/1000: LR=1.04e-06, Loss=2.76e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1974, Batch 1000/1000: LR=1.04e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1974 Train Time 38.28452205657959s

Training epoch 1975, Batch 500/1000: LR=1.04e-06, Loss=2.74e-02 BER=1.11e-02 FER=1.03e-01
Training epoch 1975, Batch 1000/1000: LR=1.04e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1975 Train Time 38.31494450569153s

Training epoch 1976, Batch 500/1000: LR=1.04e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.04e-01
Training epoch 1976, Batch 1000/1000: LR=1.04e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1976 Train Time 38.268476486206055s

Training epoch 1977, Batch 500/1000: LR=1.04e-06, Loss=2.72e-02 BER=1.10e-02 FER=1.02e-01
Training epoch 1977, Batch 1000/1000: LR=1.04e-06, Loss=2.77e-02 BER=1.12e-02 FER=1.03e-01
Epoch 1977 Train Time 57.74934411048889s

Training epoch 1978, Batch 500/1000: LR=1.03e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 1978, Batch 1000/1000: LR=1.03e-06, Loss=2.88e-02 BER=1.18e-02 FER=1.07e-01
Epoch 1978 Train Time 38.96885299682617s

Training epoch 1979, Batch 500/1000: LR=1.03e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1979, Batch 1000/1000: LR=1.03e-06, Loss=2.79e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1979 Train Time 38.41369986534119s

Training epoch 1980, Batch 500/1000: LR=1.03e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1980, Batch 1000/1000: LR=1.03e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1980 Train Time 38.31739664077759s

Training epoch 1981, Batch 500/1000: LR=1.02e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1981, Batch 1000/1000: LR=1.02e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1981 Train Time 38.381226539611816s

Training epoch 1982, Batch 500/1000: LR=1.02e-06, Loss=2.85e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1982, Batch 1000/1000: LR=1.02e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1982 Train Time 38.302976846694946s

Training epoch 1983, Batch 500/1000: LR=1.02e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1983, Batch 1000/1000: LR=1.02e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Epoch 1983 Train Time 38.29648017883301s

Training epoch 1984, Batch 500/1000: LR=1.02e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1984, Batch 1000/1000: LR=1.02e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1984 Train Time 38.3054735660553s

Training epoch 1985, Batch 500/1000: LR=1.02e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Training epoch 1985, Batch 1000/1000: LR=1.02e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1985 Train Time 38.26613783836365s

Training epoch 1986, Batch 500/1000: LR=1.01e-06, Loss=2.87e-02 BER=1.17e-02 FER=1.07e-01
Training epoch 1986, Batch 1000/1000: LR=1.01e-06, Loss=2.84e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1986 Train Time 38.298155784606934s

Training epoch 1987, Batch 500/1000: LR=1.01e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.03e-01
Training epoch 1987, Batch 1000/1000: LR=1.01e-06, Loss=2.77e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1987 Train Time 38.31223130226135s

Training epoch 1988, Batch 500/1000: LR=1.01e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1988, Batch 1000/1000: LR=1.01e-06, Loss=2.84e-02 BER=1.15e-02 FER=1.04e-01
Epoch 1988 Train Time 38.2998948097229s

Training epoch 1989, Batch 500/1000: LR=1.01e-06, Loss=2.90e-02 BER=1.18e-02 FER=1.08e-01
Training epoch 1989, Batch 1000/1000: LR=1.01e-06, Loss=2.86e-02 BER=1.16e-02 FER=1.06e-01
Epoch 1989 Train Time 38.32438898086548s

Training epoch 1990, Batch 500/1000: LR=1.01e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1990, Batch 1000/1000: LR=1.01e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1990 Train Time 38.36262226104736s

Training epoch 1991, Batch 500/1000: LR=1.01e-06, Loss=2.73e-02 BER=1.11e-02 FER=1.02e-01
Training epoch 1991, Batch 1000/1000: LR=1.01e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Epoch 1991 Train Time 38.31506156921387s

Training epoch 1992, Batch 500/1000: LR=1.00e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Training epoch 1992, Batch 1000/1000: LR=1.00e-06, Loss=2.81e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1992 Train Time 38.26689600944519s

Training epoch 1993, Batch 500/1000: LR=1.00e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.06e-01
Training epoch 1993, Batch 1000/1000: LR=1.00e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1993 Train Time 38.355740547180176s

Training epoch 1994, Batch 500/1000: LR=1.00e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.05e-01
Training epoch 1994, Batch 1000/1000: LR=1.00e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.05e-01
Epoch 1994 Train Time 38.27432894706726s

Training epoch 1995, Batch 500/1000: LR=1.00e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1995, Batch 1000/1000: LR=1.00e-06, Loss=2.81e-02 BER=1.15e-02 FER=1.05e-01
Epoch 1995 Train Time 38.301838874816895s

Training epoch 1996, Batch 500/1000: LR=1.00e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.03e-01
Training epoch 1996, Batch 1000/1000: LR=1.00e-06, Loss=2.80e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1996 Train Time 38.3030481338501s

Training epoch 1997, Batch 500/1000: LR=1.00e-06, Loss=2.82e-02 BER=1.15e-02 FER=1.05e-01
Training epoch 1997, Batch 1000/1000: LR=1.00e-06, Loss=2.80e-02 BER=1.14e-02 FER=1.04e-01
Epoch 1997 Train Time 38.30090689659119s

Training epoch 1998, Batch 500/1000: LR=1.00e-06, Loss=2.76e-02 BER=1.12e-02 FER=1.04e-01
Training epoch 1998, Batch 1000/1000: LR=1.00e-06, Loss=2.79e-02 BER=1.14e-02 FER=1.05e-01
Epoch 1998 Train Time 38.31779098510742s

Training epoch 1999, Batch 500/1000: LR=1.00e-06, Loss=2.73e-02 BER=1.10e-02 FER=1.02e-01
Training epoch 1999, Batch 1000/1000: LR=1.00e-06, Loss=2.78e-02 BER=1.13e-02 FER=1.04e-01
Epoch 1999 Train Time 38.374366998672485s

Training epoch 2000, Batch 500/1000: LR=1.00e-06, Loss=2.83e-02 BER=1.16e-02 FER=1.06e-01
Training epoch 2000, Batch 1000/1000: LR=1.00e-06, Loss=2.85e-02 BER=1.16e-02 FER=1.06e-01
Epoch 2000 Train Time 38.29279184341431s


Test Loss 4: 8.46e-03 5: 8.46e-04 6: 3.27e-05
Test FER 4: 3.77e-02 5: 4.12e-03 6: 1.48e-04
Test BER 4: 3.14e-03 5: 2.71e-04 6: 8.35e-06
Test -ln(BER) 4: 5.76e+00 5: 8.21e+00 6: 1.17e+01
# of testing samples: [100352.0, 100352.0, 684032.0]
 Test Time 164.0385890007019 s

